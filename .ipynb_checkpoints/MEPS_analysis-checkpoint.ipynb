{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MEPS Dataset Analysis\n",
    "\n",
    "So we have two files - one with basic demographic info and one with medications. They're small and pandas will deal with them fine - no need for SQL in an offline analysis setting. We'll just want to join them on id to make predictions.\n",
    "\n",
    "Some obvious things to keep in mind from looking at them -  \n",
    "1) a significant proportion of subjects are younger than sixteen. For these individuals, we have basically zero info - best to drop them from our tables and not make predictions for them. A cursory search of meds reveals no medication info for them.  \n",
    "2) We have tons of duplicate meds - we'll probably want to consolidate these. \n",
    "\n",
    "Since this is an informal ad hoc analysis, I'll just be checking results of operations rather than building out proper tests. Of course, this isn't intended to look like production code :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " Summary of data: \n",
      "\n",
      "\n",
      "Preview: \n",
      "   Unnamed: 0        id  panel  pooledWeight  age     sex      race  \\\n",
      "0           1  10007101     15   3603.881236   28    Male     White   \n",
      "1           2  10007102     15   2544.550424   25  Female     White   \n",
      "2           3  10007103     15   4050.397468    4    Male     White   \n",
      "3           4  10007104     15   3064.059720    3  Female     White   \n",
      "4           5  10008101     15   3635.552466   51    Male  Multiple   \n",
      "\n",
      "                   married highBPDiagnosed diabetesDiagnosed  chdDiagnosed  \\\n",
      "0                  MARRIED             Yes                No            No   \n",
      "1                  MARRIED              No                No            No   \n",
      "2  UNDER 16 - INAPPLICABLE    Inapplicable      Inapplicable  Inapplicable   \n",
      "3  UNDER 16 - INAPPLICABLE    Inapplicable      Inapplicable  Inapplicable   \n",
      "4                  MARRIED              No                No            No   \n",
      "\n",
      "    miDiagnosed anginaDiagnosed strokeDiagnosed emphysemaDiagnosed  \\\n",
      "0            No              No              No                 No   \n",
      "1            No              No              No                 No   \n",
      "2  Inapplicable    Inapplicable    Inapplicable       Inapplicable   \n",
      "3  Inapplicable    Inapplicable    Inapplicable       Inapplicable   \n",
      "4            No              No              No                 No   \n",
      "\n",
      "  asthmaDiagnosed otherHDDiagnosed heartFailureDiagnosed  \n",
      "0              No               No                    No  \n",
      "1             Yes               No                    No  \n",
      "2              No     Inapplicable                    No  \n",
      "3              No     Inapplicable                    No  \n",
      "4              No               No                    No  \n",
      "\n",
      "\n",
      " Stats: \n",
      "         Unnamed: 0            id         panel  pooledWeight           age\n",
      "count  61489.000000  6.148900e+04  61489.000000  61489.000000  61489.000000\n",
      "mean   30745.000000  5.534638e+07     13.534453   5063.701982     33.578396\n",
      "std    17750.489688  2.759592e+07      1.061329   3815.885387     22.887576\n",
      "min        1.000000  1.000710e+07     12.000000    127.710358     -1.000000\n",
      "25%    15373.000000  4.045510e+07     13.000000   2217.419038     14.000000\n",
      "50%    30745.000000  4.965010e+07     14.000000   3989.180418     32.000000\n",
      "75%    46117.000000  8.161711e+07     14.000000   6905.677619     51.000000\n",
      "max    61489.000000  8.968810e+07     15.000000  38828.153564     85.000000\n",
      "\n",
      "\n",
      "\n",
      "Preview: \n",
      "   Unnamed: 0        id  rxStartMonth  rxStartYear  \\\n",
      "0           1  10007104             3         2011   \n",
      "1           2  10007104             3         2011   \n",
      "2           3  10008102             3         2011   \n",
      "3           4  10008102             3         2011   \n",
      "4           5  10008102             9         2011   \n",
      "\n",
      "                           rxName        rxNDC  rxQuantity rxForm  \n",
      "0                     AMOXICILLIN    143988775        75.0   SUSR  \n",
      "1              OTIC EDGE SOLUTION  68032032814        14.0    SOL  \n",
      "2  NASAL DECONGESTANT 0.05% SPRAY  63981056903        15.0    SPR  \n",
      "3  NASAL DECONGESTANT 0.05% SPRAY  63981056903        15.0    SPR  \n",
      "4                    DIPHENHYDRAM    603333921        30.0    CAP  \n",
      "\n",
      "\n",
      " Stats: \n",
      "         Unnamed: 0            id  rxStartMonth   rxStartYear         rxNDC  \\\n",
      "count  1.148347e+06  1.148347e+06  1.148347e+06  1.148347e+06  1.148347e+06   \n",
      "mean   1.240252e+06  5.523596e+07  5.184600e-01  1.172427e+03  2.226109e+10   \n",
      "std    9.590400e+05  2.728584e+07  4.087907e+00  9.895660e+02  2.834269e+10   \n",
      "min    1.000000e+00  1.000710e+07 -9.000000e+00 -1.400000e+01 -9.000000e+00   \n",
      "25%    2.870875e+05  4.063810e+07 -1.000000e+00 -1.000000e+00  1.490472e+08   \n",
      "50%    1.093262e+06  4.947510e+07 -1.000000e+00  2.000000e+03  5.910385e+08   \n",
      "75%    2.103602e+06  8.118210e+07  1.000000e+00  2.008000e+03  5.486835e+10   \n",
      "max    3.336212e+06  8.968810e+07  1.200000e+01  2.011000e+03  9.920707e+10   \n",
      "\n",
      "         rxQuantity  \n",
      "count  1.148347e+06  \n",
      "mean   5.942380e+01  \n",
      "std    3.702845e+02  \n",
      "min   -9.000000e+00  \n",
      "25%    3.000000e+01  \n",
      "50%    3.000000e+01  \n",
      "75%    6.800000e+01  \n",
      "max    1.200000e+05  \n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# coding=utf-8\n",
    "# python = 2.7.x, since most companies still use that, but I'll keep the code 3.x compatible where possible\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.dummy import DummyRegressor\n",
    "\n",
    "\n",
    "pd.options.display.max_columns = 50\n",
    "sns.set_palette('pastel')\n",
    "%matplotlib inline\n",
    "\n",
    "subjects = pd.read_csv(\"./input/meps_base_data.csv\")\n",
    "meds = pd.read_csv(\"./input/meps_meds.csv\")\n",
    "\n",
    "\n",
    "def display_summary(dfs_to_describe, preview_size=5):\n",
    "    print(\"\\n\\n Summary of data: \\n\\n\")\n",
    "    \n",
    "    for df in dfs_to_describe:\n",
    "\n",
    "        print(\"Preview: \")\n",
    "        print(df.head(preview_size))\n",
    "        print(\"\\n\\n Stats: \")\n",
    "        print(df.describe())\n",
    "        print(\"\\n\\n\")\n",
    "\n",
    "    \n",
    "display_summary([subjects,meds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Cleanup  \n",
    "\n",
    "Let's think about what data we can drop -  \n",
    "\n",
    "1) from our subjects,  \n",
    "    a) `panel` seems to be panel year and is unlikely to be terribly useful to us, at least for now. With a sufficiently large amount of data, it could be used in tree algorithms and the like as-is. Or we could subdivide by groups of years and treat as a categorical so that a classifier could find trends for each period of time bin.  \n",
    "    b) `pooledWeight` seems to be used for a weighting function / to correct for demographics. I couldn't immediately find details on how to use the weighting function, so I'm ignoring it for now.  \n",
    "    \n",
    "2)  from our medications\n",
    "    a) we have tons of duplicates of drugs - presumably we have one record per prescription written; let's just keep one record of a prescription of a given drug per person (we'll assume that they've stayed on it)  \n",
    "    b) right now, let's drop a few columns - rxNDC is apparently a \"NATIONAL DRUG CODE (IMPUTED)\"; this might initially seem useful, but it actually isn't because there are multiple codes for many drugs    \n",
    "    \n",
    "Let's also drop `rxStartMonth` - we could use this and rxStartYear to build a more standardized datetime scheme (ignoring that months are missing very frequently), but for now let's just use year; year could be useful - lets us control for differing prescriptions used to treat diseases as medicine progresses.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cols found to drop.\n",
      "No cols found to drop.\n",
      "\n",
      "\n",
      " Summary of data: \n",
      "\n",
      "\n",
      "Preview: \n",
      "         id  age     sex      race        married highBPDiagnosed  \\\n",
      "0  10007101   28    Male     White        MARRIED             Yes   \n",
      "1  10007102   25  Female     White        MARRIED              No   \n",
      "4  10008101   51    Male  Multiple        MARRIED              No   \n",
      "5  10008102   53  Female     Asian        MARRIED              No   \n",
      "7  10009101   61  Female     Black  NEVER MARRIED             Yes   \n",
      "\n",
      "  diabetesDiagnosed chdDiagnosed miDiagnosed anginaDiagnosed strokeDiagnosed  \\\n",
      "0                No           No          No              No              No   \n",
      "1                No           No          No              No              No   \n",
      "4                No           No          No              No              No   \n",
      "5                No           No          No              No              No   \n",
      "7                No           No          No              No              No   \n",
      "\n",
      "  emphysemaDiagnosed asthmaDiagnosed otherHDDiagnosed heartFailureDiagnosed  \n",
      "0                 No              No               No                    No  \n",
      "1                 No             Yes               No                    No  \n",
      "4                 No              No               No                    No  \n",
      "5                 No              No               No                    No  \n",
      "7                 No              No               No                    No  \n",
      "\n",
      "\n",
      " Stats: \n",
      "                 id           age\n",
      "count  4.426600e+04  44266.000000\n",
      "mean   5.512156e+07     44.062667\n",
      "std    2.755210e+07     18.037354\n",
      "min    1.000710e+07     16.000000\n",
      "25%    4.040310e+07     29.000000\n",
      "50%    4.949510e+07     43.000000\n",
      "75%    8.143210e+07     57.000000\n",
      "max    8.968810e+07     85.000000\n",
      "\n",
      "\n",
      "\n",
      "Preview: \n",
      "           id  rxStartYear                          rxName  rxQuantity rxForm\n",
      "0  10007104.0       2011.0                     AMOXICILLIN        75.0   SUSR\n",
      "1  10007104.0       2011.0              OTIC EDGE SOLUTION        14.0    SOL\n",
      "2  10008102.0       2011.0  NASAL DECONGESTANT 0.05% SPRAY        15.0    SPR\n",
      "4  10008102.0       2011.0                    DIPHENHYDRAM        30.0    CAP\n",
      "5  10008102.0       2011.0                    CHLD ALLERGY       100.0   LIQD\n",
      "\n",
      "\n",
      " Stats: \n",
      "                 id    rxStartYear     rxQuantity\n",
      "count  1.966740e+05  196674.000000  196674.000000\n",
      "mean   5.500321e+07    2006.451618      62.511634\n",
      "std    2.709755e+07       5.427340     464.765955\n",
      "min    2.005437e+03    1940.000000      -9.000000\n",
      "25%    4.080210e+07    2006.000000      21.000000\n",
      "50%    4.907110e+07    2008.000000      30.000000\n",
      "75%    8.126610e+07    2009.000000      63.000000\n",
      "max    8.968810e+07    2011.000000  120000.000000\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define a simple drop function.\n",
    "def drop_cols(df, cols):\n",
    "    # Find which cols in requested list are present.\n",
    "    cols_drop = list(set(df.columns) & set(cols))\n",
    "    if not cols_drop:\n",
    "        print('No cols found to drop.')\n",
    "    else:\n",
    "        # Inplace to avoid namespace/scope issues.\n",
    "        df.drop(cols, axis='columns', inplace=True)\n",
    "        \n",
    "# Drop fields mentioned above.\n",
    "drop_cols(subjects,['Unnamed: 0', 'panel','pooledWeight'])\n",
    "drop_cols(meds,['Unnamed: 0', 'rxNDC','rxStartMonth'])\n",
    "\n",
    "# Drop individuals younger than 16.\n",
    "younglings = subjects[subjects.age < 16].index\n",
    "try: subjects.drop(younglings, axis=0, inplace=True)\n",
    "except ValueError: print('Already dropped underage subjects.')\n",
    "\n",
    "# Impute mean prescription year for prescriptions with invalid years (e.g -8).  \n",
    "valid_by_year = meds[meds.rxStartYear > 1900]\n",
    "avg_rx_year = valid_by_year.rxStartYear.mean()\n",
    "# Apply that value to prescriptions with invalid years.  \n",
    "meds.loc[meds.rxStartYear < 1900] = avg_rx_year\n",
    "\n",
    "meds.drop_duplicates(subset = ['id','rxName'], inplace=True)\n",
    "\n",
    "display_summary([subjects,meds])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### JOIN\n",
    "\n",
    "I'm going to inner join, so we keep all prescriptions for people who we have demographic info.  \n",
    "It would also be reasonable to left join so that we keep info on all people even if they don't have any prescriptions. I went ahead and also tried a left join, and it only affected the number of subjects pretty marginally (by <10%)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cols before merge:\n",
      "['id' 'age' 'sex' 'race' 'married' 'highBPDiagnosed' 'diabetesDiagnosed'\n",
      " 'chdDiagnosed' 'miDiagnosed' 'anginaDiagnosed' 'strokeDiagnosed'\n",
      " 'emphysemaDiagnosed' 'asthmaDiagnosed' 'otherHDDiagnosed'\n",
      " 'heartFailureDiagnosed']\n",
      "['id' 'rxStartYear' 'rxName' 'rxQuantity' 'rxForm']\n",
      "Cols after merge:\n",
      "['id' 'age' 'sex' 'race' 'married' 'highBPDiagnosed' 'diabetesDiagnosed'\n",
      " 'chdDiagnosed' 'miDiagnosed' 'anginaDiagnosed' 'strokeDiagnosed'\n",
      " 'emphysemaDiagnosed' 'asthmaDiagnosed' 'otherHDDiagnosed'\n",
      " 'heartFailureDiagnosed' 'rxStartYear' 'rxName' 'rxQuantity' 'rxForm']\n",
      "(169868, 19)\n"
     ]
    }
   ],
   "source": [
    "subj_and_meds = pd.merge(subjects, meds, how='inner', on='id', sort=True)\n",
    "print('Cols before merge:')\n",
    "print(subjects.columns.values)\n",
    "print(meds.columns.values)\n",
    "print('Cols after merge:')\n",
    "print(subj_and_meds.columns.values)\n",
    "print(subj_and_meds.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Visually inspect result of JOIN to make sure it worked as expected.\n",
    "# subj_and_meds.to_csv(\"joined_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variable Encoding  \n",
    "\n",
    "We currently don't have much of our info in an easily-interpretable form for our model(s) - we'll want to re-encode a whole bunch of categorial variables -  \n",
    "\n",
    "1) We need to turn our sex column and diagnoses into a boolean value - e.g. \"isFemale\"   \n",
    "2) We need to one-hot encode race and married. (If we were ignoring logisitic regression and its kin, factorizing with e.g. pd.factorize() would also work and would result in a slightly smaller memory footprint and faster model training for tree-based models.)  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "isFemale already created. Skipping.\n",
      "No cols found to drop.\n",
      "Example of diagnosis col before value correction:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: diabetesDiagnosed, dtype: bool\n",
      "\n",
      " Example of diagnosis col after value correction:\n",
      "0    False\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: diabetesDiagnosed, dtype: bool\n",
      "\n",
      " Cols incl. newly-created bools:\n",
      "Index([u'id', u'age', u'highBPDiagnosed', u'diabetesDiagnosed',\n",
      "       u'chdDiagnosed', u'miDiagnosed', u'anginaDiagnosed', u'strokeDiagnosed',\n",
      "       u'emphysemaDiagnosed', u'asthmaDiagnosed', u'otherHDDiagnosed',\n",
      "       u'heartFailureDiagnosed', u'rxStartYear', u'rxName', u'rxQuantity',\n",
      "       u'rxForm', u'isFemale', u'd__Amer Indian/Alaska Native', u'd__Asian',\n",
      "       u'd__Black', u'd__Multiple', u'd__Native Hawaiian/Pacific Islander',\n",
      "       u'd__White', u'd__DIVORCED', u'd__DIVORCED IN ROUND', u'd__MARRIED',\n",
      "       u'd__MARRIED IN ROUND', u'd__NEVER MARRIED', u'd__SEPARATED',\n",
      "       u'd__SEPARATED IN ROUND', u'd__WIDOWED', u'd__WIDOWED IN ROUND'],\n",
      "      dtype='object')\n",
      "Couldn't find dummy sources - likely already created.\n",
      "Columns including one-hot encoded cols: \n",
      "Index([u'id', u'age', u'highBPDiagnosed', u'diabetesDiagnosed',\n",
      "       u'chdDiagnosed', u'miDiagnosed', u'anginaDiagnosed', u'strokeDiagnosed',\n",
      "       u'emphysemaDiagnosed', u'asthmaDiagnosed', u'otherHDDiagnosed',\n",
      "       u'heartFailureDiagnosed', u'rxStartYear', u'rxName', u'rxQuantity',\n",
      "       u'rxForm', u'isFemale', u'd__Amer Indian/Alaska Native', u'd__Asian',\n",
      "       u'd__Black', u'd__Multiple', u'd__Native Hawaiian/Pacific Islander',\n",
      "       u'd__White', u'd__DIVORCED', u'd__DIVORCED IN ROUND', u'd__MARRIED',\n",
      "       u'd__MARRIED IN ROUND', u'd__NEVER MARRIED', u'd__SEPARATED',\n",
      "       u'd__SEPARATED IN ROUND', u'd__WIDOWED', u'd__WIDOWED IN ROUND'],\n",
      "      dtype='object')\n",
      "\n",
      "\n",
      " Now including dummies: \n",
      "\n",
      "\n",
      "No cols found to drop.\n",
      "Index([u'id', u'age', u'highBPDiagnosed', u'diabetesDiagnosed',\n",
      "       u'chdDiagnosed', u'miDiagnosed', u'anginaDiagnosed', u'strokeDiagnosed',\n",
      "       u'emphysemaDiagnosed', u'asthmaDiagnosed', u'otherHDDiagnosed',\n",
      "       u'heartFailureDiagnosed', u'rxStartYear', u'rxName', u'rxQuantity',\n",
      "       u'rxForm', u'isFemale', u'd__Amer Indian/Alaska Native', u'd__Asian',\n",
      "       u'd__Black', u'd__Multiple', u'd__Native Hawaiian/Pacific Islander',\n",
      "       u'd__White', u'd__DIVORCED', u'd__DIVORCED IN ROUND', u'd__MARRIED',\n",
      "       u'd__MARRIED IN ROUND', u'd__NEVER MARRIED', u'd__SEPARATED',\n",
      "       u'd__SEPARATED IN ROUND', u'd__WIDOWED', u'd__WIDOWED IN ROUND'],\n",
      "      dtype='object')\n",
      "         id  age  highBPDiagnosed  diabetesDiagnosed  chdDiagnosed  \\\n",
      "0  10007101   28             True              False         False   \n",
      "1  10007101   28             True              False         False   \n",
      "2  10007102   25            False              False         False   \n",
      "\n",
      "   miDiagnosed  anginaDiagnosed  strokeDiagnosed  emphysemaDiagnosed  \\\n",
      "0        False            False            False               False   \n",
      "1        False            False            False               False   \n",
      "2        False            False            False               False   \n",
      "\n",
      "   asthmaDiagnosed  otherHDDiagnosed  heartFailureDiagnosed  rxStartYear  \\\n",
      "0            False             False                  False       2005.0   \n",
      "1            False             False                  False       2010.0   \n",
      "2             True             False                  False       2009.0   \n",
      "\n",
      "         rxName  rxQuantity rxForm  isFemale  d__Amer Indian/Alaska Native  \\\n",
      "0      ATENOLOL        30.0   TABS     False                             0   \n",
      "1  AZITHROMYCIN        30.0   SUSR     False                             0   \n",
      "2      TREXIMET        18.0   TABS      True                             0   \n",
      "\n",
      "   d__Asian  d__Black  d__Multiple  d__Native Hawaiian/Pacific Islander  \\\n",
      "0         0         0            0                                    0   \n",
      "1         0         0            0                                    0   \n",
      "2         0         0            0                                    0   \n",
      "\n",
      "   d__White  d__DIVORCED  d__DIVORCED IN ROUND  d__MARRIED  \\\n",
      "0         1            0                     0           1   \n",
      "1         1            0                     0           1   \n",
      "2         1            0                     0           1   \n",
      "\n",
      "   d__MARRIED IN ROUND  d__NEVER MARRIED  d__SEPARATED  d__SEPARATED IN ROUND  \\\n",
      "0                    0                 0             0                      0   \n",
      "1                    0                 0             0                      0   \n",
      "2                    0                 0             0                      0   \n",
      "\n",
      "   d__WIDOWED  d__WIDOWED IN ROUND  \n",
      "0           0                    0  \n",
      "1           0                    0  \n",
      "2           0                    0  \n"
     ]
    }
   ],
   "source": [
    "# Start with re-encoding sex.\n",
    "\n",
    "try: subj_and_meds['isFemale'] = subj_and_meds.sex == \"Female\"\n",
    "except AttributeError: print(\"isFemale already created. Skipping.\")\n",
    "drop_cols(subj_and_meds, ['sex'])\n",
    "\n",
    "print('Example of diagnosis col before value correction:')\n",
    "print(subj_and_meds.diabetesDiagnosed.iloc[:5])\n",
    "\n",
    "# Now we'll re-encode all the diagnoses.\n",
    "# or == True so I can run this code multiple times without getting glitches\n",
    "# (Don't want to force you to restart the notebook if you run a cell twice.)\n",
    "yn_to_bool = lambda value: value == \"Yes\" or value == True \n",
    "diagnoses = ['highBPDiagnosed', 'diabetesDiagnosed', 'chdDiagnosed', 'miDiagnosed', 'anginaDiagnosed',\n",
    "             'strokeDiagnosed', 'emphysemaDiagnosed', 'asthmaDiagnosed', 'otherHDDiagnosed', 'heartFailureDiagnosed']\n",
    "# for diagnosis in diagnoses:\n",
    "#     subj_and_meds[diagnosis] = subj_and_meds[diagnosis].apply(yn_to_bool)\n",
    "subj_and_meds[diagnoses] = subj_and_meds[diagnoses].applymap(yn_to_bool)\n",
    "\n",
    "print('\\n Example of diagnosis col after value correction:')\n",
    "print(subj_and_meds.diabetesDiagnosed.iloc[:5])\n",
    "    \n",
    "print('\\n Cols incl. newly-created bools:')\n",
    "print(subj_and_meds.columns)\n",
    "\n",
    "\n",
    "# For the sake of code cleanliness, I'll create both sets here, but you could argue that \n",
    "# I should create them separately to have more descriptive variable names (e.g. \"race_\"\n",
    "# and \"marital_\" prefixes rather than \"d_\")\n",
    "try: \n",
    "    subj_and_meds = pd.get_dummies(subj_and_meds, columns = ['race', 'married'], prefix='d_')\n",
    "except ValueError: \n",
    "    print(\"Couldn't find dummy sources - likely already created.\")\n",
    "print('Columns including one-hot encoded cols: ')\n",
    "print(subj_and_meds.columns)\n",
    "\n",
    "\n",
    "print(\"\\n\\n Now including dummies: \\n\\n\")\n",
    "drop_cols(subj_and_meds, ['race', 'married'])\n",
    "print(subj_and_meds.columns)\n",
    "print(subj_and_meds.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# visually inspect result of concat above to make sure it worked as expected\n",
    "# subj_and_meds.to_csv(\"with_dummies.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I noticed that we have categories that we might want to merge - e.g. \"widowed in round\" is pretty rare and should, perhaps, be merged into \"widowed.\"  \n",
    "One other caveat - we have no default for our dummy variables, which will cause multicollinearity issues with regression models - we should fix this later if we want to use them.\n",
    "\n",
    "## Let's actually do some analyses :)\n",
    "\n",
    "#### 1) What are the most common medications for each disease?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      " For diagnosis highBPDiagnosed, most common prescription is: \n",
      "\n",
      "count          93623\n",
      "unique          5650\n",
      "top       LISINOPRIL\n",
      "freq            2476\n",
      "Name: rxName, dtype: object\n",
      "\n",
      "\n",
      " For diagnosis diabetesDiagnosed, most common prescription is: \n",
      "\n",
      "count         40116\n",
      "unique         3823\n",
      "top       METFORMIN\n",
      "freq           1158\n",
      "Name: rxName, dtype: object\n",
      "\n",
      "\n",
      " For diagnosis chdDiagnosed, most common prescription is: \n",
      "\n",
      "count          22039\n",
      "unique          2867\n",
      "top       LISINOPRIL\n",
      "freq             466\n",
      "Name: rxName, dtype: object\n",
      "\n",
      "\n",
      " For diagnosis miDiagnosed, most common prescription is: \n",
      "\n",
      "count          14725\n",
      "unique          2333\n",
      "top       LISINOPRIL\n",
      "freq             339\n",
      "Name: rxName, dtype: object\n",
      "\n",
      "\n",
      " For diagnosis anginaDiagnosed, most common prescription is: \n",
      "\n",
      "count          11603\n",
      "unique          2164\n",
      "top       LISINOPRIL\n",
      "freq             194\n",
      "Name: rxName, dtype: object\n",
      "\n",
      "\n",
      " For diagnosis strokeDiagnosed, most common prescription is: \n",
      "\n",
      "count          14319\n",
      "unique          2464\n",
      "top       LISINOPRIL\n",
      "freq             283\n",
      "Name: rxName, dtype: object\n",
      "\n",
      "\n",
      " For diagnosis emphysemaDiagnosed, most common prescription is: \n",
      "\n",
      "count           9594\n",
      "unique          1997\n",
      "top       LISINOPRIL\n",
      "freq             145\n",
      "Name: rxName, dtype: object\n",
      "\n",
      "\n",
      " For diagnosis asthmaDiagnosed, most common prescription is: \n",
      "\n",
      "count         28376\n",
      "unique         3568\n",
      "top       ALBUTEROL\n",
      "freq            536\n",
      "Name: rxName, dtype: object\n",
      "\n",
      "\n",
      " For diagnosis otherHDDiagnosed, most common prescription is: \n",
      "\n",
      "count          31770\n",
      "unique          3715\n",
      "top       LISINOPRIL\n",
      "freq             584\n",
      "Name: rxName, dtype: object\n",
      "\n",
      "\n",
      " For diagnosis heartFailureDiagnosed, most common prescription is: \n",
      "\n",
      "count           4940\n",
      "unique          1350\n",
      "top       FUROSEMIDE\n",
      "freq             173\n",
      "Name: rxName, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# TODO: this could be expressed in a more efficient manner as a .groupby(), \n",
    "#   although I think the for may be more readable.\n",
    "# Also, you'd have to convert the one-hot-encoded diseases into a single categorical column, \n",
    "#   and handling individuals with multiple diseases would be a pain.\n",
    "\n",
    "for diagnosis in diagnoses:\n",
    "    current_diagnosis = subj_and_meds[subj_and_meds[diagnosis] == True]\n",
    "    print(\"\\n\\n For diagnosis %s, most common prescription is: \\n\" % diagnosis)\n",
    "    print(current_diagnosis['rxName'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gut check - lisinopril is an ACE inhibitor, and ACE inhibitors are a frontline treatment for hypertension. Metformin is a frontline treatment for type 2 diabetes (and type 2 is far more common than type 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2) Which medications are most indicative of each disease?\n",
    "\n",
    "Let's figure out which drug is the most specific for each disease. So I'll calculate:\n",
    "\n",
    "instances of drug for disease / instances of drug overall\n",
    "\n",
    "In other words, I'm getting the precision of a given drug in making a diagnosis for a given disease.\n",
    "\n",
    "One caveat: if we have drugs with exceedingly low counts - say one doctor has homeopathic leanings and prescribes a diabetic patient ginseng - it could seemingly be a perfect identifier by this metric. Instead, I'll only look at the drugs that are reasonably common - using exceedingly rare drugs to diagnoses common diseases seems like it would only be marginally useful, anyway. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of drugs extracted:\n",
      "100\n",
      "Most common drugs that we've extracted:\n",
      "         rxName  count\n",
      "0  AZITHROMYCIN   3358\n",
      "1    LISINOPRIL   2865\n",
      "2   AMOXICILLIN   2687\n",
      "3   SIMVASTATIN   2312\n",
      "4     IBUPROFEN   2243\n",
      "5    PREDNISONE   1712\n",
      "6  HYDROCO/APAP   1703\n",
      "7       LIPITOR   1630\n",
      "8    OMEPRAZOLE   1496\n",
      "9     METFORMIN   1422\n",
      "Least common drugs that we've extracted:\n",
      "                       rxName  count\n",
      "90                 LORATADINE    309\n",
      "91               ADVAIR DISKU    308\n",
      "92             APAP/OXYCODONE    306\n",
      "93                 DIOVAN HCT    303\n",
      "94                GLIMEPIRIDE    302\n",
      "95                 SMZ/TMP DS    302\n",
      "96               PENICILLN VK    294\n",
      "97      ACETAMINOPHEN/CODEINE    294\n",
      "98         PRAVASTATIN SODIUM    293\n",
      "99  SIMVASTATIN (FILM-COATED)    293\n"
     ]
    }
   ],
   "source": [
    "# We'll take our list of prescriptions, and get their counts.\n",
    "# All of our most common drugs per diagnosis above have high frequencies (>1000), \n",
    "#   but I'll go ahead and grab the top 100 to be safe.\n",
    "# Use counts as the index, so we have them sorted by descending frequency.\n",
    "# Using function-chaining syntax here. I find it pretty readable, but some people don't.\n",
    "drugs = (\n",
    "    subj_and_meds['rxName']\n",
    "        # Get value_counts() for drugs - it's sorted and descending by default, \n",
    "        # but I've specified them as kwargs for maximum explicitness.\n",
    "        .value_counts(sort=True, ascending=False)  \n",
    "        # Get the top 100 most-common.\n",
    "        .iloc[0:100]\n",
    "        .reset_index(drop=False)\n",
    ")\n",
    "\n",
    "# Fix column names.\n",
    "drugs.rename(columns={'index': 'rxName', 'rxName': 'count'}, inplace=True)\n",
    "\n",
    "# Confirm size of list.\n",
    "print('# of drugs extracted:')\n",
    "print(drugs.rxName.size)\n",
    "print('')\n",
    "# Confirm that our most common drugs are here, indexed by count.\n",
    "print(\"Most common drugs that we've extracted:\")\n",
    "print(drugs.head(10))\n",
    "print(\"Least common drugs that we've extracted:\")\n",
    "print(drugs.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'rxName': 'AZITHROMYCIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.3356164383561644}, {'rxName': 'AZITHROMYCIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.09767718880285885}, {'rxName': 'AZITHROMYCIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.0604526503871352}, {'rxName': 'AZITHROMYCIN', 'diagnosis': 'miDiagnosed', 'precision': 0.0357355568790947}, {'rxName': 'AZITHROMYCIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.033948779035139966}, {'rxName': 'AZITHROMYCIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.034544371649791544}, {'rxName': 'AZITHROMYCIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.034544371649791544}, {'rxName': 'AZITHROMYCIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.14740917212626564}, {'rxName': 'AZITHROMYCIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.11465157832042883}, {'rxName': 'AZITHROMYCIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.011911852293031567}, {'rxName': 'LISINOPRIL', 'diagnosis': 'highBPDiagnosed', 'precision': 0.8642233856893543}, {'rxName': 'LISINOPRIL', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.3403141361256545}, {'rxName': 'LISINOPRIL', 'diagnosis': 'chdDiagnosed', 'precision': 0.16265270506108204}, {'rxName': 'LISINOPRIL', 'diagnosis': 'miDiagnosed', 'precision': 0.11832460732984293}, {'rxName': 'LISINOPRIL', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06771378708551483}, {'rxName': 'LISINOPRIL', 'diagnosis': 'strokeDiagnosed', 'precision': 0.09877835951134381}, {'rxName': 'LISINOPRIL', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.0506108202443281}, {'rxName': 'LISINOPRIL', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.12076788830715532}, {'rxName': 'LISINOPRIL', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.20383944153577663}, {'rxName': 'LISINOPRIL', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.03769633507853403}, {'rxName': 'AMOXICILLIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.30777819129140305}, {'rxName': 'AMOXICILLIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.09304056568663938}, {'rxName': 'AMOXICILLIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.05321920357275772}, {'rxName': 'AMOXICILLIN', 'diagnosis': 'miDiagnosed', 'precision': 0.03312244138444362}, {'rxName': 'AMOXICILLIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.02791216970599181}, {'rxName': 'AMOXICILLIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.03312244138444362}, {'rxName': 'AMOXICILLIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.018608113137327874}, {'rxName': 'AMOXICILLIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.12765165612206922}, {'rxName': 'AMOXICILLIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1146259769259397}, {'rxName': 'AMOXICILLIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.00893189430591738}, {'rxName': 'SIMVASTATIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.6812283737024222}, {'rxName': 'SIMVASTATIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.3032006920415225}, {'rxName': 'SIMVASTATIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.1855536332179931}, {'rxName': 'SIMVASTATIN', 'diagnosis': 'miDiagnosed', 'precision': 0.12716262975778547}, {'rxName': 'SIMVASTATIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.08131487889273356}, {'rxName': 'SIMVASTATIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.11418685121107267}, {'rxName': 'SIMVASTATIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.050173010380622836}, {'rxName': 'SIMVASTATIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.11072664359861592}, {'rxName': 'SIMVASTATIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.2041522491349481}, {'rxName': 'SIMVASTATIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.024653979238754325}, {'rxName': 'IBUPROFEN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.30494872938029427}, {'rxName': 'IBUPROFEN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.09585376727596968}, {'rxName': 'IBUPROFEN', 'diagnosis': 'chdDiagnosed', 'precision': 0.032545697726259475}, {'rxName': 'IBUPROFEN', 'diagnosis': 'miDiagnosed', 'precision': 0.021845742309407043}, {'rxName': 'IBUPROFEN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.022737405260811413}, {'rxName': 'IBUPROFEN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.030762371823450735}, {'rxName': 'IBUPROFEN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.018724921979491754}, {'rxName': 'IBUPROFEN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.132857779759251}, {'rxName': 'IBUPROFEN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.08470798038341507}, {'rxName': 'IBUPROFEN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.0057958091841284}, {'rxName': 'PREDNISONE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.4328271028037383}, {'rxName': 'PREDNISONE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.11740654205607477}, {'rxName': 'PREDNISONE', 'diagnosis': 'chdDiagnosed', 'precision': 0.08294392523364486}, {'rxName': 'PREDNISONE', 'diagnosis': 'miDiagnosed', 'precision': 0.0630841121495327}, {'rxName': 'PREDNISONE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.04789719626168224}, {'rxName': 'PREDNISONE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.05957943925233645}, {'rxName': 'PREDNISONE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.07768691588785047}, {'rxName': 'PREDNISONE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.25817757009345793}, {'rxName': 'PREDNISONE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.16121495327102803}, {'rxName': 'PREDNISONE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.02102803738317757}, {'rxName': 'HYDROCO/APAP', 'diagnosis': 'highBPDiagnosed', 'precision': 0.44333529066353494}, {'rxName': 'HYDROCO/APAP', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.14386376981796828}, {'rxName': 'HYDROCO/APAP', 'diagnosis': 'chdDiagnosed', 'precision': 0.07046388725778038}, {'rxName': 'HYDROCO/APAP', 'diagnosis': 'miDiagnosed', 'precision': 0.0540223135642983}, {'rxName': 'HYDROCO/APAP', 'diagnosis': 'anginaDiagnosed', 'precision': 0.046975924838520255}, {'rxName': 'HYDROCO/APAP', 'diagnosis': 'strokeDiagnosed', 'precision': 0.06341749853200235}, {'rxName': 'HYDROCO/APAP', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05108631826189078}, {'rxName': 'HYDROCO/APAP', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.16147974163241338}, {'rxName': 'HYDROCO/APAP', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1473869641808573}, {'rxName': 'HYDROCO/APAP', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.011743981209630064}, {'rxName': 'LIPITOR', 'diagnosis': 'highBPDiagnosed', 'precision': 0.6809815950920245}, {'rxName': 'LIPITOR', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.3177914110429448}, {'rxName': 'LIPITOR', 'diagnosis': 'chdDiagnosed', 'precision': 0.21533742331288344}, {'rxName': 'LIPITOR', 'diagnosis': 'miDiagnosed', 'precision': 0.1374233128834356}, {'rxName': 'LIPITOR', 'diagnosis': 'anginaDiagnosed', 'precision': 0.09815950920245399}, {'rxName': 'LIPITOR', 'diagnosis': 'strokeDiagnosed', 'precision': 0.09141104294478528}, {'rxName': 'LIPITOR', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.046012269938650305}, {'rxName': 'LIPITOR', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.11042944785276074}, {'rxName': 'LIPITOR', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.22576687116564417}, {'rxName': 'LIPITOR', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.029447852760736196}, {'rxName': 'OMEPRAZOLE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.6062834224598931}, {'rxName': 'OMEPRAZOLE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.21056149732620322}, {'rxName': 'OMEPRAZOLE', 'diagnosis': 'chdDiagnosed', 'precision': 0.13101604278074866}, {'rxName': 'OMEPRAZOLE', 'diagnosis': 'miDiagnosed', 'precision': 0.09959893048128342}, {'rxName': 'OMEPRAZOLE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.09425133689839572}, {'rxName': 'OMEPRAZOLE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.08957219251336898}, {'rxName': 'OMEPRAZOLE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.07352941176470588}, {'rxName': 'OMEPRAZOLE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1751336898395722}, {'rxName': 'OMEPRAZOLE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.2072192513368984}, {'rxName': 'OMEPRAZOLE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.027406417112299464}, {'rxName': 'METFORMIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7060478199718706}, {'rxName': 'METFORMIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.8143459915611815}, {'rxName': 'METFORMIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.12658227848101267}, {'rxName': 'METFORMIN', 'diagnosis': 'miDiagnosed', 'precision': 0.0850914205344585}, {'rxName': 'METFORMIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06610407876230662}, {'rxName': 'METFORMIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.07383966244725738}, {'rxName': 'METFORMIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.040787623066104076}, {'rxName': 'METFORMIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.14064697609001406}, {'rxName': 'METFORMIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.16385372714486637}, {'rxName': 'METFORMIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.02180028129395218}, {'rxName': 'HYDROCHLOROTHIAZIDE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.9032006245120999}, {'rxName': 'HYDROCHLOROTHIAZIDE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.234192037470726}, {'rxName': 'HYDROCHLOROTHIAZIDE', 'diagnosis': 'chdDiagnosed', 'precision': 0.10616705698672912}, {'rxName': 'HYDROCHLOROTHIAZIDE', 'diagnosis': 'miDiagnosed', 'precision': 0.0741608118657299}, {'rxName': 'HYDROCHLOROTHIAZIDE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.05776736924277908}, {'rxName': 'HYDROCHLOROTHIAZIDE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.10070257611241218}, {'rxName': 'HYDROCHLOROTHIAZIDE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.03747072599531616}, {'rxName': 'HYDROCHLOROTHIAZIDE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.12724434035909446}, {'rxName': 'HYDROCHLOROTHIAZIDE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.17096018735362997}, {'rxName': 'HYDROCHLOROTHIAZIDE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.0195160031225605}, {'rxName': 'NAPROXEN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.40984974958263776}, {'rxName': 'NAPROXEN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.11018363939899833}, {'rxName': 'NAPROXEN', 'diagnosis': 'chdDiagnosed', 'precision': 0.03672787979966611}, {'rxName': 'NAPROXEN', 'diagnosis': 'miDiagnosed', 'precision': 0.020868113522537562}, {'rxName': 'NAPROXEN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.02671118530884808}, {'rxName': 'NAPROXEN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.034223706176961605}, {'rxName': 'NAPROXEN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.02587646076794658}, {'rxName': 'NAPROXEN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.12520868113522537}, {'rxName': 'NAPROXEN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.10517529215358931}, {'rxName': 'NAPROXEN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.005843071786310518}, {'rxName': 'ATENOLOL', 'diagnosis': 'highBPDiagnosed', 'precision': 0.8793103448275862}, {'rxName': 'ATENOLOL', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.19782214156079855}, {'rxName': 'ATENOLOL', 'diagnosis': 'chdDiagnosed', 'precision': 0.19509981851179672}, {'rxName': 'ATENOLOL', 'diagnosis': 'miDiagnosed', 'precision': 0.11705989110707804}, {'rxName': 'ATENOLOL', 'diagnosis': 'anginaDiagnosed', 'precision': 0.11161524500907441}, {'rxName': 'ATENOLOL', 'diagnosis': 'strokeDiagnosed', 'precision': 0.10617059891107078}, {'rxName': 'ATENOLOL', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.043557168784029036}, {'rxName': 'ATENOLOL', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.08983666061705989}, {'rxName': 'ATENOLOL', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.2676950998185118}, {'rxName': 'ATENOLOL', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.023593466424682397}, {'rxName': 'FUROSEMIDE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.8188539741219963}, {'rxName': 'FUROSEMIDE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.41312384473197783}, {'rxName': 'FUROSEMIDE', 'diagnosis': 'chdDiagnosed', 'precision': 0.3659889094269871}, {'rxName': 'FUROSEMIDE', 'diagnosis': 'miDiagnosed', 'precision': 0.24584103512014788}, {'rxName': 'FUROSEMIDE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.15804066543438078}, {'rxName': 'FUROSEMIDE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.1987060998151571}, {'rxName': 'FUROSEMIDE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.10813308687615526}, {'rxName': 'FUROSEMIDE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.17652495378927913}, {'rxName': 'FUROSEMIDE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.42606284658040666}, {'rxName': 'FUROSEMIDE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.1598890942698706}, {'rxName': 'LEVOTHYROXIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5324947589098532}, {'rxName': 'LEVOTHYROXIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.19077568134171907}, {'rxName': 'LEVOTHYROXIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.11215932914046121}, {'rxName': 'LEVOTHYROXIN', 'diagnosis': 'miDiagnosed', 'precision': 0.07547169811320754}, {'rxName': 'LEVOTHYROXIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.05660377358490566}, {'rxName': 'LEVOTHYROXIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.08176100628930817}, {'rxName': 'LEVOTHYROXIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.03459119496855346}, {'rxName': 'LEVOTHYROXIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1278825995807128}, {'rxName': 'LEVOTHYROXIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1792452830188679}, {'rxName': 'LEVOTHYROXIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.0220125786163522}, {'rxName': 'APAP/HYDROCODONE BITARTRATE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.40168243953732913}, {'rxName': 'APAP/HYDROCODONE BITARTRATE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.12618296529968454}, {'rxName': 'APAP/HYDROCODONE BITARTRATE', 'diagnosis': 'chdDiagnosed', 'precision': 0.08412197686645637}, {'rxName': 'APAP/HYDROCODONE BITARTRATE', 'diagnosis': 'miDiagnosed', 'precision': 0.06203995793901157}, {'rxName': 'APAP/HYDROCODONE BITARTRATE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.03995793901156677}, {'rxName': 'APAP/HYDROCODONE BITARTRATE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.06414300736067298}, {'rxName': 'APAP/HYDROCODONE BITARTRATE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.0452155625657203}, {'rxName': 'APAP/HYDROCODONE BITARTRATE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.14300736067297581}, {'rxName': 'APAP/HYDROCODONE BITARTRATE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.14090431125131442}, {'rxName': 'APAP/HYDROCODONE BITARTRATE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.017875920084121977}, {'rxName': 'AMLODIPINE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.9418103448275862}, {'rxName': 'AMLODIPINE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.26185344827586204}, {'rxName': 'AMLODIPINE', 'diagnosis': 'chdDiagnosed', 'precision': 0.17025862068965517}, {'rxName': 'AMLODIPINE', 'diagnosis': 'miDiagnosed', 'precision': 0.10452586206896551}, {'rxName': 'AMLODIPINE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.08297413793103449}, {'rxName': 'AMLODIPINE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.1271551724137931}, {'rxName': 'AMLODIPINE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05818965517241379}, {'rxName': 'AMLODIPINE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.13469827586206898}, {'rxName': 'AMLODIPINE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.2252155172413793}, {'rxName': 'AMLODIPINE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.034482758620689655}, {'rxName': 'HYDROCHLOROT', 'diagnosis': 'highBPDiagnosed', 'precision': 0.9049295774647887}, {'rxName': 'HYDROCHLOROT', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.215962441314554}, {'rxName': 'HYDROCHLOROT', 'diagnosis': 'chdDiagnosed', 'precision': 0.09624413145539906}, {'rxName': 'HYDROCHLOROT', 'diagnosis': 'miDiagnosed', 'precision': 0.07746478873239436}, {'rxName': 'HYDROCHLOROT', 'diagnosis': 'anginaDiagnosed', 'precision': 0.057511737089201875}, {'rxName': 'HYDROCHLOROT', 'diagnosis': 'strokeDiagnosed', 'precision': 0.0880281690140845}, {'rxName': 'HYDROCHLOROT', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.029342723004694836}, {'rxName': 'HYDROCHLOROT', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.14553990610328638}, {'rxName': 'HYDROCHLOROT', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.17488262910798122}, {'rxName': 'HYDROCHLOROT', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.018779342723004695}, {'rxName': 'AMLODIPINE BESYLATE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.9483173076923077}, {'rxName': 'AMLODIPINE BESYLATE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.26322115384615385}, {'rxName': 'AMLODIPINE BESYLATE', 'diagnosis': 'chdDiagnosed', 'precision': 0.20432692307692307}, {'rxName': 'AMLODIPINE BESYLATE', 'diagnosis': 'miDiagnosed', 'precision': 0.1310096153846154}, {'rxName': 'AMLODIPINE BESYLATE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.10096153846153846}, {'rxName': 'AMLODIPINE BESYLATE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.12980769230769232}, {'rxName': 'AMLODIPINE BESYLATE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04447115384615385}, {'rxName': 'AMLODIPINE BESYLATE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1141826923076923}, {'rxName': 'AMLODIPINE BESYLATE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.24278846153846154}, {'rxName': 'AMLODIPINE BESYLATE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.039663461538461536}, {'rxName': 'NEXIUM', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5500603136308806}, {'rxName': 'NEXIUM', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.18335343787696018}, {'rxName': 'NEXIUM', 'diagnosis': 'chdDiagnosed', 'precision': 0.12545235223160434}, {'rxName': 'NEXIUM', 'diagnosis': 'miDiagnosed', 'precision': 0.05790108564535585}, {'rxName': 'NEXIUM', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06513872135102533}, {'rxName': 'NEXIUM', 'diagnosis': 'strokeDiagnosed', 'precision': 0.07840772014475271}, {'rxName': 'NEXIUM', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05548854041013269}, {'rxName': 'NEXIUM', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.16767189384800965}, {'rxName': 'NEXIUM', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.18576598311218334}, {'rxName': 'NEXIUM', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.033775633293124246}, {'rxName': 'ACETAMINOPHEN-HYDROCODONE BITARTRATE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.44430844553243576}, {'rxName': 'ACETAMINOPHEN-HYDROCODONE BITARTRATE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1591187270501836}, {'rxName': 'ACETAMINOPHEN-HYDROCODONE BITARTRATE', 'diagnosis': 'chdDiagnosed', 'precision': 0.07466340269277846}, {'rxName': 'ACETAMINOPHEN-HYDROCODONE BITARTRATE', 'diagnosis': 'miDiagnosed', 'precision': 0.07221542227662178}, {'rxName': 'ACETAMINOPHEN-HYDROCODONE BITARTRATE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.04895960832313342}, {'rxName': 'ACETAMINOPHEN-HYDROCODONE BITARTRATE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.06976744186046512}, {'rxName': 'ACETAMINOPHEN-HYDROCODONE BITARTRATE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.046511627906976744}, {'rxName': 'ACETAMINOPHEN-HYDROCODONE BITARTRATE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.15667074663402691}, {'rxName': 'ACETAMINOPHEN-HYDROCODONE BITARTRATE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.12362301101591187}, {'rxName': 'ACETAMINOPHEN-HYDROCODONE BITARTRATE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.01835985312117503}, {'rxName': 'CRESTOR', 'diagnosis': 'highBPDiagnosed', 'precision': 0.6674846625766871}, {'rxName': 'CRESTOR', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.2748466257668712}, {'rxName': 'CRESTOR', 'diagnosis': 'chdDiagnosed', 'precision': 0.22699386503067484}, {'rxName': 'CRESTOR', 'diagnosis': 'miDiagnosed', 'precision': 0.15337423312883436}, {'rxName': 'CRESTOR', 'diagnosis': 'anginaDiagnosed', 'precision': 0.09325153374233129}, {'rxName': 'CRESTOR', 'diagnosis': 'strokeDiagnosed', 'precision': 0.09570552147239264}, {'rxName': 'CRESTOR', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04171779141104295}, {'rxName': 'CRESTOR', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1116564417177914}, {'rxName': 'CRESTOR', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.21717791411042944}, {'rxName': 'CRESTOR', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.024539877300613498}, {'rxName': 'CEPHALEXIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.39146800501882056}, {'rxName': 'CEPHALEXIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.14052697616060225}, {'rxName': 'CEPHALEXIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.07528230865746549}, {'rxName': 'CEPHALEXIN', 'diagnosis': 'miDiagnosed', 'precision': 0.04767879548306148}, {'rxName': 'CEPHALEXIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.03262233375156838}, {'rxName': 'CEPHALEXIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.06398996235884567}, {'rxName': 'CEPHALEXIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.03638644918444166}, {'rxName': 'CEPHALEXIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.12170639899623588}, {'rxName': 'CEPHALEXIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1329987452948557}, {'rxName': 'CEPHALEXIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.020075282308657464}, {'rxName': 'ALBUTEROL', 'diagnosis': 'highBPDiagnosed', 'precision': 0.4396984924623116}, {'rxName': 'ALBUTEROL', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.15326633165829145}, {'rxName': 'ALBUTEROL', 'diagnosis': 'chdDiagnosed', 'precision': 0.11055276381909548}, {'rxName': 'ALBUTEROL', 'diagnosis': 'miDiagnosed', 'precision': 0.08040201005025126}, {'rxName': 'ALBUTEROL', 'diagnosis': 'anginaDiagnosed', 'precision': 0.07035175879396985}, {'rxName': 'ALBUTEROL', 'diagnosis': 'strokeDiagnosed', 'precision': 0.09296482412060302}, {'rxName': 'ALBUTEROL', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.17336683417085427}, {'rxName': 'ALBUTEROL', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.6733668341708543}, {'rxName': 'ALBUTEROL', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.18969849246231155}, {'rxName': 'ALBUTEROL', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.03768844221105527}, {'rxName': 'LEVOTHYROXINE SODIUM', 'diagnosis': 'highBPDiagnosed', 'precision': 0.551948051948052}, {'rxName': 'LEVOTHYROXINE SODIUM', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.21168831168831168}, {'rxName': 'LEVOTHYROXINE SODIUM', 'diagnosis': 'chdDiagnosed', 'precision': 0.12597402597402596}, {'rxName': 'LEVOTHYROXINE SODIUM', 'diagnosis': 'miDiagnosed', 'precision': 0.08311688311688312}, {'rxName': 'LEVOTHYROXINE SODIUM', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06363636363636363}, {'rxName': 'LEVOTHYROXINE SODIUM', 'diagnosis': 'strokeDiagnosed', 'precision': 0.09350649350649351}, {'rxName': 'LEVOTHYROXINE SODIUM', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.045454545454545456}, {'rxName': 'LEVOTHYROXINE SODIUM', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.14675324675324675}, {'rxName': 'LEVOTHYROXINE SODIUM', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.19480519480519481}, {'rxName': 'LEVOTHYROXINE SODIUM', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.02857142857142857}, {'rxName': 'GABAPENTIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.6166883963494133}, {'rxName': 'GABAPENTIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.318122555410691}, {'rxName': 'GABAPENTIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.15645371577574968}, {'rxName': 'GABAPENTIN', 'diagnosis': 'miDiagnosed', 'precision': 0.11603650586701435}, {'rxName': 'GABAPENTIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.09126466753585398}, {'rxName': 'GABAPENTIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.11864406779661017}, {'rxName': 'GABAPENTIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.08865710560625815}, {'rxName': 'GABAPENTIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.17470664928292046}, {'rxName': 'GABAPENTIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.23598435462842243}, {'rxName': 'GABAPENTIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.03650586701434159}, {'rxName': 'SYNTHROID', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5058670143415906}, {'rxName': 'SYNTHROID', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.13559322033898305}, {'rxName': 'SYNTHROID', 'diagnosis': 'chdDiagnosed', 'precision': 0.12255541069100391}, {'rxName': 'SYNTHROID', 'diagnosis': 'miDiagnosed', 'precision': 0.07431551499348109}, {'rxName': 'SYNTHROID', 'diagnosis': 'anginaDiagnosed', 'precision': 0.0651890482398957}, {'rxName': 'SYNTHROID', 'diagnosis': 'strokeDiagnosed', 'precision': 0.06388526727509779}, {'rxName': 'SYNTHROID', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04041720990873533}, {'rxName': 'SYNTHROID', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1408083441981747}, {'rxName': 'SYNTHROID', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1981747066492829}, {'rxName': 'SYNTHROID', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.028683181225554105}, {'rxName': 'ALPRAZOLAM', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5136612021857924}, {'rxName': 'ALPRAZOLAM', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.15710382513661203}, {'rxName': 'ALPRAZOLAM', 'diagnosis': 'chdDiagnosed', 'precision': 0.10655737704918032}, {'rxName': 'ALPRAZOLAM', 'diagnosis': 'miDiagnosed', 'precision': 0.07650273224043716}, {'rxName': 'ALPRAZOLAM', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06693989071038252}, {'rxName': 'ALPRAZOLAM', 'diagnosis': 'strokeDiagnosed', 'precision': 0.08469945355191257}, {'rxName': 'ALPRAZOLAM', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.09016393442622951}, {'rxName': 'ALPRAZOLAM', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.18442622950819673}, {'rxName': 'ALPRAZOLAM', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.17486338797814208}, {'rxName': 'ALPRAZOLAM', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.028688524590163935}, {'rxName': 'VICODIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.3058984910836763}, {'rxName': 'VICODIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.09190672153635117}, {'rxName': 'VICODIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.04252400548696845}, {'rxName': 'VICODIN', 'diagnosis': 'miDiagnosed', 'precision': 0.03292181069958848}, {'rxName': 'VICODIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.02606310013717421}, {'rxName': 'VICODIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.03292181069958848}, {'rxName': 'VICODIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.023319615912208505}, {'rxName': 'VICODIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.15637860082304528}, {'rxName': 'VICODIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.09739368998628258}, {'rxName': 'VICODIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.0027434842249657062}, {'rxName': 'TRAMADOL HCL', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5513888888888889}, {'rxName': 'TRAMADOL HCL', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.19305555555555556}, {'rxName': 'TRAMADOL HCL', 'diagnosis': 'chdDiagnosed', 'precision': 0.09305555555555556}, {'rxName': 'TRAMADOL HCL', 'diagnosis': 'miDiagnosed', 'precision': 0.05694444444444444}, {'rxName': 'TRAMADOL HCL', 'diagnosis': 'anginaDiagnosed', 'precision': 0.059722222222222225}, {'rxName': 'TRAMADOL HCL', 'diagnosis': 'strokeDiagnosed', 'precision': 0.0875}, {'rxName': 'TRAMADOL HCL', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04861111111111111}, {'rxName': 'TRAMADOL HCL', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.18611111111111112}, {'rxName': 'TRAMADOL HCL', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.17777777777777778}, {'rxName': 'TRAMADOL HCL', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.02361111111111111}, {'rxName': 'LEXAPRO', 'diagnosis': 'highBPDiagnosed', 'precision': 0.4042253521126761}, {'rxName': 'LEXAPRO', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.13661971830985917}, {'rxName': 'LEXAPRO', 'diagnosis': 'chdDiagnosed', 'precision': 0.08873239436619719}, {'rxName': 'LEXAPRO', 'diagnosis': 'miDiagnosed', 'precision': 0.05211267605633803}, {'rxName': 'LEXAPRO', 'diagnosis': 'anginaDiagnosed', 'precision': 0.04647887323943662}, {'rxName': 'LEXAPRO', 'diagnosis': 'strokeDiagnosed', 'precision': 0.0676056338028169}, {'rxName': 'LEXAPRO', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04507042253521127}, {'rxName': 'LEXAPRO', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.16056338028169015}, {'rxName': 'LEXAPRO', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.15211267605633802}, {'rxName': 'LEXAPRO', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.015492957746478873}, {'rxName': 'PROAIR HFA', 'diagnosis': 'highBPDiagnosed', 'precision': 0.47007299270072994}, {'rxName': 'PROAIR HFA', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.13138686131386862}, {'rxName': 'PROAIR HFA', 'diagnosis': 'chdDiagnosed', 'precision': 0.08467153284671533}, {'rxName': 'PROAIR HFA', 'diagnosis': 'miDiagnosed', 'precision': 0.06569343065693431}, {'rxName': 'PROAIR HFA', 'diagnosis': 'anginaDiagnosed', 'precision': 0.04525547445255475}, {'rxName': 'PROAIR HFA', 'diagnosis': 'strokeDiagnosed', 'precision': 0.06277372262773723}, {'rxName': 'PROAIR HFA', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.11970802919708029}, {'rxName': 'PROAIR HFA', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.6116788321167883}, {'rxName': 'PROAIR HFA', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.14014598540145987}, {'rxName': 'PROAIR HFA', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.02335766423357664}, {'rxName': 'PLAVIX', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7815533980582524}, {'rxName': 'PLAVIX', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.3883495145631068}, {'rxName': 'PLAVIX', 'diagnosis': 'chdDiagnosed', 'precision': 0.529126213592233}, {'rxName': 'PLAVIX', 'diagnosis': 'miDiagnosed', 'precision': 0.40129449838187703}, {'rxName': 'PLAVIX', 'diagnosis': 'anginaDiagnosed', 'precision': 0.2961165048543689}, {'rxName': 'PLAVIX', 'diagnosis': 'strokeDiagnosed', 'precision': 0.3074433656957929}, {'rxName': 'PLAVIX', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.10194174757281553}, {'rxName': 'PLAVIX', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.12459546925566344}, {'rxName': 'PLAVIX', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.45307443365695793}, {'rxName': 'PLAVIX', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.06957928802588997}, {'rxName': 'CYCLOBENZAPR', 'diagnosis': 'highBPDiagnosed', 'precision': 0.473257698541329}, {'rxName': 'CYCLOBENZAPR', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.13452188006482982}, {'rxName': 'CYCLOBENZAPR', 'diagnosis': 'chdDiagnosed', 'precision': 0.059967585089141004}, {'rxName': 'CYCLOBENZAPR', 'diagnosis': 'miDiagnosed', 'precision': 0.050243111831442464}, {'rxName': 'CYCLOBENZAPR', 'diagnosis': 'anginaDiagnosed', 'precision': 0.050243111831442464}, {'rxName': 'CYCLOBENZAPR', 'diagnosis': 'strokeDiagnosed', 'precision': 0.05672609400324149}, {'rxName': 'CYCLOBENZAPR', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04213938411669368}, {'rxName': 'CYCLOBENZAPR', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.17179902755267423}, {'rxName': 'CYCLOBENZAPR', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1507293354943274}, {'rxName': 'CYCLOBENZAPR', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.011345218800648298}, {'rxName': 'MELOXICAM', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5074135090609555}, {'rxName': 'MELOXICAM', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1630971993410214}, {'rxName': 'MELOXICAM', 'diagnosis': 'chdDiagnosed', 'precision': 0.07907742998352553}, {'rxName': 'MELOXICAM', 'diagnosis': 'miDiagnosed', 'precision': 0.05601317957166392}, {'rxName': 'MELOXICAM', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06754530477759473}, {'rxName': 'MELOXICAM', 'diagnosis': 'strokeDiagnosed', 'precision': 0.05930807248764415}, {'rxName': 'MELOXICAM', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05601317957166392}, {'rxName': 'MELOXICAM', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.15321252059308071}, {'rxName': 'MELOXICAM', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.15321252059308071}, {'rxName': 'MELOXICAM', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.011532125205930808}, {'rxName': 'LOVASTATIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.6958677685950413}, {'rxName': 'LOVASTATIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.343801652892562}, {'rxName': 'LOVASTATIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.13884297520661157}, {'rxName': 'LOVASTATIN', 'diagnosis': 'miDiagnosed', 'precision': 0.08429752066115702}, {'rxName': 'LOVASTATIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.05785123966942149}, {'rxName': 'LOVASTATIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.07603305785123966}, {'rxName': 'LOVASTATIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.047933884297520664}, {'rxName': 'LOVASTATIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.11570247933884298}, {'rxName': 'LOVASTATIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.17851239669421487}, {'rxName': 'LOVASTATIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.04297520661157025}, {'rxName': 'DIOVAN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.9252173913043479}, {'rxName': 'DIOVAN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.28695652173913044}, {'rxName': 'DIOVAN', 'diagnosis': 'chdDiagnosed', 'precision': 0.19304347826086957}, {'rxName': 'DIOVAN', 'diagnosis': 'miDiagnosed', 'precision': 0.11652173913043479}, {'rxName': 'DIOVAN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.08695652173913043}, {'rxName': 'DIOVAN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.09217391304347826}, {'rxName': 'DIOVAN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05391304347826087}, {'rxName': 'DIOVAN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.12869565217391304}, {'rxName': 'DIOVAN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.2539130434782609}, {'rxName': 'DIOVAN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.043478260869565216}, {'rxName': 'ASPIRIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.799645390070922}, {'rxName': 'ASPIRIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.4379432624113475}, {'rxName': 'ASPIRIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.30851063829787234}, {'rxName': 'ASPIRIN', 'diagnosis': 'miDiagnosed', 'precision': 0.22872340425531915}, {'rxName': 'ASPIRIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.13297872340425532}, {'rxName': 'ASPIRIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.15602836879432624}, {'rxName': 'ASPIRIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.06382978723404255}, {'rxName': 'ASPIRIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.14361702127659576}, {'rxName': 'ASPIRIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.2801418439716312}, {'rxName': 'ASPIRIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.051418439716312055}, {'rxName': 'METOPROLOL', 'diagnosis': 'highBPDiagnosed', 'precision': 0.8300180831826401}, {'rxName': 'METOPROLOL', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.2694394213381555}, {'rxName': 'METOPROLOL', 'diagnosis': 'chdDiagnosed', 'precision': 0.3309222423146474}, {'rxName': 'METOPROLOL', 'diagnosis': 'miDiagnosed', 'precision': 0.22423146473779385}, {'rxName': 'METOPROLOL', 'diagnosis': 'anginaDiagnosed', 'precision': 0.15370705244122965}, {'rxName': 'METOPROLOL', 'diagnosis': 'strokeDiagnosed', 'precision': 0.12477396021699819}, {'rxName': 'METOPROLOL', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05244122965641953}, {'rxName': 'METOPROLOL', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.09584086799276673}, {'rxName': 'METOPROLOL', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.3743218806509946}, {'rxName': 'METOPROLOL', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.03616636528028933}, {'rxName': 'CELEBREX', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5692883895131086}, {'rxName': 'CELEBREX', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1797752808988764}, {'rxName': 'CELEBREX', 'diagnosis': 'chdDiagnosed', 'precision': 0.11235955056179775}, {'rxName': 'CELEBREX', 'diagnosis': 'miDiagnosed', 'precision': 0.056179775280898875}, {'rxName': 'CELEBREX', 'diagnosis': 'anginaDiagnosed', 'precision': 0.05805243445692884}, {'rxName': 'CELEBREX', 'diagnosis': 'strokeDiagnosed', 'precision': 0.08052434456928839}, {'rxName': 'CELEBREX', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.0599250936329588}, {'rxName': 'CELEBREX', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1647940074906367}, {'rxName': 'CELEBREX', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.20599250936329588}, {'rxName': 'CELEBREX', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.026217228464419477}, {'rxName': 'METOPROLOL TARTRATE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.9040307101727447}, {'rxName': 'METOPROLOL TARTRATE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.30710172744721687}, {'rxName': 'METOPROLOL TARTRATE', 'diagnosis': 'chdDiagnosed', 'precision': 0.3435700575815739}, {'rxName': 'METOPROLOL TARTRATE', 'diagnosis': 'miDiagnosed', 'precision': 0.2629558541266795}, {'rxName': 'METOPROLOL TARTRATE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.16506717850287908}, {'rxName': 'METOPROLOL TARTRATE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.14971209213051823}, {'rxName': 'METOPROLOL TARTRATE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.07485604606525911}, {'rxName': 'METOPROLOL TARTRATE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.11708253358925144}, {'rxName': 'METOPROLOL TARTRATE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.3666026871401152}, {'rxName': 'METOPROLOL TARTRATE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.05758157389635317}, {'rxName': 'PRAVASTATIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.717479674796748}, {'rxName': 'PRAVASTATIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.30691056910569103}, {'rxName': 'PRAVASTATIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.21341463414634146}, {'rxName': 'PRAVASTATIN', 'diagnosis': 'miDiagnosed', 'precision': 0.11585365853658537}, {'rxName': 'PRAVASTATIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.09349593495934959}, {'rxName': 'PRAVASTATIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.09959349593495935}, {'rxName': 'PRAVASTATIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05894308943089431}, {'rxName': 'PRAVASTATIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.11585365853658537}, {'rxName': 'PRAVASTATIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.25609756097560976}, {'rxName': 'PRAVASTATIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.026422764227642278}, {'rxName': 'SINGULAIR', 'diagnosis': 'highBPDiagnosed', 'precision': 0.4458077709611452}, {'rxName': 'SINGULAIR', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1492842535787321}, {'rxName': 'SINGULAIR', 'diagnosis': 'chdDiagnosed', 'precision': 0.09611451942740286}, {'rxName': 'SINGULAIR', 'diagnosis': 'miDiagnosed', 'precision': 0.0408997955010225}, {'rxName': 'SINGULAIR', 'diagnosis': 'anginaDiagnosed', 'precision': 0.044989775051124746}, {'rxName': 'SINGULAIR', 'diagnosis': 'strokeDiagnosed', 'precision': 0.065439672801636}, {'rxName': 'SINGULAIR', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.08384458077709611}, {'rxName': 'SINGULAIR', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.6032719836400818}, {'rxName': 'SINGULAIR', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1574642126789366}, {'rxName': 'SINGULAIR', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.022494887525562373}, {'rxName': 'LORAZEPAM', 'diagnosis': 'highBPDiagnosed', 'precision': 0.465979381443299}, {'rxName': 'LORAZEPAM', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1670103092783505}, {'rxName': 'LORAZEPAM', 'diagnosis': 'chdDiagnosed', 'precision': 0.12577319587628866}, {'rxName': 'LORAZEPAM', 'diagnosis': 'miDiagnosed', 'precision': 0.07422680412371134}, {'rxName': 'LORAZEPAM', 'diagnosis': 'anginaDiagnosed', 'precision': 0.07010309278350516}, {'rxName': 'LORAZEPAM', 'diagnosis': 'strokeDiagnosed', 'precision': 0.088659793814433}, {'rxName': 'LORAZEPAM', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.08041237113402062}, {'rxName': 'LORAZEPAM', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.16494845360824742}, {'rxName': 'LORAZEPAM', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.20412371134020618}, {'rxName': 'LORAZEPAM', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.03711340206185567}, {'rxName': 'LEVAQUIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.44258872651356995}, {'rxName': 'LEVAQUIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.14613778705636743}, {'rxName': 'LEVAQUIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.11691022964509394}, {'rxName': 'LEVAQUIN', 'diagnosis': 'miDiagnosed', 'precision': 0.081419624217119}, {'rxName': 'LEVAQUIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.07515657620041753}, {'rxName': 'LEVAQUIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.0709812108559499}, {'rxName': 'LEVAQUIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.07724425887265135}, {'rxName': 'LEVAQUIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.20041753653444677}, {'rxName': 'LEVAQUIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.19206680584551147}, {'rxName': 'LEVAQUIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.025052192066805846}, {'rxName': 'CLONAZEPAM', 'diagnosis': 'highBPDiagnosed', 'precision': 0.48326359832635984}, {'rxName': 'CLONAZEPAM', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.14644351464435146}, {'rxName': 'CLONAZEPAM', 'diagnosis': 'chdDiagnosed', 'precision': 0.08577405857740586}, {'rxName': 'CLONAZEPAM', 'diagnosis': 'miDiagnosed', 'precision': 0.06485355648535565}, {'rxName': 'CLONAZEPAM', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06903765690376569}, {'rxName': 'CLONAZEPAM', 'diagnosis': 'strokeDiagnosed', 'precision': 0.0899581589958159}, {'rxName': 'CLONAZEPAM', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.0899581589958159}, {'rxName': 'CLONAZEPAM', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.18619246861924685}, {'rxName': 'CLONAZEPAM', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1799163179916318}, {'rxName': 'CLONAZEPAM', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.01882845188284519}, {'rxName': 'METFORMIN HCL', 'diagnosis': 'highBPDiagnosed', 'precision': 0.701271186440678}, {'rxName': 'METFORMIN HCL', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.902542372881356}, {'rxName': 'METFORMIN HCL', 'diagnosis': 'chdDiagnosed', 'precision': 0.163135593220339}, {'rxName': 'METFORMIN HCL', 'diagnosis': 'miDiagnosed', 'precision': 0.1016949152542373}, {'rxName': 'METFORMIN HCL', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06991525423728813}, {'rxName': 'METFORMIN HCL', 'diagnosis': 'strokeDiagnosed', 'precision': 0.08050847457627118}, {'rxName': 'METFORMIN HCL', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04449152542372881}, {'rxName': 'METFORMIN HCL', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.08898305084745763}, {'rxName': 'METFORMIN HCL', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.20127118644067796}, {'rxName': 'METFORMIN HCL', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.038135593220338986}, {'rxName': 'APAP/CODEINE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.42948717948717946}, {'rxName': 'APAP/CODEINE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.16666666666666666}, {'rxName': 'APAP/CODEINE', 'diagnosis': 'chdDiagnosed', 'precision': 0.06196581196581197}, {'rxName': 'APAP/CODEINE', 'diagnosis': 'miDiagnosed', 'precision': 0.05982905982905983}, {'rxName': 'APAP/CODEINE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.049145299145299144}, {'rxName': 'APAP/CODEINE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.07692307692307693}, {'rxName': 'APAP/CODEINE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.03632478632478633}, {'rxName': 'APAP/CODEINE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1581196581196581}, {'rxName': 'APAP/CODEINE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1388888888888889}, {'rxName': 'APAP/CODEINE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.027777777777777776}, {'rxName': 'CITALOPRAM', 'diagnosis': 'highBPDiagnosed', 'precision': 0.47854077253218885}, {'rxName': 'CITALOPRAM', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.16523605150214593}, {'rxName': 'CITALOPRAM', 'diagnosis': 'chdDiagnosed', 'precision': 0.08369098712446352}, {'rxName': 'CITALOPRAM', 'diagnosis': 'miDiagnosed', 'precision': 0.07939914163090128}, {'rxName': 'CITALOPRAM', 'diagnosis': 'anginaDiagnosed', 'precision': 0.05793991416309013}, {'rxName': 'CITALOPRAM', 'diagnosis': 'strokeDiagnosed', 'precision': 0.07939914163090128}, {'rxName': 'CITALOPRAM', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.06652360515021459}, {'rxName': 'CITALOPRAM', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.13948497854077252}, {'rxName': 'CITALOPRAM', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.15665236051502146}, {'rxName': 'CITALOPRAM', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.030042918454935622}, {'rxName': 'CIPROFLOXACN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.45493562231759654}, {'rxName': 'CIPROFLOXACN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.16738197424892703}, {'rxName': 'CIPROFLOXACN', 'diagnosis': 'chdDiagnosed', 'precision': 0.0815450643776824}, {'rxName': 'CIPROFLOXACN', 'diagnosis': 'miDiagnosed', 'precision': 0.0407725321888412}, {'rxName': 'CIPROFLOXACN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.060085836909871244}, {'rxName': 'CIPROFLOXACN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.05150214592274678}, {'rxName': 'CIPROFLOXACN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.030042918454935622}, {'rxName': 'CIPROFLOXACN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.11802575107296137}, {'rxName': 'CIPROFLOXACN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1351931330472103}, {'rxName': 'CIPROFLOXACN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.012875536480686695}, {'rxName': 'ACTOS', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7354838709677419}, {'rxName': 'ACTOS', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.9655913978494624}, {'rxName': 'ACTOS', 'diagnosis': 'chdDiagnosed', 'precision': 0.16344086021505377}, {'rxName': 'ACTOS', 'diagnosis': 'miDiagnosed', 'precision': 0.0967741935483871}, {'rxName': 'ACTOS', 'diagnosis': 'anginaDiagnosed', 'precision': 0.09247311827956989}, {'rxName': 'ACTOS', 'diagnosis': 'strokeDiagnosed', 'precision': 0.09462365591397849}, {'rxName': 'ACTOS', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04516129032258064}, {'rxName': 'ACTOS', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.12688172043010754}, {'rxName': 'ACTOS', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.2129032258064516}, {'rxName': 'ACTOS', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.025806451612903226}, {'rxName': 'GLIPIZIDE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7554112554112554}, {'rxName': 'GLIPIZIDE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.9329004329004329}, {'rxName': 'GLIPIZIDE', 'diagnosis': 'chdDiagnosed', 'precision': 0.17316017316017315}, {'rxName': 'GLIPIZIDE', 'diagnosis': 'miDiagnosed', 'precision': 0.12121212121212122}, {'rxName': 'GLIPIZIDE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.09523809523809523}, {'rxName': 'GLIPIZIDE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.13203463203463203}, {'rxName': 'GLIPIZIDE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.06060606060606061}, {'rxName': 'GLIPIZIDE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.11688311688311688}, {'rxName': 'GLIPIZIDE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.170995670995671}, {'rxName': 'GLIPIZIDE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.023809523809523808}, {'rxName': 'SERTRALINE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.4662309368191721}, {'rxName': 'SERTRALINE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1786492374727669}, {'rxName': 'SERTRALINE', 'diagnosis': 'chdDiagnosed', 'precision': 0.08278867102396514}, {'rxName': 'SERTRALINE', 'diagnosis': 'miDiagnosed', 'precision': 0.058823529411764705}, {'rxName': 'SERTRALINE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.04793028322440087}, {'rxName': 'SERTRALINE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.0915032679738562}, {'rxName': 'SERTRALINE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04357298474945534}, {'rxName': 'SERTRALINE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.15468409586056645}, {'rxName': 'SERTRALINE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.16122004357298475}, {'rxName': 'SERTRALINE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.04139433551198257}, {'rxName': 'METOPROL TAR', 'diagnosis': 'highBPDiagnosed', 'precision': 0.8493449781659389}, {'rxName': 'METOPROL TAR', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.27510917030567683}, {'rxName': 'METOPROL TAR', 'diagnosis': 'chdDiagnosed', 'precision': 0.34497816593886466}, {'rxName': 'METOPROL TAR', 'diagnosis': 'miDiagnosed', 'precision': 0.23580786026200873}, {'rxName': 'METOPROL TAR', 'diagnosis': 'anginaDiagnosed', 'precision': 0.16812227074235808}, {'rxName': 'METOPROL TAR', 'diagnosis': 'strokeDiagnosed', 'precision': 0.1462882096069869}, {'rxName': 'METOPROL TAR', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.0611353711790393}, {'rxName': 'METOPROL TAR', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.13755458515283842}, {'rxName': 'METOPROL TAR', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.3537117903930131}, {'rxName': 'METOPROL TAR', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.05240174672489083}, {'rxName': 'BENZONATATE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.40397350993377484}, {'rxName': 'BENZONATATE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.16114790286975716}, {'rxName': 'BENZONATATE', 'diagnosis': 'chdDiagnosed', 'precision': 0.0706401766004415}, {'rxName': 'BENZONATATE', 'diagnosis': 'miDiagnosed', 'precision': 0.04415011037527594}, {'rxName': 'BENZONATATE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.03532008830022075}, {'rxName': 'BENZONATATE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.05077262693156733}, {'rxName': 'BENZONATATE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.019867549668874173}, {'rxName': 'BENZONATATE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.17218543046357615}, {'rxName': 'BENZONATATE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.16556291390728478}, {'rxName': 'BENZONATATE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.019867549668874173}, {'rxName': 'CYMBALTA', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5088495575221239}, {'rxName': 'CYMBALTA', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.21902654867256638}, {'rxName': 'CYMBALTA', 'diagnosis': 'chdDiagnosed', 'precision': 0.10619469026548672}, {'rxName': 'CYMBALTA', 'diagnosis': 'miDiagnosed', 'precision': 0.06858407079646017}, {'rxName': 'CYMBALTA', 'diagnosis': 'anginaDiagnosed', 'precision': 0.07743362831858407}, {'rxName': 'CYMBALTA', 'diagnosis': 'strokeDiagnosed', 'precision': 0.084070796460177}, {'rxName': 'CYMBALTA', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.06415929203539823}, {'rxName': 'CYMBALTA', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.24336283185840707}, {'rxName': 'CYMBALTA', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.16371681415929204}, {'rxName': 'CYMBALTA', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.01327433628318584}, {'rxName': 'VYTORIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.6504424778761062}, {'rxName': 'VYTORIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.33849557522123896}, {'rxName': 'VYTORIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.26327433628318586}, {'rxName': 'VYTORIN', 'diagnosis': 'miDiagnosed', 'precision': 0.17035398230088494}, {'rxName': 'VYTORIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.11061946902654868}, {'rxName': 'VYTORIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.07964601769911504}, {'rxName': 'VYTORIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05309734513274336}, {'rxName': 'VYTORIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.11061946902654868}, {'rxName': 'VYTORIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.21017699115044247}, {'rxName': 'VYTORIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.02654867256637168}, {'rxName': 'OXYCOD/APAP', 'diagnosis': 'highBPDiagnosed', 'precision': 0.435665914221219}, {'rxName': 'OXYCOD/APAP', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.17381489841986456}, {'rxName': 'OXYCOD/APAP', 'diagnosis': 'chdDiagnosed', 'precision': 0.0654627539503386}, {'rxName': 'OXYCOD/APAP', 'diagnosis': 'miDiagnosed', 'precision': 0.05869074492099323}, {'rxName': 'OXYCOD/APAP', 'diagnosis': 'anginaDiagnosed', 'precision': 0.04966139954853273}, {'rxName': 'OXYCOD/APAP', 'diagnosis': 'strokeDiagnosed', 'precision': 0.06772009029345373}, {'rxName': 'OXYCOD/APAP', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.045146726862302484}, {'rxName': 'OXYCOD/APAP', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1670428893905192}, {'rxName': 'OXYCOD/APAP', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.15575620767494355}, {'rxName': 'OXYCOD/APAP', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.01805869074492099}, {'rxName': 'ZITHROMAX', 'diagnosis': 'highBPDiagnosed', 'precision': 0.3195402298850575}, {'rxName': 'ZITHROMAX', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.10804597701149425}, {'rxName': 'ZITHROMAX', 'diagnosis': 'chdDiagnosed', 'precision': 0.06206896551724138}, {'rxName': 'ZITHROMAX', 'diagnosis': 'miDiagnosed', 'precision': 0.05057471264367816}, {'rxName': 'ZITHROMAX', 'diagnosis': 'anginaDiagnosed', 'precision': 0.027586206896551724}, {'rxName': 'ZITHROMAX', 'diagnosis': 'strokeDiagnosed', 'precision': 0.04367816091954023}, {'rxName': 'ZITHROMAX', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.0367816091954023}, {'rxName': 'ZITHROMAX', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1839080459770115}, {'rxName': 'ZITHROMAX', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.12183908045977011}, {'rxName': 'ZITHROMAX', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.011494252873563218}, {'rxName': 'PREVACID', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5638051044083526}, {'rxName': 'PREVACID', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.2111368909512761}, {'rxName': 'PREVACID', 'diagnosis': 'chdDiagnosed', 'precision': 0.12064965197215777}, {'rxName': 'PREVACID', 'diagnosis': 'miDiagnosed', 'precision': 0.07192575406032482}, {'rxName': 'PREVACID', 'diagnosis': 'anginaDiagnosed', 'precision': 0.09280742459396751}, {'rxName': 'PREVACID', 'diagnosis': 'strokeDiagnosed', 'precision': 0.05568445475638051}, {'rxName': 'PREVACID', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04408352668213457}, {'rxName': 'PREVACID', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.16705336426914152}, {'rxName': 'PREVACID', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1902552204176334}, {'rxName': 'PREVACID', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.03248259860788863}, {'rxName': 'ONETOUCH', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7149643705463183}, {'rxName': 'ONETOUCH', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.8693586698337292}, {'rxName': 'ONETOUCH', 'diagnosis': 'chdDiagnosed', 'precision': 0.171021377672209}, {'rxName': 'ONETOUCH', 'diagnosis': 'miDiagnosed', 'precision': 0.09738717339667459}, {'rxName': 'ONETOUCH', 'diagnosis': 'anginaDiagnosed', 'precision': 0.07838479809976247}, {'rxName': 'ONETOUCH', 'diagnosis': 'strokeDiagnosed', 'precision': 0.08788598574821853}, {'rxName': 'ONETOUCH', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.0332541567695962}, {'rxName': 'ONETOUCH', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.14489311163895488}, {'rxName': 'ONETOUCH', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.20665083135391923}, {'rxName': 'ONETOUCH', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.057007125890736345}, {'rxName': 'RANITIDINE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.6057007125890737}, {'rxName': 'RANITIDINE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.19002375296912113}, {'rxName': 'RANITIDINE', 'diagnosis': 'chdDiagnosed', 'precision': 0.14251781472684086}, {'rxName': 'RANITIDINE', 'diagnosis': 'miDiagnosed', 'precision': 0.1187648456057007}, {'rxName': 'RANITIDINE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.07363420427553444}, {'rxName': 'RANITIDINE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.08788598574821853}, {'rxName': 'RANITIDINE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.06413301662707839}, {'rxName': 'RANITIDINE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.18052256532066507}, {'rxName': 'RANITIDINE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.20902612826603326}, {'rxName': 'RANITIDINE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.03800475059382423}, {'rxName': 'VITAMIN D', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5542168674698795}, {'rxName': 'VITAMIN D', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1855421686746988}, {'rxName': 'VITAMIN D', 'diagnosis': 'chdDiagnosed', 'precision': 0.10120481927710843}, {'rxName': 'VITAMIN D', 'diagnosis': 'miDiagnosed', 'precision': 0.05542168674698795}, {'rxName': 'VITAMIN D', 'diagnosis': 'anginaDiagnosed', 'precision': 0.05542168674698795}, {'rxName': 'VITAMIN D', 'diagnosis': 'strokeDiagnosed', 'precision': 0.07228915662650602}, {'rxName': 'VITAMIN D', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05301204819277108}, {'rxName': 'VITAMIN D', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.17590361445783131}, {'rxName': 'VITAMIN D', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.21445783132530122}, {'rxName': 'VITAMIN D', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.024096385542168676}, {'rxName': 'OXYCODONE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.47}, {'rxName': 'OXYCODONE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.14}, {'rxName': 'OXYCODONE', 'diagnosis': 'chdDiagnosed', 'precision': 0.085}, {'rxName': 'OXYCODONE', 'diagnosis': 'miDiagnosed', 'precision': 0.0725}, {'rxName': 'OXYCODONE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.05}, {'rxName': 'OXYCODONE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.0825}, {'rxName': 'OXYCODONE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.065}, {'rxName': 'OXYCODONE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.17}, {'rxName': 'OXYCODONE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.155}, {'rxName': 'OXYCODONE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.025}, {'rxName': 'FLUTICASONE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.4318181818181818}, {'rxName': 'FLUTICASONE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.09848484848484848}, {'rxName': 'FLUTICASONE', 'diagnosis': 'chdDiagnosed', 'precision': 0.07575757575757576}, {'rxName': 'FLUTICASONE', 'diagnosis': 'miDiagnosed', 'precision': 0.030303030303030304}, {'rxName': 'FLUTICASONE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.03787878787878788}, {'rxName': 'FLUTICASONE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.050505050505050504}, {'rxName': 'FLUTICASONE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04040404040404041}, {'rxName': 'FLUTICASONE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.20707070707070707}, {'rxName': 'FLUTICASONE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.15404040404040403}, {'rxName': 'FLUTICASONE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.010101010101010102}, {'rxName': 'FLOMAX', 'diagnosis': 'highBPDiagnosed', 'precision': 0.6298200514138818}, {'rxName': 'FLOMAX', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.17994858611825193}, {'rxName': 'FLOMAX', 'diagnosis': 'chdDiagnosed', 'precision': 0.20822622107969152}, {'rxName': 'FLOMAX', 'diagnosis': 'miDiagnosed', 'precision': 0.14395886889460155}, {'rxName': 'FLOMAX', 'diagnosis': 'anginaDiagnosed', 'precision': 0.09511568123393316}, {'rxName': 'FLOMAX', 'diagnosis': 'strokeDiagnosed', 'precision': 0.09511568123393316}, {'rxName': 'FLOMAX', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.07969151670951156}, {'rxName': 'FLOMAX', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.09768637532133675}, {'rxName': 'FLOMAX', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.2365038560411311}, {'rxName': 'FLOMAX', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.030848329048843187}, {'rxName': 'CARVEDILOL', 'diagnosis': 'highBPDiagnosed', 'precision': 0.8455497382198953}, {'rxName': 'CARVEDILOL', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.4607329842931937}, {'rxName': 'CARVEDILOL', 'diagnosis': 'chdDiagnosed', 'precision': 0.46596858638743455}, {'rxName': 'CARVEDILOL', 'diagnosis': 'miDiagnosed', 'precision': 0.29842931937172773}, {'rxName': 'CARVEDILOL', 'diagnosis': 'anginaDiagnosed', 'precision': 0.1806282722513089}, {'rxName': 'CARVEDILOL', 'diagnosis': 'strokeDiagnosed', 'precision': 0.17539267015706805}, {'rxName': 'CARVEDILOL', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.08115183246073299}, {'rxName': 'CARVEDILOL', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1256544502617801}, {'rxName': 'CARVEDILOL', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.5026178010471204}, {'rxName': 'CARVEDILOL', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.20418848167539266}, {'rxName': 'GLYBURIDE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7349081364829396}, {'rxName': 'GLYBURIDE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.8976377952755905}, {'rxName': 'GLYBURIDE', 'diagnosis': 'chdDiagnosed', 'precision': 0.1784776902887139}, {'rxName': 'GLYBURIDE', 'diagnosis': 'miDiagnosed', 'precision': 0.11286089238845144}, {'rxName': 'GLYBURIDE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.07086614173228346}, {'rxName': 'GLYBURIDE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.11811023622047244}, {'rxName': 'GLYBURIDE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.049868766404199474}, {'rxName': 'GLYBURIDE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.11023622047244094}, {'rxName': 'GLYBURIDE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1968503937007874}, {'rxName': 'GLYBURIDE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.04461942257217848}, {'rxName': 'TRICOR', 'diagnosis': 'highBPDiagnosed', 'precision': 0.6736842105263158}, {'rxName': 'TRICOR', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.3526315789473684}, {'rxName': 'TRICOR', 'diagnosis': 'chdDiagnosed', 'precision': 0.24736842105263157}, {'rxName': 'TRICOR', 'diagnosis': 'miDiagnosed', 'precision': 0.14736842105263157}, {'rxName': 'TRICOR', 'diagnosis': 'anginaDiagnosed', 'precision': 0.10526315789473684}, {'rxName': 'TRICOR', 'diagnosis': 'strokeDiagnosed', 'precision': 0.12368421052631579}, {'rxName': 'TRICOR', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05789473684210526}, {'rxName': 'TRICOR', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.09736842105263158}, {'rxName': 'TRICOR', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.24210526315789474}, {'rxName': 'TRICOR', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.02894736842105263}, {'rxName': 'WARFARIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7210526315789474}, {'rxName': 'WARFARIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.25263157894736843}, {'rxName': 'WARFARIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.3973684210526316}, {'rxName': 'WARFARIN', 'diagnosis': 'miDiagnosed', 'precision': 0.20789473684210527}, {'rxName': 'WARFARIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.1631578947368421}, {'rxName': 'WARFARIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.23684210526315788}, {'rxName': 'WARFARIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.08947368421052632}, {'rxName': 'WARFARIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.15789473684210525}, {'rxName': 'WARFARIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.5526315789473685}, {'rxName': 'WARFARIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.1}, {'rxName': 'PERCOCET', 'diagnosis': 'highBPDiagnosed', 'precision': 0.36675461741424803}, {'rxName': 'PERCOCET', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.10817941952506596}, {'rxName': 'PERCOCET', 'diagnosis': 'chdDiagnosed', 'precision': 0.05013192612137203}, {'rxName': 'PERCOCET', 'diagnosis': 'miDiagnosed', 'precision': 0.029023746701846966}, {'rxName': 'PERCOCET', 'diagnosis': 'anginaDiagnosed', 'precision': 0.023746701846965697}, {'rxName': 'PERCOCET', 'diagnosis': 'strokeDiagnosed', 'precision': 0.036939313984168866}, {'rxName': 'PERCOCET', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.036939313984168866}, {'rxName': 'PERCOCET', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1820580474934037}, {'rxName': 'PERCOCET', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.10817941952506596}, {'rxName': 'PERCOCET', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.013192612137203167}, {'rxName': 'LYRICA', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5618279569892473}, {'rxName': 'LYRICA', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.260752688172043}, {'rxName': 'LYRICA', 'diagnosis': 'chdDiagnosed', 'precision': 0.11021505376344086}, {'rxName': 'LYRICA', 'diagnosis': 'miDiagnosed', 'precision': 0.0913978494623656}, {'rxName': 'LYRICA', 'diagnosis': 'anginaDiagnosed', 'precision': 0.10752688172043011}, {'rxName': 'LYRICA', 'diagnosis': 'strokeDiagnosed', 'precision': 0.11021505376344086}, {'rxName': 'LYRICA', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.07526881720430108}, {'rxName': 'LYRICA', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.22311827956989247}, {'rxName': 'LYRICA', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1989247311827957}, {'rxName': 'LYRICA', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.024193548387096774}, {'rxName': 'LANTUS', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7698630136986301}, {'rxName': 'LANTUS', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.958904109589041}, {'rxName': 'LANTUS', 'diagnosis': 'chdDiagnosed', 'precision': 0.2356164383561644}, {'rxName': 'LANTUS', 'diagnosis': 'miDiagnosed', 'precision': 0.14794520547945206}, {'rxName': 'LANTUS', 'diagnosis': 'anginaDiagnosed', 'precision': 0.11506849315068493}, {'rxName': 'LANTUS', 'diagnosis': 'strokeDiagnosed', 'precision': 0.14520547945205478}, {'rxName': 'LANTUS', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04657534246575343}, {'rxName': 'LANTUS', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.14794520547945206}, {'rxName': 'LANTUS', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.23013698630136986}, {'rxName': 'LANTUS', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.07397260273972603}, {'rxName': 'NASONEX', 'diagnosis': 'highBPDiagnosed', 'precision': 0.3701657458563536}, {'rxName': 'NASONEX', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1270718232044199}, {'rxName': 'NASONEX', 'diagnosis': 'chdDiagnosed', 'precision': 0.08287292817679558}, {'rxName': 'NASONEX', 'diagnosis': 'miDiagnosed', 'precision': 0.03314917127071823}, {'rxName': 'NASONEX', 'diagnosis': 'anginaDiagnosed', 'precision': 0.022099447513812154}, {'rxName': 'NASONEX', 'diagnosis': 'strokeDiagnosed', 'precision': 0.03867403314917127}, {'rxName': 'NASONEX', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.055248618784530384}, {'rxName': 'NASONEX', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.27900552486187846}, {'rxName': 'NASONEX', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.10497237569060773}, {'rxName': 'NASONEX', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.0055248618784530384}, {'rxName': 'ALENDRONATE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5561797752808989}, {'rxName': 'ALENDRONATE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1601123595505618}, {'rxName': 'ALENDRONATE', 'diagnosis': 'chdDiagnosed', 'precision': 0.12359550561797752}, {'rxName': 'ALENDRONATE', 'diagnosis': 'miDiagnosed', 'precision': 0.05056179775280899}, {'rxName': 'ALENDRONATE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.0449438202247191}, {'rxName': 'ALENDRONATE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.0702247191011236}, {'rxName': 'ALENDRONATE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.06179775280898876}, {'rxName': 'ALENDRONATE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1151685393258427}, {'rxName': 'ALENDRONATE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.17415730337078653}, {'rxName': 'ALENDRONATE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.019662921348314606}, {'rxName': 'LISINOP/HCTZ', 'diagnosis': 'highBPDiagnosed', 'precision': 0.9352112676056338}, {'rxName': 'LISINOP/HCTZ', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.22816901408450704}, {'rxName': 'LISINOP/HCTZ', 'diagnosis': 'chdDiagnosed', 'precision': 0.09014084507042254}, {'rxName': 'LISINOP/HCTZ', 'diagnosis': 'miDiagnosed', 'precision': 0.04788732394366197}, {'rxName': 'LISINOP/HCTZ', 'diagnosis': 'anginaDiagnosed', 'precision': 0.03943661971830986}, {'rxName': 'LISINOP/HCTZ', 'diagnosis': 'strokeDiagnosed', 'precision': 0.09014084507042254}, {'rxName': 'LISINOP/HCTZ', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.01971830985915493}, {'rxName': 'LISINOP/HCTZ', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1295774647887324}, {'rxName': 'LISINOP/HCTZ', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.15774647887323945}, {'rxName': 'LISINOP/HCTZ', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.014084507042253521}, {'rxName': 'CIPROFLOXACIN HYDROCHLORIDE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.4540229885057471}, {'rxName': 'CIPROFLOXACIN HYDROCHLORIDE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.16666666666666666}, {'rxName': 'CIPROFLOXACIN HYDROCHLORIDE', 'diagnosis': 'chdDiagnosed', 'precision': 0.09482758620689655}, {'rxName': 'CIPROFLOXACIN HYDROCHLORIDE', 'diagnosis': 'miDiagnosed', 'precision': 0.031609195402298854}, {'rxName': 'CIPROFLOXACIN HYDROCHLORIDE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.04885057471264368}, {'rxName': 'CIPROFLOXACIN HYDROCHLORIDE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.08333333333333333}, {'rxName': 'CIPROFLOXACIN HYDROCHLORIDE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05459770114942529}, {'rxName': 'CIPROFLOXACIN HYDROCHLORIDE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.16666666666666666}, {'rxName': 'CIPROFLOXACIN HYDROCHLORIDE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1752873563218391}, {'rxName': 'CIPROFLOXACIN HYDROCHLORIDE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.017241379310344827}, {'rxName': 'ZOLPIDEM', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5260115606936416}, {'rxName': 'ZOLPIDEM', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.16184971098265896}, {'rxName': 'ZOLPIDEM', 'diagnosis': 'chdDiagnosed', 'precision': 0.11560693641618497}, {'rxName': 'ZOLPIDEM', 'diagnosis': 'miDiagnosed', 'precision': 0.09826589595375723}, {'rxName': 'ZOLPIDEM', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06358381502890173}, {'rxName': 'ZOLPIDEM', 'diagnosis': 'strokeDiagnosed', 'precision': 0.06936416184971098}, {'rxName': 'ZOLPIDEM', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05202312138728324}, {'rxName': 'ZOLPIDEM', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.13872832369942195}, {'rxName': 'ZOLPIDEM', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1994219653179191}, {'rxName': 'ZOLPIDEM', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.014450867052023121}, {'rxName': 'DIAZEPAM', 'diagnosis': 'highBPDiagnosed', 'precision': 0.4476744186046512}, {'rxName': 'DIAZEPAM', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.11627906976744186}, {'rxName': 'DIAZEPAM', 'diagnosis': 'chdDiagnosed', 'precision': 0.0755813953488372}, {'rxName': 'DIAZEPAM', 'diagnosis': 'miDiagnosed', 'precision': 0.0436046511627907}, {'rxName': 'DIAZEPAM', 'diagnosis': 'anginaDiagnosed', 'precision': 0.05232558139534884}, {'rxName': 'DIAZEPAM', 'diagnosis': 'strokeDiagnosed', 'precision': 0.04941860465116279}, {'rxName': 'DIAZEPAM', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.08430232558139535}, {'rxName': 'DIAZEPAM', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.20930232558139536}, {'rxName': 'DIAZEPAM', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.15406976744186046}, {'rxName': 'DIAZEPAM', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.005813953488372093}, {'rxName': 'WARFARIN SODIUM', 'diagnosis': 'highBPDiagnosed', 'precision': 0.6695906432748538}, {'rxName': 'WARFARIN SODIUM', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.21929824561403508}, {'rxName': 'WARFARIN SODIUM', 'diagnosis': 'chdDiagnosed', 'precision': 0.3567251461988304}, {'rxName': 'WARFARIN SODIUM', 'diagnosis': 'miDiagnosed', 'precision': 0.19005847953216373}, {'rxName': 'WARFARIN SODIUM', 'diagnosis': 'anginaDiagnosed', 'precision': 0.1111111111111111}, {'rxName': 'WARFARIN SODIUM', 'diagnosis': 'strokeDiagnosed', 'precision': 0.2309941520467836}, {'rxName': 'WARFARIN SODIUM', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.09649122807017543}, {'rxName': 'WARFARIN SODIUM', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.13450292397660818}, {'rxName': 'WARFARIN SODIUM', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.5380116959064327}, {'rxName': 'WARFARIN SODIUM', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.09649122807017543}, {'rxName': 'METFORMIN HYDROCHLORIDE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7202380952380952}, {'rxName': 'METFORMIN HYDROCHLORIDE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.8571428571428571}, {'rxName': 'METFORMIN HYDROCHLORIDE', 'diagnosis': 'chdDiagnosed', 'precision': 0.1488095238095238}, {'rxName': 'METFORMIN HYDROCHLORIDE', 'diagnosis': 'miDiagnosed', 'precision': 0.10416666666666667}, {'rxName': 'METFORMIN HYDROCHLORIDE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06845238095238096}, {'rxName': 'METFORMIN HYDROCHLORIDE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.09821428571428571}, {'rxName': 'METFORMIN HYDROCHLORIDE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.047619047619047616}, {'rxName': 'METFORMIN HYDROCHLORIDE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.12797619047619047}, {'rxName': 'METFORMIN HYDROCHLORIDE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.19047619047619047}, {'rxName': 'METFORMIN HYDROCHLORIDE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.02976190476190476}, {'rxName': 'FOLIC ACID', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5625}, {'rxName': 'FOLIC ACID', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1875}, {'rxName': 'FOLIC ACID', 'diagnosis': 'chdDiagnosed', 'precision': 0.16666666666666666}, {'rxName': 'FOLIC ACID', 'diagnosis': 'miDiagnosed', 'precision': 0.09821428571428571}, {'rxName': 'FOLIC ACID', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06845238095238096}, {'rxName': 'FOLIC ACID', 'diagnosis': 'strokeDiagnosed', 'precision': 0.10714285714285714}, {'rxName': 'FOLIC ACID', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.047619047619047616}, {'rxName': 'FOLIC ACID', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.13690476190476192}, {'rxName': 'FOLIC ACID', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.18452380952380953}, {'rxName': 'FOLIC ACID', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.026785714285714284}, {'rxName': 'FLUTICASONE PROPIONATE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.41964285714285715}, {'rxName': 'FLUTICASONE PROPIONATE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.12202380952380952}, {'rxName': 'FLUTICASONE PROPIONATE', 'diagnosis': 'chdDiagnosed', 'precision': 0.0625}, {'rxName': 'FLUTICASONE PROPIONATE', 'diagnosis': 'miDiagnosed', 'precision': 0.03869047619047619}, {'rxName': 'FLUTICASONE PROPIONATE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.03869047619047619}, {'rxName': 'FLUTICASONE PROPIONATE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.047619047619047616}, {'rxName': 'FLUTICASONE PROPIONATE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05357142857142857}, {'rxName': 'FLUTICASONE PROPIONATE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.24107142857142858}, {'rxName': 'FLUTICASONE PROPIONATE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.15178571428571427}, {'rxName': 'FLUTICASONE PROPIONATE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.008928571428571428}, {'rxName': 'ALLOPURINOL', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7827380952380952}, {'rxName': 'ALLOPURINOL', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.30654761904761907}, {'rxName': 'ALLOPURINOL', 'diagnosis': 'chdDiagnosed', 'precision': 0.25892857142857145}, {'rxName': 'ALLOPURINOL', 'diagnosis': 'miDiagnosed', 'precision': 0.14285714285714285}, {'rxName': 'ALLOPURINOL', 'diagnosis': 'anginaDiagnosed', 'precision': 0.09226190476190477}, {'rxName': 'ALLOPURINOL', 'diagnosis': 'strokeDiagnosed', 'precision': 0.10714285714285714}, {'rxName': 'ALLOPURINOL', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05654761904761905}, {'rxName': 'ALLOPURINOL', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.10714285714285714}, {'rxName': 'ALLOPURINOL', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.26785714285714285}, {'rxName': 'ALLOPURINOL', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.05654761904761905}, {'rxName': 'DOXYCYCLINE HYCLATE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.37910447761194027}, {'rxName': 'DOXYCYCLINE HYCLATE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.13134328358208955}, {'rxName': 'DOXYCYCLINE HYCLATE', 'diagnosis': 'chdDiagnosed', 'precision': 0.08358208955223881}, {'rxName': 'DOXYCYCLINE HYCLATE', 'diagnosis': 'miDiagnosed', 'precision': 0.041791044776119404}, {'rxName': 'DOXYCYCLINE HYCLATE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.050746268656716415}, {'rxName': 'DOXYCYCLINE HYCLATE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.06567164179104477}, {'rxName': 'DOXYCYCLINE HYCLATE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04776119402985075}, {'rxName': 'DOXYCYCLINE HYCLATE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.14925373134328357}, {'rxName': 'DOXYCYCLINE HYCLATE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.1373134328358209}, {'rxName': 'DOXYCYCLINE HYCLATE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.01791044776119403}, {'rxName': 'FLUOXETINE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.4006024096385542}, {'rxName': 'FLUOXETINE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1536144578313253}, {'rxName': 'FLUOXETINE', 'diagnosis': 'chdDiagnosed', 'precision': 0.07530120481927711}, {'rxName': 'FLUOXETINE', 'diagnosis': 'miDiagnosed', 'precision': 0.05120481927710843}, {'rxName': 'FLUOXETINE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.04819277108433735}, {'rxName': 'FLUOXETINE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.05120481927710843}, {'rxName': 'FLUOXETINE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.05421686746987952}, {'rxName': 'FLUOXETINE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.19578313253012047}, {'rxName': 'FLUOXETINE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.15963855421686746}, {'rxName': 'FLUOXETINE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.015060240963855422}, {'rxName': 'HYDROCODONE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.46153846153846156}, {'rxName': 'HYDROCODONE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.14153846153846153}, {'rxName': 'HYDROCODONE', 'diagnosis': 'chdDiagnosed', 'precision': 0.07384615384615385}, {'rxName': 'HYDROCODONE', 'diagnosis': 'miDiagnosed', 'precision': 0.052307692307692305}, {'rxName': 'HYDROCODONE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.036923076923076927}, {'rxName': 'HYDROCODONE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.055384615384615386}, {'rxName': 'HYDROCODONE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04923076923076923}, {'rxName': 'HYDROCODONE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1723076923076923}, {'rxName': 'HYDROCODONE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.16615384615384615}, {'rxName': 'HYDROCODONE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.018461538461538463}, {'rxName': 'PREMARIN', 'diagnosis': 'highBPDiagnosed', 'precision': 0.49523809523809526}, {'rxName': 'PREMARIN', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.13968253968253969}, {'rxName': 'PREMARIN', 'diagnosis': 'chdDiagnosed', 'precision': 0.06031746031746032}, {'rxName': 'PREMARIN', 'diagnosis': 'miDiagnosed', 'precision': 0.03492063492063492}, {'rxName': 'PREMARIN', 'diagnosis': 'anginaDiagnosed', 'precision': 0.05396825396825397}, {'rxName': 'PREMARIN', 'diagnosis': 'strokeDiagnosed', 'precision': 0.05714285714285714}, {'rxName': 'PREMARIN', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04126984126984127}, {'rxName': 'PREMARIN', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.14603174603174604}, {'rxName': 'PREMARIN', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.19365079365079366}, {'rxName': 'PREMARIN', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.009523809523809525}, {'rxName': 'PROMETHAZINE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.402555910543131}, {'rxName': 'PROMETHAZINE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.14376996805111822}, {'rxName': 'PROMETHAZINE', 'diagnosis': 'chdDiagnosed', 'precision': 0.05750798722044728}, {'rxName': 'PROMETHAZINE', 'diagnosis': 'miDiagnosed', 'precision': 0.038338658146964855}, {'rxName': 'PROMETHAZINE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.02875399361022364}, {'rxName': 'PROMETHAZINE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.06070287539936102}, {'rxName': 'PROMETHAZINE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.03514376996805112}, {'rxName': 'PROMETHAZINE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.15335463258785942}, {'rxName': 'PROMETHAZINE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.13099041533546327}, {'rxName': 'PROMETHAZINE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.003194888178913738}, {'rxName': 'FLUCONAZOLE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.329073482428115}, {'rxName': 'FLUCONAZOLE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.13738019169329074}, {'rxName': 'FLUCONAZOLE', 'diagnosis': 'chdDiagnosed', 'precision': 0.06070287539936102}, {'rxName': 'FLUCONAZOLE', 'diagnosis': 'miDiagnosed', 'precision': 0.03514376996805112}, {'rxName': 'FLUCONAZOLE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.03194888178913738}, {'rxName': 'FLUCONAZOLE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.051118210862619806}, {'rxName': 'FLUCONAZOLE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.03194888178913738}, {'rxName': 'FLUCONAZOLE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.16932907348242812}, {'rxName': 'FLUCONAZOLE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.12140575079872204}, {'rxName': 'FLUCONAZOLE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.006389776357827476}, {'rxName': 'LORATADINE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.4919093851132686}, {'rxName': 'LORATADINE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.18446601941747573}, {'rxName': 'LORATADINE', 'diagnosis': 'chdDiagnosed', 'precision': 0.09061488673139159}, {'rxName': 'LORATADINE', 'diagnosis': 'miDiagnosed', 'precision': 0.0744336569579288}, {'rxName': 'LORATADINE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.05177993527508091}, {'rxName': 'LORATADINE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.07766990291262135}, {'rxName': 'LORATADINE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.07119741100323625}, {'rxName': 'LORATADINE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.28802588996763756}, {'rxName': 'LORATADINE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.18122977346278318}, {'rxName': 'LORATADINE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.019417475728155338}, {'rxName': 'ADVAIR DISKU', 'diagnosis': 'highBPDiagnosed', 'precision': 0.5422077922077922}, {'rxName': 'ADVAIR DISKU', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1525974025974026}, {'rxName': 'ADVAIR DISKU', 'diagnosis': 'chdDiagnosed', 'precision': 0.1461038961038961}, {'rxName': 'ADVAIR DISKU', 'diagnosis': 'miDiagnosed', 'precision': 0.07792207792207792}, {'rxName': 'ADVAIR DISKU', 'diagnosis': 'anginaDiagnosed', 'precision': 0.06493506493506493}, {'rxName': 'ADVAIR DISKU', 'diagnosis': 'strokeDiagnosed', 'precision': 0.06168831168831169}, {'rxName': 'ADVAIR DISKU', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.21103896103896103}, {'rxName': 'ADVAIR DISKU', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.6753246753246753}, {'rxName': 'ADVAIR DISKU', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.18506493506493507}, {'rxName': 'ADVAIR DISKU', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.032467532467532464}, {'rxName': 'APAP/OXYCODONE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.3758169934640523}, {'rxName': 'APAP/OXYCODONE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.09477124183006536}, {'rxName': 'APAP/OXYCODONE', 'diagnosis': 'chdDiagnosed', 'precision': 0.05555555555555555}, {'rxName': 'APAP/OXYCODONE', 'diagnosis': 'miDiagnosed', 'precision': 0.05555555555555555}, {'rxName': 'APAP/OXYCODONE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.05555555555555555}, {'rxName': 'APAP/OXYCODONE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.058823529411764705}, {'rxName': 'APAP/OXYCODONE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.03594771241830065}, {'rxName': 'APAP/OXYCODONE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1503267973856209}, {'rxName': 'APAP/OXYCODONE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.11764705882352941}, {'rxName': 'APAP/OXYCODONE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.02287581699346405}, {'rxName': 'DIOVAN HCT', 'diagnosis': 'highBPDiagnosed', 'precision': 0.9702970297029703}, {'rxName': 'DIOVAN HCT', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.22442244224422442}, {'rxName': 'DIOVAN HCT', 'diagnosis': 'chdDiagnosed', 'precision': 0.11221122112211221}, {'rxName': 'DIOVAN HCT', 'diagnosis': 'miDiagnosed', 'precision': 0.036303630363036306}, {'rxName': 'DIOVAN HCT', 'diagnosis': 'anginaDiagnosed', 'precision': 0.056105610561056105}, {'rxName': 'DIOVAN HCT', 'diagnosis': 'strokeDiagnosed', 'precision': 0.052805280528052806}, {'rxName': 'DIOVAN HCT', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.039603960396039604}, {'rxName': 'DIOVAN HCT', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.10231023102310231}, {'rxName': 'DIOVAN HCT', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.17491749174917492}, {'rxName': 'DIOVAN HCT', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.006600660066006601}, {'rxName': 'GLIMEPIRIDE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7483443708609272}, {'rxName': 'GLIMEPIRIDE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.9403973509933775}, {'rxName': 'GLIMEPIRIDE', 'diagnosis': 'chdDiagnosed', 'precision': 0.23178807947019867}, {'rxName': 'GLIMEPIRIDE', 'diagnosis': 'miDiagnosed', 'precision': 0.11920529801324503}, {'rxName': 'GLIMEPIRIDE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.10596026490066225}, {'rxName': 'GLIMEPIRIDE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.11589403973509933}, {'rxName': 'GLIMEPIRIDE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.046357615894039736}, {'rxName': 'GLIMEPIRIDE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.1490066225165563}, {'rxName': 'GLIMEPIRIDE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.2119205298013245}, {'rxName': 'GLIMEPIRIDE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.059602649006622516}, {'rxName': 'SMZ/TMP DS', 'diagnosis': 'highBPDiagnosed', 'precision': 0.347682119205298}, {'rxName': 'SMZ/TMP DS', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.11589403973509933}, {'rxName': 'SMZ/TMP DS', 'diagnosis': 'chdDiagnosed', 'precision': 0.059602649006622516}, {'rxName': 'SMZ/TMP DS', 'diagnosis': 'miDiagnosed', 'precision': 0.046357615894039736}, {'rxName': 'SMZ/TMP DS', 'diagnosis': 'anginaDiagnosed', 'precision': 0.03642384105960265}, {'rxName': 'SMZ/TMP DS', 'diagnosis': 'strokeDiagnosed', 'precision': 0.052980132450331126}, {'rxName': 'SMZ/TMP DS', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.03642384105960265}, {'rxName': 'SMZ/TMP DS', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.15562913907284767}, {'rxName': 'SMZ/TMP DS', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.08609271523178808}, {'rxName': 'SMZ/TMP DS', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.0}, {'rxName': 'PENICILLN VK', 'diagnosis': 'highBPDiagnosed', 'precision': 0.336734693877551}, {'rxName': 'PENICILLN VK', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.09523809523809523}, {'rxName': 'PENICILLN VK', 'diagnosis': 'chdDiagnosed', 'precision': 0.04081632653061224}, {'rxName': 'PENICILLN VK', 'diagnosis': 'miDiagnosed', 'precision': 0.027210884353741496}, {'rxName': 'PENICILLN VK', 'diagnosis': 'anginaDiagnosed', 'precision': 0.034013605442176874}, {'rxName': 'PENICILLN VK', 'diagnosis': 'strokeDiagnosed', 'precision': 0.04421768707482993}, {'rxName': 'PENICILLN VK', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.027210884353741496}, {'rxName': 'PENICILLN VK', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.10884353741496598}, {'rxName': 'PENICILLN VK', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.09863945578231292}, {'rxName': 'PENICILLN VK', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.006802721088435374}, {'rxName': 'ACETAMINOPHEN/CODEINE', 'diagnosis': 'highBPDiagnosed', 'precision': 0.4013605442176871}, {'rxName': 'ACETAMINOPHEN/CODEINE', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.1598639455782313}, {'rxName': 'ACETAMINOPHEN/CODEINE', 'diagnosis': 'chdDiagnosed', 'precision': 0.08163265306122448}, {'rxName': 'ACETAMINOPHEN/CODEINE', 'diagnosis': 'miDiagnosed', 'precision': 0.047619047619047616}, {'rxName': 'ACETAMINOPHEN/CODEINE', 'diagnosis': 'anginaDiagnosed', 'precision': 0.047619047619047616}, {'rxName': 'ACETAMINOPHEN/CODEINE', 'diagnosis': 'strokeDiagnosed', 'precision': 0.07142857142857142}, {'rxName': 'ACETAMINOPHEN/CODEINE', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.04081632653061224}, {'rxName': 'ACETAMINOPHEN/CODEINE', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.12244897959183673}, {'rxName': 'ACETAMINOPHEN/CODEINE', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.11904761904761904}, {'rxName': 'ACETAMINOPHEN/CODEINE', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.006802721088435374}, {'rxName': 'PRAVASTATIN SODIUM', 'diagnosis': 'highBPDiagnosed', 'precision': 0.689419795221843}, {'rxName': 'PRAVASTATIN SODIUM', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.34812286689419797}, {'rxName': 'PRAVASTATIN SODIUM', 'diagnosis': 'chdDiagnosed', 'precision': 0.22184300341296928}, {'rxName': 'PRAVASTATIN SODIUM', 'diagnosis': 'miDiagnosed', 'precision': 0.11945392491467577}, {'rxName': 'PRAVASTATIN SODIUM', 'diagnosis': 'anginaDiagnosed', 'precision': 0.10580204778156997}, {'rxName': 'PRAVASTATIN SODIUM', 'diagnosis': 'strokeDiagnosed', 'precision': 0.10921501706484642}, {'rxName': 'PRAVASTATIN SODIUM', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.07508532423208192}, {'rxName': 'PRAVASTATIN SODIUM', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.10921501706484642}, {'rxName': 'PRAVASTATIN SODIUM', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.24914675767918087}, {'rxName': 'PRAVASTATIN SODIUM', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.030716723549488054}, {'rxName': 'SIMVASTATIN (FILM-COATED)', 'diagnosis': 'highBPDiagnosed', 'precision': 0.7542662116040956}, {'rxName': 'SIMVASTATIN (FILM-COATED)', 'diagnosis': 'diabetesDiagnosed', 'precision': 0.310580204778157}, {'rxName': 'SIMVASTATIN (FILM-COATED)', 'diagnosis': 'chdDiagnosed', 'precision': 0.1945392491467577}, {'rxName': 'SIMVASTATIN (FILM-COATED)', 'diagnosis': 'miDiagnosed', 'precision': 0.14675767918088736}, {'rxName': 'SIMVASTATIN (FILM-COATED)', 'diagnosis': 'anginaDiagnosed', 'precision': 0.08873720136518772}, {'rxName': 'SIMVASTATIN (FILM-COATED)', 'diagnosis': 'strokeDiagnosed', 'precision': 0.15699658703071673}, {'rxName': 'SIMVASTATIN (FILM-COATED)', 'diagnosis': 'emphysemaDiagnosed', 'precision': 0.051194539249146756}, {'rxName': 'SIMVASTATIN (FILM-COATED)', 'diagnosis': 'asthmaDiagnosed', 'precision': 0.08191126279863481}, {'rxName': 'SIMVASTATIN (FILM-COATED)', 'diagnosis': 'otherHDDiagnosed', 'precision': 0.24573378839590443}, {'rxName': 'SIMVASTATIN (FILM-COATED)', 'diagnosis': 'heartFailureDiagnosed', 'precision': 0.04436860068259386}]\n"
     ]
    }
   ],
   "source": [
    "drug_precisions = list()\n",
    "\n",
    "# Iterate through each dx and each drug - O(n^2)\n",
    "# There's plenty of room to optimize this code if it gets run frequently\n",
    "for drug in drugs.rxName:\n",
    "    # get number of users for the drug\n",
    "    users = float(subj_and_meds[subj_and_meds['rxName'] == drug]['rxName'].size)\n",
    "    # checked that these counts are equal to the counts above - commented it out now\n",
    "    for diagnosis in diagnoses:\n",
    "        # get number of users of the drug who have the diagnosis\n",
    "        fil_dx_and_rx = ((subj_and_meds[diagnosis] == True) & (subj_and_meds['rxName'] == drug))\n",
    "        users_with_dx = subj_and_meds[fil_dx_and_rx]['rxName'].size\n",
    "        this_precision = users_with_dx / users\n",
    "        drug_precisions.append({'rxName': drug, 'diagnosis': diagnosis, 'precision': this_precision})\n",
    "        \n",
    "# print(drug_precisions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           diagnosis  precision        rxName\n",
      "0    highBPDiagnosed   0.335616  AZITHROMYCIN\n",
      "1  diabetesDiagnosed   0.097677  AZITHROMYCIN\n",
      "2       chdDiagnosed   0.060453  AZITHROMYCIN\n",
      "3        miDiagnosed   0.035736  AZITHROMYCIN\n",
      "4    anginaDiagnosed   0.033949  AZITHROMYCIN\n"
     ]
    }
   ],
   "source": [
    "# Convert list of dict rows to pd.DataFrame. \n",
    "# (Want to do this all at once since extending a DataFrame is an expensive operation.)\n",
    "precisions = pd.DataFrame(drug_precisions)\n",
    "print(precisions.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 diagnosis  precision        rxName\n",
      "669  heartFailureDiagnosed   0.204188    CARVEDILOL\n",
      "916     emphysemaDiagnosed   0.211039  ADVAIR DISKU\n",
      "324        anginaDiagnosed   0.296117        PLAVIX\n",
      "325        strokeDiagnosed   0.307443        PLAVIX\n",
      "323            miDiagnosed   0.401294        PLAVIX\n",
      "322           chdDiagnosed   0.529126        PLAVIX\n",
      "698       otherHDDiagnosed   0.552632      WARFARIN\n",
      "917        asthmaDiagnosed   0.675325  ADVAIR DISKU\n",
      "501      diabetesDiagnosed   0.965591         ACTOS\n",
      "930        highBPDiagnosed   0.970297    DIOVAN HCT\n"
     ]
    }
   ],
   "source": [
    "# Now get the max precision for each diagnosis. \n",
    "# It would be cleaner to just groupby diagnosis and get the max precision,\n",
    "#   but that wouldn't yield the drug name for each max.\n",
    "# Instead, we'll sort our precisions and then take the max for each diagnosis.\n",
    "\n",
    "sorted_ = precisions.sort_values(by='precision')\n",
    "max_precisions = sorted_.drop_duplicates('diagnosis', keep='last').sort_values(by='precision')\n",
    "print(max_precisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABC0AAAFKCAYAAAA5RaVOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xm8pnPdwPHPjEH2VBNKT3tfbVSWRJhsUUokSZJEG2lP\nQuHJEyqVFNMgFFlT2VLZeSwRsuRbkUo9MTF2mmbmPH/8fre55zjLfWbOfZ9r5nzer9d5nfu+7mv5\nXsvvWr7X73ddE/r6+pAkSZIkSWqaiWMdgCRJkiRJ0kBMWkiSJEmSpEYyaSFJkiRJkhrJpIUkSZIk\nSWokkxaSJEmSJKmRTFpIkiRJkqRGmjTWAUiSpJGJiBcAdwA3104Tgf8A387ME2s/BwF/an0fSxHx\nQuDrmfnOiHgOcEZmrjeC4VcDvgE8r3aaAeybmVd0IdZjgFMy89cRMQ04OjOvb+8+yHBPzteCzq8k\nSZprQl9f31jHIEmSRqAmLW7JzGXbuj0fuBDYOzPPHKvYBhIRU4AjM/NV8zn8rcB+mXlW/b4hcDbw\nwsy8f9QCfep07wK2y8zrRjjcFBZgfiVJ0lzWtJAkaRGQmX+JiC8BnwPOjIjjKYmNr0fErsCHgSWA\nZwCHZOZREbEY8DXg7cCDwDXAKzJzSkRcAlwFrA/8F3A58P7MnBMR7wC+DCwGPAR8OjOvrTUijgWe\nBkwAjgGm1v/PjYgLahy3ZOayETEJOAzYCpgF/C/wscyc2W/2VgGWaZvXyyJie2A2QESsBxxa+5kD\nHJCZ50TELsA2tdtLgZnAzpl5S0RsC+xXf5sNfK6O9xLgSOC1wHOAkyJi5zr+I4HXActn5p512lsA\nBwLvBm4BVhhsfmv/+wLvpNSOuavO7z8Gi2fwNS5J0vjgMy0kSVp03AS8ur1DRCwL7A68JTNfS7m4\nPqz+vBuwJvAq4A3Ai/uN78XAlDrOjYGNamLiaOCdmbk68CXgZxGxPCVhcnZmrgm8BdgQ6KvTuSMz\n39xv/B+r01+jxrBcja+/PYDvRMQ/IuK0iNgT+E1mPhgRKwI/AN6Xma+jJGCOioj/qsNuBHy81nq4\nssYIJVnzscxcC9i/zueTMnNf4B/AezPzmrafjgHeHRFL1O8fAKa1DTd7sPmtyY9XA+tk5muA8+r4\nho1HkqTxyqSFJEmLjj7gsfYOmfkIpSbDWyPiv4F9gVazkrcAJ2bmE7V2w9R+4zs7M+dk5sPAnyi1\nNDYGLszMO+v4LwLupSQfzgI+HxE/AbYF9srMOUPEuynww8x8vE7n3Zn5w/49ZeaPKbUtdgZuB3YF\nbqvNZN5Qf/tpRNxISQT0AavXwa/PzLvr59/WeQA4BTirPqtiReYmcoZU5/sm4O01YbJJHVcntgLW\nBa6rsX4ciAWJR5KkRZ1JC0mSFh1rM/fhnABExKrAjcDzgSsoTRBaZlGacbTM7je+x9s+99V+Bzp3\nmAgsnpnnUJphnEZpXnFzRPSvvdFuVh1vK9aVImKVfvGvFhGH1MTKrzPzS7VGxc3AdpQmKr/PzNe0\n/iiJgQuGmIdWTYr1geuAXYCrIqLT86JjKAmUHYGzamKoE4sBh7bFuVaNYUHjkSRpkeXBUJKkRUBE\nvIzSrOAb/X5aC5gOfCUzL6Dc7ac+z+JcYKeIWLI+X2IX2pIIg7gI2DwiXlTHszHlrR7XRMTJwLsz\n8xRK04+H6m+zgMUHGNevgR3r9CcCRwHv6dfPPcCHImK7tnl9BrASpebE1cBL68M5iYjXAH+kPI9i\nQBExqT5kc5nMPLrG+vIBYhws7rMoNUt2p61pSAfDXQDsVpvSABwE/HAE8UiSNO6YtJAkaeG0VETc\nWP9+CxwP7JOZ5/br75fA3UBGxA2Uh2pOB15Sh7kGuIHyEMyZ9Gte0l9m3ka5qP5JRNwCHAK8LTMf\nBP4beG9E3FTHexZwKXArMDsirmXemh1Tgevr383A/wFH9JveDEqTlA9GxF31TSK/Br6WmRdl5nTK\ngy2/Vqf7Q8rzLf4yxDzMAj4JnFyX3enArpn57369/hQ4NSI27zf8v4FTgYmZee0Akxhsfo8BzgGu\nrvOxOrDLCOKRJGnc8ZWnkiSNU/Vi/NmZ+aP6/dvAE5m599hGJkmSVPjKU0mSxq9bgc9FxOco5wQ3\nAR8d25AkSZLmsqaFJEmSJElqJJ9pIUmSJEmSGsmkhSRJkiRJaiSTFpIkSZIkqZEW2QdxTp/+sA/r\nkCRJkiSpYSZPXm7C8H0V1rSQJEmSJEmN1NWaFhHxeuDQzJwSES8Bjgf6gFuAPTJzTkTsDnwYmAV8\nJTPPiYhVgdOA2cAOmfn3iNgJmJWZp3QzZkmSJEmS1Axdq2kREZ8HjgGeVjsdDuyXmRsAE4CtI2Jl\nYC9gfeDNwFcjYklge+CwOsz2EbEU8Hbg1G7FK0mSJEmSmqWbzUPuALZt+74mcGn9fD6wKbAOcGVm\n/jszHwT+BKwOPAIsVf8eBT4FfDszfU6FJEmSJEnjRNeah2TmmRHxgrZOE9qSDg8DKwDLAw+29dPq\nfjLwTUrzkMOA/YDLI+Jo4LrMPGa46a+44tJMmrTYAs+HJEmSJEkaG718e8icts/LAQ8AD9XP83TP\nzEeA3QEi4jvAwcCRwFbAGRHx48x8dKiJzZjx2CiGLkmSJEmSRsPkycsN31PVy7eH3BARU+rnLYHL\ngWuBDSLiaRGxAvByykM6AYiIVwGPZ+YdlKYifcBiwJI9jFuSJEmSJI2BXta0+AwwLSKWAH4PnJGZ\nsyPiCEoCYyKwb2Y+0TbMF4E96ucTgKsozUPu72HckiRJkiRpDEzo61s0n205ffrDi+aMSZIkSZK0\nEJs8ebkJnfbby+YhkiRJkiRJHTNpIUmSJEmSGsmkhSRJkiRJaqRePohTkiRJkqTGmnPSH8Y6hIXa\nxPe+bNTHadJCkiRJksbI3T97fKxDWKituvVSYx2CuszmIZIkSZIkqZFMWkiSJEmSpEYyaSFJkiRJ\nkhrJpIUkSZIkSWokkxaSJEmSJKmRTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJJMWkiRJkiSp\nkUxaSJIkSZKkRjJpIUmSJEmSGsmkhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmSpEYyaSFJkiRJkhrJ\npIUkSZIkSWokkxaSJEmSJKmRTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJJMWkiRJkiSpkUxa\nSJIkSZKkRjJpIUmSJEmSGsmkhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmSpEYyaSFJkiRJkhrJpIUk\nSZIkSWokkxaSJEmSJKmRTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJJMWkiRJkiSpkUxaSJIk\nSZKkRjJpIUmSJEmSGsmkhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmSpEYyaSFJkiRJkhrJpIUkSZIk\nSWqkSb2cWEQsDpwAvACYDewOzAKOB/qAW4A9MnNOREwF1gC+l5knRsQKwHczc6dexixJkiRJksZG\nr2tavAWYlJnrAQcBBwOHA/tl5gbABGDriHgmsBKwHrBrHXYf4JAexytJkiRJksZIr5MWfwAmRcRE\nYHngP8CawKX19/OBTYEnKLVAlgCeiIgXActk5i09jleSJEmSJI2RnjYPAR6hNA25HXgWsBWwYWb2\n1d8fBlbIzEcj4mzgROBAYF/gqxFxBKVZyX6Z+ehQE1pxxaWZNGmx7syFJEmSJI2Cu3l8rENYqE2e\nvNyoju+eUR3b+DPa6wN6n7T4FHBBZu4TEc8DLqLUpmhZDngAIDOnAlMjYj3gTmAT4LLa347AtKEm\nNGPGY6McuiRJkiSpSaZPf3isQ1CbTtfHSJIbvW4eMgN4sH6+H1gcuCEiptRuWwKX9xvm05TnXixN\nqWXRByzb9UglSZIkSdKY6nVNi28Cx0XE5ZQaFl8ErgOmRcQSwO+BM1o9R8QOwNmZ+XhEnA6cCswB\nduhx3JIkSZIkqccm9PX1Dd/XQmj69IcXzRmTJEmStMi4+2c+02JBrLr1UqM6vjkn/WFUxzfeTHzv\nyzrqb/Lk5SZ0PM75jkaSJEmSJKmLTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJJMWkiRJkiSp\nkUxaSJIkSZKkRjJpIUmSJEmSGsmkhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmSpEYyaSFJkiRJkhrJ\npIUkSZIkSWokkxaSJEmSJKmRTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJJMWkiRJkiSpkUxa\nSJIkSZKkRjJpIUmSJEmSGsmkhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmSpEYyaSFJkiRJkhrJpIUk\nSZIkSWokkxaSJEmSJKmRTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJJMWkiRJkiSpkSaNdQCS\nJEmSeuO0Kx4b6xAWatu/cemxDkEad6xpIUmSJEmSGsmkhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmS\npEYyaSFJkiRJkhrJpIUkSZIkSWokkxaSJEmSJKmRTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElq\nJJMWkiRJkiSpkUxaSJIkSZKkRjJpIUmSJEmSGsmkhSRJkiRJaiSTFpIkSZIkqZEm9XqCEbEP8HZg\nCeB7wKXA8UAfcAuwR2bOiYipwBrA9zLzxIhYAfhuZu7U65glSZIkSVLv9bSmRURMAdYD1gc2Ap4H\nHA7sl5kbABOArSPimcBKtd9d6+D7AIf0Ml5JkiRJkjR2et085M3AzcBZwNnAOcCalNoWAOcDmwJP\nUGqBLAE8EREvApbJzFt6HK8kSZIkSRojvW4e8izg+cBWwAuBnwMTM7Ov/v4wsEJmPhoRZwMnAgcC\n+wJfjYgjgNmUmhmP9jh2SZIkSZLUQ71OWtwH3J6ZM4GMiCcoTURalgMeAMjMqcDUiFgPuBPYBLis\n9rcjMG2oCa244tJMmrTYKIcvSZIkLcweG+sAFmqTJy836uO8m8dHfZzjyWivk3tGdWzjTzfKSK+T\nFlcAn4iIw4FVgGWACyNiSmZeAmwJXNxvmE8D7wM+AtxLadKy7HATmjHDHbIkSZKk0TN9+sNjHYL6\ncZ00S6frYyTJjZ4mLTLznIjYELiWknzYA/gzMC0ilgB+D5zR6j8idgDOzszHI+J04FRgDrBDL+OW\nJEmSJEm91/NXnmbm5wfovNEg/Z7S9vluyltHJEmSJEnSONBR0iIing/sCTyD8lpSADJz10EHkiRJ\nkiRJWgCd1rQ4Dbi8/vUN068kSZIkSdIC6zRpsXhmfrarkUiSJEmSJLWZ2GF/V0TE2+rDMiVJkiRJ\nkrqu05oW21GeaUFEtLr1ZeZi3QhKkiRJkiSpo6RFZj6n24FIkiRJkiS16/TtIUsDXwY2qcNcBOyf\nmY92MTZJkiRJkjSOdfpMiyOBZYBdgfcDSwBHdysoSZIkSZKkTp9psWZmrtH2fc+IuK0bAUmSJGnR\n8aHLbhrrEBZq399wjeF7kqRFWKc1LSZGxNNbX+rnWd0JSZIkSZIkqfOaFocDv4mInwMTgLcBX+1a\nVJIkSZIkadzrqKZFZv4A2Aa4E/gzsG1mHtfNwCRJkiRJ0vg2ZNIiIraq/3cGXgc8DDwIvLZ2kyRJ\nkiRJ6orhmoesDZwDvGmA3/qAE0c9IkmSJEmSJIZJWmTml+v/D7S6RcQKwKqZeWuXY5MkSZIkSeNY\nRw/ijIgPAusDewM3AA9HxJmZuV83g5MkSRqJD1z687EOYaH3g43ePtYhSJL0pE5fefox4LPAe4Cf\nAa8GtuhWUJIkSZIkSZ0mLcjM+4G3AOdm5ixgqa5FJUmSJEmSxr1Okxa3RsQ5wIuAX0fEacB13QtL\nkiRJkiSNd50mLXYFDgPWzcyZwA9rN0mSJEmSpK4Y8kGcEfGhzPw+8MXaaUpEtH5+LXBQF2OTJEmS\nJEnj2HBvD5nQ778kSZIkSVJPDNk8JDOn1o8HAzdk5oHAd4G/YS0LSZIkSZLURZ0+0+L7wDvbvr8J\nOGr0w5EkSZIkSSqGax7SsnZmvhogM/8FvC8ifte9sCRJkiRJ0njXaU2LiRGxSutLRDwbmNOdkCRJ\nkiRJkjqvaXEwcENEXEF5KOc6wCe6FpUkSZIkSRr3OqppkZknA68DfgycAKyTmT/pZmCSJEmSJGl8\n6yhpERFLALsAWwOXArvXbpIkSZIkSV3R6TMtvgssS6lt8R/gJcCx3QpKkiRJkiSp06TFmpn5ReA/\nmfkY8H7gtd0LS5IkSZIkjXedJi36anOQvvr9WW2fJUmSJEmSRl2nSYtvAb8GVo6IbwHXAd/sWlSS\nJEmSJGnc6/SVp+cD1wNvAhYD3paZv+taVJIkSZIkadzrNGlxeWa+HLitm8FIkiRJkiS1dJq0uCki\ndgauAR5vdczMv3YlKkmSJEmSNO51mrR4PbAOMKGtWx/wolGPSJIkSZIkiWGSFhHxHOBI4FHgCuAL\nmflALwKTJEmSJEnj23BvD/kBcDvwWWBJ4PCuRyRJkiRJksTwzUOem5lvBoiIC4Ebux+SJEmSJEnS\n8DUtZrY+ZOZ/2r9LkiRJkiR103BJi/76uhKFJEmSJElSP8M1D3llRNzZ9v259fsEoC8zfXuIJEmS\nJEnqiuGSFi/rSRSSJEmSJEn9DJm0yMy/9CoQSZIkSZKkdiN9poUkSZIkSVJPDNc8pCsi4tnA9cBm\nwCzgeMpDPm8B9sjMORExFVgD+F5mnhgRKwDfzcydxiJmSZIkSZLUWz2vaRERiwNTgcdrp8OB/TJz\nA8oDPreOiGcCKwHrAbvW/vYBDulxuJIkSZIkaYyMRfOQrwNHA/+o39cELq2fzwc2BZ6g1AJZAngi\nIl4ELJOZt/Q4VkmSJEmSNEZ62jwkInYBpmfmBRGxT+08ITP76ueHgRUy89GIOBs4ETgQ2Bf4akQc\nAcym1Mx4dKhprbji0kyatFhX5kOSpJa3nPWVsQ5hoXbeNvuNdQjqZ/Lk5cY6BLUZ/fXx2CiPb3zp\nRvm4+8kK6Jofo71O7hnVsY0/3SgjvX6mxa5AX0RsCryGkpR4dtvvywEPAGTmVGBqRKwH3AlsAlxW\n+9sRmDbUhGbMcIcsSVLTTZ/+8FiHoH5cJ83i+mgW10fzuE6apdP1MZLkRk+bh2Tmhpm5UWZOAW4E\ndgbOj4gptZctgcv7DfZpynMvlqbUsugDlu1JwJIkSZIkacyMydtD+vkMMC0ilgB+D5zR+iEidgDO\nzszHI+J04FRgDrDDmEQqSZIkSZJ6ZsySFrW2RctGg/RzStvnu4H1uxyWJEmSJElqiLF4e4gkSZIk\nSdKwTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJJMWkiRJkiSpkUxaSJIkSZKkRjJpIUmSJEmS\nGsmkhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmSpEYyaSFJkiRJkhrJpIUkSZIkSWokkxaSJEmSJKmR\nTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJJMWkiRJkiSpkUxaSJIkSZKkRjJpIUmSJEmSGsmk\nhSRJkiRJaqRJYx2AJKlz3714u7EOYaG3x5vOGOsQJEmS1CFrWkiSJEmSpEYyaSFJkiRJkhrJ5iGS\nhnTpOe8a6xAWahttdfpYhyBJkiQttKxpIUmSJEmSGsmkhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmS\npEYyaSFJkiRJkhrJpIUkSZIkSWokkxaSJEmSJKmRTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElq\nJJMWkiRJkiSpkUxaSJIkSZKkRjJpIUmSJEmSGsmkhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmSpEYy\naSFJkiRJkhrJpIUkSZIkSWokkxaSJEmSJKmRTFpIkiRJkqRGMmkhSZIkSZIaaVIvJxYRiwPHAS8A\nlgS+AtwGHA/0AbcAe2TmnIiYCqwBfC8zT4yIFYDvZuZOvYxZvXXfaa7eBfXM7X801iFIkiRJ0qjo\ndU2LnYD7MnMDYAvgSOBwYL/abQKwdUQ8E1gJWA/YtQ67D3BIj+OVJEmSJEljpKc1LYDTgTPq5wnA\nLGBN4NLa7Xxgc+CXNbYlgCci4kXAMpl5y6hHdMbPRn2U48p2W491BJIkSZKkRVRPkxaZ+QhARCxH\nSV7sB3w9M/tqLw8DK2TmoxFxNnAicCCwL/DViDgCmE2pmfHoUNNaccWlmTRpsWFjmj6/MyMAJk9e\nblTHd9+ojm18Gu11ogXj+mge10mzuD6ax3XSLKO/Ph4b5fGNL90oH3fz+KiPczwZ7XVyz6iObfzp\nRhnpdU0LIuJ5wFmUZ1WcHBGHtf28HPAAQGZOBaZGxHrAncAmwGW1vx2BaUNNZ8YMd8i9MH36w2Md\ngvpxnTSL66N5XCfN4vpoHtdJs7g+msX10Tyuk2bpdH2MJLnR02daRMRKlKYfe2fmcbXzDRExpX7e\nEri832Cfpjz3YmlKLYs+YNnuRytJkiRJksZSr2tafBFYEdg/Ivav3T4BHBERSwC/Z+4zL4iIHYCz\nM/PxiDgdOBWYA+zQ27AlSZIkSVKv9fqZFp+gJCn622iQ/k9p+3w3sH6XQpMkSZIkSQ3T61eeSpIk\nSZIkdcSkhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmSpEYyaSFJkiRJkhrJpIUkSZIkSWokkxaSJEmS\nJKmRTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJJMWkiRJkiSpkUxaSJIkSZKkRjJpIUmSJEmS\nGsmkhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmSpEYyaSFJkiRJkhrJpIUkSZIkSWokkxaSJEmSJKmR\nTFpIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJJMWkiRJkiSpkUxaSJIkSZKkRjJpIUmSJEmSGsmk\nhSRJkiRJaiSTFpIkSZIkqZFMWkiSJEmSpEYyaSFJkiRJkhrJpIUkSZIkSWokkxaSJEmSJKmRTFpI\nkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJJMWkiRJkiSpkUxaSJIkSZKkRjJpIUmSJEmSGsmkhSRJ\nkiRJaiSTFpIkSZIkqZFMWkiSJEmSpEYyaSFJkiRJkhrJpIUkSZIkSWokkxaSJEmSJKmRTFpIkiRJ\nkqRGMmkhSZIkSZIayaSFJEmSJElqpEljHQBAREwEvgesAfwb2A14CXAQ8Fdg+8ycExFHAl/PzLvG\nKlZJkiRJktQbTalp8Q7gaZn5BuALwDeAjwGbA38H1oiI1YGHTFhIkiRJkjQ+NCVp8UbgFwCZeTWw\nFvAIsFT9e5SSzDh0rAKUJEmSJEm9NaGvr2+sYyAijgHOzMzz6/e/Am8F9gV+B9wIvBCYDbwGOCEz\nrxqjcCVJkiRJUg804pkWwEPAcm3fJ2bmzcAOEbEYcBrlORfHAe8Cfg68pedRSpIkSZKknmlK85Ar\nqUmIiFgXuLnttw8Bx9fPE4E+YJleBidJkiRJknqvKTUtzgI2i4j/BSYAHwCIiOWBKZn57vr9n5QE\nx/fGKlBJkiRJktQbjXimhSRJkiRJUn9NaR4iSZIkSZI0D5MWkiRJkiSpkZryTIvGiIgpwEcyc4e2\nbocAt1Nevfr2zDxokGF3AVbLzC8MMf6ZQOvZHcsC38zMH9VhDwLupDxs9Gn1t9MGGc+mwEnA7+u4\nJtX+z4iINYEtMvPgEcx6Y9V1chpwG2VeFwe+lZmnRcRrWMB10tbv04CdMvOYUYz988CngBdm5hND\n9PdqYMXMvGy0pj3WIuKVwGHA0pRt/TzgAOD5wCmZuW5bvx8BVs7MA9rKCMBSwAXAlzNzwLZsQ5Wd\niLiLsv4HXfYDjO8nmblt53O68Kpl62LgPZl5Slv33wG/zcxdIuISyj7x9kHGcQllHT9aO80C3g+8\njH770g7i2QL4r8z8/sjnZuHQ6T5hkGF3Ae7PzJ+PQhy7YLkhIr4AbEo5rswBPpuZ1490nzw/y6zf\n8JewiJSjfsfslumZ+a4FGOddLMDy7ZWI2B74AfDSzPzHAL9vAeyQmbuMYJxjsj472VdFxH8Ba2Tm\n2cMdK0Y5thuBKzNzj0F+v5qynO8awThPAXbOzJmjE2XH030h8HXgmZT90E3A3pn58Ggv34g4APhn\nZh7d1u1qYAdgCnOPCa0XHxyYmRcNMq4NgH0ys/UihX2AzwHPzsxZdT/wycx8RwdxTQJ+BSwJvDUz\nZwzT/y50eCwc6rouM48fbvghxjvgMaLuq/5KOZ5Q4xzw2Ngq28Av6XdePFoiYiLwBWBLYDZlve5V\n39LZNRHxz8xcuR5jLwJewRDXYwNtm/2ZtBiBzLyRkrhYEPdn5hSAiFgB+ENEnFR/O7m1MiPiGcDv\nIuL0wS7WgF9l5k61/+WAyyLi9sy8Hrh+AeNsmotaO5yIWBa4NCL+MErrpGVlyqt1Ry1pAewEnEI5\nIBw/RH/vBP4JLBJJi4h4OmW+t83MP9ZXF58OfBj4xTCDt5eRCcDRwJ7Ad4YYZsCyMz+xL4wXXgvo\ndsr2eQo8eSAe6Ruadm6dSEXER4HPUl5NPSKZOdy2sSjodJ/wFAtygjWIcV1uIuIVwNuB9TOzrybB\nTwDWYGz2yYtSObooR5BoWYTsDhxBefPdAaMxwjFcn53sqzYGVgPO7lFMRMT6lLcMbhwRy2Xmw6Mx\n3rHYXiNiKUoZ3y0zr6nd3g/8GNiK3i/f9mPCSpTrio0y858D9Hs1sHpETMzMOcCbKRen6wOXAm9i\n+PO9lucAy2fmmp303IVj4fwY6hixeScJ1lbZjogXjG5o8/g88Cxgo8ycExFrAz+LiMjM/3RxugBk\n5iHw5PF2gZi0GIH2bF1EfJByIXU/MBM4tfa2bkT8EpgMHDVMZnx5YEY9Wer/29OBx4dIWMyjZmSn\nAdtFxMrALpm5U0TsDHwc+DeQlIvGnwCHZuaV9RWznwM+CEwDVqDsPI7IzO9HxBXAb4DVKXfLt8vM\nv3USU7dk5iMRMZUyr09n7jrZE9iWcsH1L2CbOsgbIuJCyvI+IDPPjYiNgIMpWcc7KMtlX+AVEfEl\n4NvAsZQIuUMsAAAUDElEQVTMN9SsZET8AHgJpQbAtzPzh4PFWbeXOygX3T+iHvQj4vXAtyiZ7L9T\n1s8uwMyI+C1lHXwFeAK4D9iVkn0/tQ7ztDrPo5Ws6YatKSetfwTIzNl1W5xJ2b46UsvGN4DjGDpp\n0e7JstMqVxHxKuBwYDHKzvuj9f82mdl6W9FvgS2A3wGrUg5EB1KSYhdRai+N6bbfJTcBERErZOaD\nlBPVkyjZ//nxDOCR9g6DlM1TKGXo0ohYC9if8iap1Sjb+o+AdYDtgS0zc/v5jKcxBton1LtnNwKv\nouyj3pWZf4mI/SnLaTrlDvz+lDth/6QkmvamlKcXUe7QHDzQdp6ZrVpLwxmP5eZByna+a0T8IjNv\njIh1IuK5zLtPPg74A2V5f4Sy7pannEPt134nstYa2xx4D7Au/Y4zIzhJXCTLUd3eb6Js748Al1Mu\ndp5OWW5bA+8AlqNsawdl5pl18KPqXWko8/5d4KR6TH855W71pyg1HWZRjpc7ZubfIuKrwAaUbfnw\nzDy9g1hmU25iPJ1y3PpuZh41xLy9kLLeDgWuj4iDM/M/NbbjKLVoHgVmRMTbGbgcbc9T1/GOlPV5\nNOXi9T7gvMw8rMPFPmKD7Ks+Rqn9M4dyXvgpyh3cpaO8/Q/gy/VidxlKGfgvYB/KOejz6vg2piQG\nv52ZR0XEdsAelPOcPspy+dcQ4e0OnAH8rcZzZI35YMoy/Btl2yEirqOct95Vp7MB8DXgKMq51CqU\nMvzTVm2eGuMz69+wd/0X0FuBS1sJC4DMPCEiPhoRL2aY5ZuZdw6xbd9L2R7fnJmzRxpYZt4TEWdS\nkidPuZlXt+0bKImLuyjl7ZTWPAEbAbtEeRPkU8pRvxj/A7y0ntv/NwOvn1uYux++nSGOhSOZz0GW\n30bAl+s8LUspgzOZW/4upu0YkZnXdjCdgfbf7WW71d9d1FplMbem/12U/cpM4PuUmhydHls+BKxZ\nE0tk5m8iYu26/oabz/Mob/R8RT03OBK4EPgTJTk7gbnXKY/U2F5ZY1qyzs/x1JtibfP4GUoydBZw\nWWbuPdzyA59pMZiNI+KS1h9lJT4pIp5FKSTrUw5s7Xcl/0M56G0DfHKAcT+jjvcyykneqW2/7Vh/\nu4iyMbxvhHHfQ91R1zifDexHeW3sG4HHKDUJplF29FA2xmmUC/GTMnNz4C2Ug1HLVZm5CXAJ8O4R\nxtQt/ed1IuUAs2lmvp5yMrl2/flRSvXftwJH1rv+0yi1ADaiJA52oewAbsvS1OSLwIWZ+SZKgT+q\n1mbZkLLT2YKysxjKbsAxmZnAv2uyAmAqsGuN81xgJUpC43DKicD322K7lLIO16HsGLakHNxHeie8\n155DqWL4pMx8JOdWu3xFvzL26SHGNc+6HsRwZeeVwGfqdnwoZbs/l5LQWqZmnu/MzHtrrLMo5f4b\nlBO2zzb4wms0nAlsW2u2rMPc5jmdOrFt+a9KOSkEhiybA+2HAMjMGygnOSdQksMfnJ+ZaqDB9gnX\nZuamlOqx74mINShlfW3KBdwqA4zr+ZQ7PetS7qTAwNv5UMZ1ucnMv1NrWgBXRcTtwFa1+/GUE9hr\nKSdz/13vxO5HqeW4IfAu4NhabqAkoDeo3Wcy8HFmKItSOZrnPCoiPtf227V1m1oSeCwzN6M0Jdmo\n/r4MsBnl/OrwKFXHAY7NUgvvrvp7+7zvSrnRsBlwLeWY/2VghYjYktLE4Y2Uu7/71hsew8XyEspF\n0OY1lqGOU1CW73GZ+QBwFeVcAcp6/FIt461961PKEeVCZrDzmJaVKXdxu5awqAbaV30A2DMz38Dc\npsmHUO7Ot2oEnZuZGwPnA9vVbqtS9lUfpZSf91H2bx+uv7+Mkhx4I2XZv3mwoOoF8Bspy+8HdZzU\nhN2GlOW1MyXpBWWb2Ll+bpWP1YBv1HX9Ico5VX8XZeZ6XU5YQLnQvmOA7n+mJHmGXL7DbNs/zsxN\nB0hYfLrf+ddQd8CHO//6FWWft3n9/CtgsyjNrZ+epXnOUOXox7VcfJRy/v1hBl8/7fvhdgMdC/sb\n8LpuiOX3Skpz8SmUG72tpm2t8ncg8x4j+vtl2/TeOsw1SqeelpkbUI6tIzm2LN1/O87M++rH4ebz\nMMq16gYRsSRlGZ1dp79HHe48ynLfpsa4LiVRufRAwUSpzbs9sF79e2lEbNXJArCmxcDmqdZYM13t\nXkIpXI/V39tP8H9bs1H/ZOAV1l71fXngfyPiV/W3J6tlzafnA3e3fX8xcHNmttrIXkbZqU8DDolS\nHXhdys7iucBeEfFOSrZs8bbx3FD//42SKW2CeeY1S5WnmcCPI+IRykGyNQ9XZKmxcm9EPEjZAa8C\nnBbljuJSlB1tu1dTdnKtJM0zstRm+SQlqbA8ZccxoIhYkZL8eXZEfJxSe2JP4BrKsxt+X+M+tvb/\n9jros4CH6kkzlHX2P5QdwkuBn1ESY1/paCmNnb8Ar2vvUO9CPY+SIb6tVQ7qbx+h7CQH0n+7Hshw\nZefvwP4R8TjlZOahLLU/zqCcWL6BtpN9gHpn5or6WxOqW3fTyZQ7G3dS7jaO1JPV2ltq2RqqbF4A\nfK3uhzYA9mLei+ajgS9RTlJGpfrvWBpinwDz7mNXBl5OuZiaDTxe7xb2d3NNEsyq2zUMsJ0PE9a4\nLjcR8RLKPO1av68FnB8RFw/Qe9b/L6fURCIz/x4RDwHPrr9tCsyqy+jZDH+c6W9RKkdDNQ/5bf3/\nAHOfezGDcmcVyp3nOcA9ETGDUnMV5jZ7bZ1fXQJ8JyImUy6Gvki5W7o3Zdt7sHZ7NbBmvViBstxe\n0EEs9wCfjIhtKWWp/bxoHvVmyE7AnyPibZS7x3tSbky9jJJIAbgSePlA5WiY85iWP2eXn7kwxL7q\nA8Bn67H8KkrSor/2ddQ6pt9S7+o+ANyRmTPrem2t73uBE+o8r1bHPZj3Um64nlO/rxIRm1Bu/lxX\nt5uHIqLVXv9k4PKIOIbS/OCWiOgD9otSY7qPgddrDtCtG/5OuVHQ30so50ov6Ne9//IdatsebB4O\nz6c+02Iwz2duGRnIryg16x4FjszMB+t59haU8glDl6OBYvw/Bl8/A/U/0LGwv8Gu6wZbfn8Hjqjb\n5HMp5RY6L39PaR7SQdkeSHsZa837ZEZ2bJkREctn5pPnAxGxDaXGRCfz2UoOrwz8PMvzSl4OfK9O\nf3Hgj5Rt4FqAzPxrRAx2w2I14OqsNUMi4nJK8mRY1rSYP38CVouIpWr2rH2H01FzjuphyoFyiQUN\nKMrzMT5IqTLXcgfwqohoJU82Av5QT4R/QrlIObPu5D8HXJ6Z76u/tReUkcxT19Vkz+6UZyS0uq0O\nvCMz30252zWRufOwdu1nZUqm9l+Ui+Ct64XzwZRqzHOYWyZupzyUbgolI/ijiFiFUsVqG0qtjcPa\n7gD1txPlrtDmmbkF8Hpg83py9Y+IeGmNae+682hN+1/A8nVaUNcZpVr4/9VM9VcoiYwmOwfYIkr1\nRiJicUpNkleNZCS1fH2WflXL5sMRlId5vp/SFra1bRxLOcF/Pf12+lGaTr2Kkjj6zAJOv9Ey807K\n3c29GCIZNz8GK5t1v3M6ZT/00wHuBn2t/u0SES8azZjGyID7BMoJSP997K3A2hExsd7deO0A4xto\nvzzYdj6/FvVyszql9l3rGPwHyjF5NvMeD2DuQ9V+T0kOEKUZyYqUWnBQmjbMqEnYwY4z82URK0fD\nnVOsCU+2qV+eclH7lOHqzYgfUrbTX9aT4K0p5zKbUJbL3pTj+cV1PWxMeUjoHQONs5/PUGqa7lTH\nNVR5egvwm8x8U2ZukZnrACvV9XYbJTEB895dnaccDXMe0zKH7htsX/VRStPUjSj7pPV4ajkZaHkO\nuozrueuBlKriuwGPM/Ry3g14W13GW1CW0x6UZbxO3WcuQ609kKXJ4/XANyk1M6A0Pzixnu9ePMj0\nerGcodyI2iwinryOiIjdgH/V4/Jwy3eobXuB5qGeh25NuZM+oHoD7jmUfX4ruXEB5bytlbQeqhwN\nFONQ62eg/hfkGmWw5TcN+ECWB+b+oy2G9un3XzeD6rBstzxBScZNAF7Tb3ow8mPLCZRmRRNqLOtR\nzsefoLP5vJBS3ndlbjOhpCTZp1Buqp5D234uIp5DSYIM5Hbg9RExqca0IeXYOyyTFvMhS1u7Qyl3\nJH9ByXJ13E41SnWhiynVBK+nFMpBRcS+EbHZAD9tVsd1IeVBPvtm5p/a4ryXcoF7cc2kLkepJQDl\nYLktpZ0ldfhPRGm28jGgr+1Ergk2bpvXsykn0u0Z1z8Bj0bElZST6P9j7rMTlopS3fbnlHZfs4FP\nAOdGqSXzMeAWyonREhFxKGUnsH3Nvv6i/v5PYOU6zK+Ar9eM4xeiPAG43W6UkykAaq2cMynJlg8D\nx0XEpZQdwXmU7WBPSnJid+AndV42pezAbwJ2q/F8Dfjq/C3G3qgZ3fcD02rMV1PmYdD2wG1aZeQi\nSvOYP1G2VyLiW1EeljdSPwJOrxndl1G3jcz8c/39Z/XknzqdFeo0d6Uk9N5X78Iuyk4FnpeZAx48\nImLlKE9XH6mhyuZxzLsfak1ra8p6+iqlrJ5UE18Ls8H2CS/t32OWp3qfRyk3Z1GOL50cYwbczi03\nA8vMn1CO47+p2+cFwOfaLnT2jIg39RvsfyjHo8uAnwIfqnf5WvainLC/mAGOM+OoHPVvHnJJlIcO\ndmLleqw/F/jYAImYdsdTqoYfW79fBxxUjx8foTwL6WzgkbodXw/0dVjr5Gxgj3qs/iTlTu6SEbFL\nlLcXtNudtvJdHUM5rn+Gcuf4QkoCABiwHA21jntpsH3VPZRaCxdRzpeuoSQzt46I+X2I5UOUu7tX\nUcri48zdb13S3mNEvI6SqLu1rfOZlOYi91GaTPyGcpPj3rZ+plGao7SaY58OfL2W4c0Yvvlp12Tm\nI8DbKNvHlRFxDWUbeU/tZbjlO7/b9mBaTQYvpNQo+0Bm3j/MfusPwK059xl851Nq2l7aFuNTytEQ\nMfRy/Qy2/H5E2davpFw7DVQOBztGDGQkZfswyvH/PEqtr3nUfcVIji1fozxT5qo6n1+hvHVxZifz\nWdfrGcASmdlKiH2U0pzxCkoTpt9REnD31W34W5TkylPU85vTKOX+Wkpzv58OsizmMaGvr1E30RcK\nUe6u753lwWcTKHeU9s0uva4ySpWq+zLz0mF7Vs9FadrxSA7yWiiNnihVVc9vT86pN+p+79DMbPrd\n84VelKYF22Xm9+rJ3a3Axpn51/kcn+WmISxHQ4sRvKa89v9cyl3ZTboa2LzTXB1YKzOPG7ZnzbeI\n+FZmDvRsOPWY+63mGw/ryGdazId6d32ZKE97nknJNs9PO/BOXTe/J6vqiRtdPz3zM5f1mJlA24MB\n1VX/ojQP+Q2l6usxC7jdW26aw3I0SuoNnQMpNSp66X7mNjVQ93xjrAPQk9xvNd8iv46saSFJkiRJ\nkhrJZ1pIkiRJkqRGMmkhSZIkSZIayaSFJEmSJElqJB/EKUmSAIiIF1BeYXdb7bQU5XVme2bmPfUV\nph/JzN3GKEQi4jxgt8z8xwiHuwRYFXiEcv7zb2D/zDxv1IOUJEmjxgdxSpIk4MmkxSWZ+YL6fQLw\nP8AbM3ODMQxtgdWkxQGZeUn9vhZwAbBBZt42xKCSJGkMWdNCkiQNKDP7IuLLwD0RsTrwDMqF/5SI\n2Ag4GFgaWBH4fGaeHhGrAifVbjcDG2XmqhFxAPBc4KXA8ymvcj04IiYC3wI2obzi9YeZeWjbeJYB\n5gB7ZebVEXEXMAVYHvg+5VzmCeADmfnHEczbdRFxKrAb8Ok63muA1wDvA05rS94cUIc5ICK2Bw4C\nHgN+C0zKzF06na4kSRoZn2khSZIGlZkzgT8Cq/X76eOUZhqvAz4IfKl2/zZwamauDpxBSVS0rA5s\nDrwe+EJEPB34CPC8+ts6wDsj4q11nOdk5lrA54E39pv+p4Bv1N+/A6w7H7N3S7/5Oj8zA7h3oJ4j\nYjJzEyxrUZI4kiSpi0xaSJKk4fQBj/frthPwqojYH/gMsGztvhnwQ4DMPAt4oG2YizNzZmbeC9wP\nrABsDByfmbMz8zFK7YpNgF8Dn42IkymJjyP7Tf9c4MiIOBaYCZw8CvN1zTD9bwBclZl/z8w5wAnz\nMU1JkjQCJi0kSdKgImIJIJj7cM6Wyyk1I66nNBOZULvPZvDziyfaPvfVYfr3O4HS5OJK4BWU5068\nGzi7vafMPAN4HXAt8Eng6I5naq7VmXe+WgmMVmwti9f/Q82bJEnqAg+8kiRpQPV5EwcCV2fmHW3d\nnwG8DPhSffvG5sBi9edfATvW/rYEnj7MZC4C3h8Ri0XE0sB7gYsj4jDgfZl5ArAnJUHRHtupwDqZ\nORXYv//vHczbOsB2wLED/PwAsGJETI6IJYEtavf/BdaOiFXqQ0p3oCQ4JElSl/ggTkmS1O45EXFj\n/bwYcAM1CdGSmfdHxDHArRHxEHAVsHRELEOp9XBiRHwIuIl5m4cMZColAXITpUbDjzLzrIi4Djg5\nInah1HD4aL/h/gc4pjZPmQV8GqDG9fPM/PkA0zomIh6hJBoeBd6dmXf17ykzH4yIrwG/Af5Gqc1B\nZk6PiL0oiZkngLuAGcPMnyRJWgC+8lSSJI2aelH/68y8LSJeB0zLzDV7OP1tgJmZeW4Xxv1MYC/g\nwMycExFHAH/MzO+M9rQkSVJhTQtJkjSa/gj8OCLmUGoj7N7j6S8OnNelcd9Pae5yS0TMorzydFqX\npiVJkrCmhSRJkiRJaigfxClJkiRJkhrJpIUkSZIkSWokkxaSJEmSJKmRTFpIkiRJkqRGMmkhSZIk\nSZIayaSFJEmSJElqpP8HEX/CUvf3KOIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e5fb290>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# FIXME!\n",
    "\n",
    "formatted_dx = ['High BP, Diovan', 'Diabetes, Actos', 'CHD, Plavix', 'MI, Plavix',\n",
    "                'Angina, Plavix', 'Stroke, Plavix', 'Emphysema, Advair', 'Asthma, Advair',\n",
    "                'Other HD, Warfarin', 'Heart Failure, Carvedilol']\n",
    "\n",
    "plt.figure(figsize=(18,5))\n",
    "plt.title('Diagnostic Sensitivities')\n",
    "\n",
    "ax = sns.barplot(x=max_precisions.diagnosis, y=max_precisions.precision, data=precisions)\n",
    "ax.set_ylabel(\"Precision\"); ax.set_xlabel(\"Diagnosis, Drug\")\n",
    "ax.set_xticklabels(formatted_dx)\n",
    "ax.set_yticklabels(['0%', '20%', '40%', '60%', '80%', '100%'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gut check - these make sense - Diovan HCT is a combo ACE inhibitor and diuretic, two extremely common classes of drugs for high blood pressure; Plavix is an anticoagulant, so it's used for various heart diseases; advair is a bronchodilator, so it's used for respiratory disorders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3) Let's model one disease.\n",
    "\n",
    "First we have to pick a disease. If I want to pick one that's easy to model, it would be nice to choose one that has lots of instances and that is also well-distinguished by a small number of criteria. As you can see below, HBP would be an obvious choice, but HBP is really common, even in people who are mostly healthy. It would be cool to train a more complex model on it, but for the sake of simplicity, I'll model diabetes, which is a classic stats/ML problem. \n",
    "\n",
    "By the way, with regards to model performance, we probably care more about recall than precision in this instance - we really want to pick up cases of the disease based on medicines and don't care all that much if we falsely flag the potential presence of a disease. Also, raw accuracy isn't far off from worthless, since (most) of these disease are pretty rare. Diabetes affects around 10% of people in a random sample of Americans, so a model that predicts y=0 is 90% accurate in a random samples (and 74% accurate in our sample - our sample isn't a random sample of Americans, as we'll soon find out)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects with highBPDiagnosed:\n",
      "93623\n",
      "Number of subjects with diabetesDiagnosed:\n",
      "40116\n",
      "Number of subjects with chdDiagnosed:\n",
      "22039\n",
      "Number of subjects with miDiagnosed:\n",
      "14725\n",
      "Number of subjects with anginaDiagnosed:\n",
      "11603\n",
      "Number of subjects with strokeDiagnosed:\n",
      "14319\n",
      "Number of subjects with emphysemaDiagnosed:\n",
      "9594\n",
      "Number of subjects with asthmaDiagnosed:\n",
      "28376\n",
      "Number of subjects with otherHDDiagnosed:\n",
      "31770\n",
      "Number of subjects with heartFailureDiagnosed:\n",
      "4940\n",
      "Number with disease highBPDiagnosed = 93623\n",
      "Number with disease diabetesDiagnosed = 40116\n",
      "Number with disease chdDiagnosed = 22039\n",
      "Number with disease miDiagnosed = 14725\n",
      "Number with disease anginaDiagnosed = 11603\n",
      "Number with disease strokeDiagnosed = 14319\n",
      "Number with disease emphysemaDiagnosed = 9594\n",
      "Number with disease asthmaDiagnosed = 28376\n",
      "Number with disease otherHDDiagnosed = 31770\n",
      "Number with disease heartFailureDiagnosed = 4940\n"
     ]
    }
   ],
   "source": [
    "# Let's pick.\n",
    "# Again, syntax here is slightly awkward because of one-hot encoded \n",
    "#   disease columns and potential for each subject to have multiple \n",
    "#   diagnoses.\n",
    "for diagnosis in diagnoses:\n",
    "    subj_with_dx = (\n",
    "        subj_and_meds\n",
    "            .groupby([diagnosis])  # For this diagnosis, True or False\n",
    "            .id  # Arbitrary column to count.\n",
    "            .count()  # Take the count.\n",
    "            [True]  # Only care about the count that have this disease.\n",
    "    )\n",
    "    print('Number of subjects with %s:' % diagnosis)\n",
    "    print(subj_with_dx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cols found to drop.\n",
      "Index([u'id', u'age', u'diabetesDiagnosed', u'rxStartYear', u'rxName',\n",
      "       u'rxQuantity', u'rxForm', u'isFemale', u'd__Amer Indian/Alaska Native',\n",
      "       u'd__Asian', u'd__Black', u'd__Multiple',\n",
      "       u'd__Native Hawaiian/Pacific Islander', u'd__White', u'd__DIVORCED',\n",
      "       u'd__DIVORCED IN ROUND', u'd__MARRIED', u'd__MARRIED IN ROUND',\n",
      "       u'd__NEVER MARRIED', u'd__SEPARATED', u'd__SEPARATED IN ROUND',\n",
      "       u'd__WIDOWED', u'd__WIDOWED IN ROUND'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "diabetes_df = subj_and_meds.copy()\n",
    "\n",
    "# Drop other diagnoses from the set - while it would be lovely to have diagnosis info\n",
    "#   for the other diseases to train our model, it's not terribly realistic.\n",
    "other_diag = [diag for diag in diagnoses if diag is not 'diabetesDiagnosed']\n",
    "drop_cols(diabetes_df, other_diag)\n",
    "print(diabetes_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count     169868\n",
       "unique         2\n",
       "top        False\n",
       "freq      129752\n",
       "Name: diabetesDiagnosed, dtype: object"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes_df['diabetesDiagnosed'].describe()\n",
    "\n",
    "# We have (169868-129752)/169868 = 23.6% with diabetes in our sample; \n",
    "#   this is more than 2x the population proportion!\n",
    "# In our sample, diabetesDiagnosed=True isn't a terribly rare class.\n",
    "#   (But we should still be wary of class imbalance.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Do our non-drug variables carry interesting information?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x10fecb6d0>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfUAAAEFCAYAAAD62n4IAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ12SpJow1CVJqglDXZKkmvj/7QFakqvOm4AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fecb690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfAAAAHwCAYAAABZrD3mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDdmeDJ8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1106a7690>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "\n",
    "# let's see if our other fields have any useful info...\n",
    "ax = sns.barplot('isFemale','diabetesDiagnosed', data=diabetes_df)\n",
    "ax.set_ylabel('Proportion w/ diabetes')\n",
    "\n",
    "# Below regression takes around a while to run - feel free to comment out this code\n",
    "# it just shows diabetes incidence increases pretty dramatically with age.\n",
    "# This isn't exactly shocking :)\n",
    "sns.lmplot(x='age', y='diabetesDiagnosed', data=diabetes_df, size=7, logistic=True, n_boot=80, ci=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make our train-test split - 100k+ rows so we have a good amount of data. Of course, we'l use cross-validation to get the most out of our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset --> \n",
      "\n",
      "              id  age  rxStartYear  rxQuantity  isFemale  \\\n",
      "147565  85146101   59       2008.0        90.0      True   \n",
      "1231    10255101   66       2010.0        60.0     False   \n",
      "152541  86112101   61       2008.0        10.0      True   \n",
      "\n",
      "        d__Amer Indian/Alaska Native  d__Asian  d__Black  d__Multiple  \\\n",
      "147565                             0         0         0            0   \n",
      "1231                               0         0         0            0   \n",
      "152541                             0         0         0            1   \n",
      "\n",
      "        d__Native Hawaiian/Pacific Islander  d__White  d__DIVORCED  \\\n",
      "147565                                    0         1            0   \n",
      "1231                                      0         1            0   \n",
      "152541                                    0         0            0   \n",
      "\n",
      "        d__DIVORCED IN ROUND  d__MARRIED  d__MARRIED IN ROUND  \\\n",
      "147565                     0           0                    0   \n",
      "1231                       0           1                    0   \n",
      "152541                     0           1                    0   \n",
      "\n",
      "        d__NEVER MARRIED  d__SEPARATED  d__SEPARATED IN ROUND  d__WIDOWED  \\\n",
      "147565                 0             1                      0           0   \n",
      "1231                   0             0                      0           0   \n",
      "152541                 0             0                      0           0   \n",
      "\n",
      "        d__WIDOWED IN ROUND  \n",
      "147565                    0  \n",
      "1231                      0  \n",
      "152541                    0  \n",
      "\n",
      "Dataset --> \n",
      "\n",
      "             id  age  rxStartYear  rxQuantity  isFemale  \\\n",
      "66379  45239101   62       2009.0        30.0      True   \n",
      "73405  46556102   45       2008.0        60.0      True   \n",
      "29974  16762101   47       2008.0        30.0      True   \n",
      "\n",
      "       d__Amer Indian/Alaska Native  d__Asian  d__Black  d__Multiple  \\\n",
      "66379                             0         0         1            0   \n",
      "73405                             0         0         0            0   \n",
      "29974                             0         0         1            0   \n",
      "\n",
      "       d__Native Hawaiian/Pacific Islander  d__White  d__DIVORCED  \\\n",
      "66379                                    0         0            1   \n",
      "73405                                    0         1            0   \n",
      "29974                                    0         0            0   \n",
      "\n",
      "       d__DIVORCED IN ROUND  d__MARRIED  d__MARRIED IN ROUND  \\\n",
      "66379                     0           0                    0   \n",
      "73405                     0           1                    0   \n",
      "29974                     0           0                    0   \n",
      "\n",
      "       d__NEVER MARRIED  d__SEPARATED  d__SEPARATED IN ROUND  d__WIDOWED  \\\n",
      "66379                 0             0                      0           0   \n",
      "73405                 0             0                      0           0   \n",
      "29974                 0             1                      0           0   \n",
      "\n",
      "       d__WIDOWED IN ROUND  \n",
      "66379                    0  \n",
      "73405                    0  \n",
      "29974                    0  \n",
      "\n",
      "Dataset --> \n",
      "\n",
      "147565    False\n",
      "1231       True\n",
      "152541    False\n",
      "Name: diabetesDiagnosed, dtype: bool\n",
      "\n",
      "Dataset --> \n",
      "\n",
      "66379    True\n",
      "73405    True\n",
      "29974    True\n",
      "Name: diabetesDiagnosed, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "# For now, drop our qualitative variables - obviously there's a tremendous amount of info\n",
    "#   in rxName, so we'll want to add them back later.\n",
    "dropped_qual = diabetes_df.copy().drop(['rxName', 'rxForm'], axis=1)\n",
    "\n",
    "# TODO: refactor train-test split into function; \n",
    "# we'll still need the variables as globals so we can refer to them outside the function.\n",
    "\n",
    "# Split training and test\n",
    "# Large dataset (>100k rows), so 20% should be adequate for our test.\n",
    "# Since we have a nontrivial class imbalance, we'll want to stratify on our outcome.\n",
    "# (Of course, it's best practice to always stratify classification outcomes.)\n",
    "all_x = dropped_qual.copy().drop(['diabetesDiagnosed'], axis=1)\n",
    "all_y = dropped_qual.copy()['diabetesDiagnosed']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "    all_x, all_y, test_size=.2, random_state=2001, stratify=all_y.values)\n",
    "\n",
    "for dataset in [X_train, X_test, Y_train, Y_test]:\n",
    "    print(\"\\nDataset --> \\n\")\n",
    "    print(dataset.head(3))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split our train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "We're doing this to gain some insight into the underlying correlates of diabetes, not because it'll be an ideal model. (It won't.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Normalized dataset --> \n",
      "\n",
      "              id  age  rxStartYear  rxQuantity  isFemale  \\\n",
      "147565  85146101   59       2008.0        90.0      True   \n",
      "1231    10255101   66       2010.0        60.0     False   \n",
      "152541  86112101   61       2008.0        10.0      True   \n",
      "\n",
      "        d__Amer Indian/Alaska Native  d__Asian  d__Black  d__Multiple  \\\n",
      "147565                             0         0         0            0   \n",
      "1231                               0         0         0            0   \n",
      "152541                             0         0         0            1   \n",
      "\n",
      "        d__Native Hawaiian/Pacific Islander  d__White  d__DIVORCED  \\\n",
      "147565                                    0         1            0   \n",
      "1231                                      0         1            0   \n",
      "152541                                    0         0            0   \n",
      "\n",
      "        d__DIVORCED IN ROUND  d__MARRIED  d__MARRIED IN ROUND  \\\n",
      "147565                     0           0                    0   \n",
      "1231                       0           1                    0   \n",
      "152541                     0           1                    0   \n",
      "\n",
      "        d__NEVER MARRIED  d__SEPARATED  d__SEPARATED IN ROUND  d__WIDOWED  \\\n",
      "147565                 0             1                      0           0   \n",
      "1231                   0             0                      0           0   \n",
      "152541                 0             0                      0           0   \n",
      "\n",
      "        d__WIDOWED IN ROUND  \n",
      "147565                    0  \n",
      "1231                      0  \n",
      "152541                    0  \n",
      "\n",
      " Normalized dataset --> \n",
      "\n",
      "             id  age  rxStartYear  rxQuantity  isFemale  \\\n",
      "66379  45239101   62       2009.0        30.0      True   \n",
      "73405  46556102   45       2008.0        60.0      True   \n",
      "29974  16762101   47       2008.0        30.0      True   \n",
      "\n",
      "       d__Amer Indian/Alaska Native  d__Asian  d__Black  d__Multiple  \\\n",
      "66379                             0         0         1            0   \n",
      "73405                             0         0         0            0   \n",
      "29974                             0         0         1            0   \n",
      "\n",
      "       d__Native Hawaiian/Pacific Islander  d__White  d__DIVORCED  \\\n",
      "66379                                    0         0            1   \n",
      "73405                                    0         1            0   \n",
      "29974                                    0         0            0   \n",
      "\n",
      "       d__DIVORCED IN ROUND  d__MARRIED  d__MARRIED IN ROUND  \\\n",
      "66379                     0           0                    0   \n",
      "73405                     0           1                    0   \n",
      "29974                     0           0                    0   \n",
      "\n",
      "       d__NEVER MARRIED  d__SEPARATED  d__SEPARATED IN ROUND  d__WIDOWED  \\\n",
      "66379                 0             0                      0           0   \n",
      "73405                 0             0                      0           0   \n",
      "29974                 0             1                      0           0   \n",
      "\n",
      "       d__WIDOWED IN ROUND  \n",
      "66379                    0  \n",
      "73405                    0  \n",
      "29974                    0  \n",
      "\n",
      " Normalized dataset --> \n",
      "\n",
      "147565    False\n",
      "1231       True\n",
      "152541    False\n",
      "Name: diabetesDiagnosed, dtype: bool\n",
      "\n",
      " Normalized dataset --> \n",
      "\n",
      "66379    True\n",
      "73405    True\n",
      "29974    True\n",
      "Name: diabetesDiagnosed, dtype: bool\n",
      "0.593306646259\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.766     0.644     0.700     25951\n",
      "       True      0.240     0.364     0.289      8023\n",
      "\n",
      "avg / total      0.642     0.578     0.603     33974\n",
      "\n",
      "[('age', 6.2033913779375457e-05), ('rxQuantity', 2.0160215799022857e-05), ('rxStartYear', 1.080605020961186e-05), ('d__NEVER MARRIED', -6.7139635208516233e-07), ('d__White', -5.0018513020634522e-07), ('d__Black', 4.5915361365064964e-07), ('d__WIDOWED', 3.4427461081279073e-07), ('isFemale', -3.1160106014185239e-07), ('d__DIVORCED', 1.537909523861212e-07), ('d__WIDOWED IN ROUND', 7.7935604065506666e-08), ('d__SEPARATED', 7.2772061093636999e-08), ('d__MARRIED', 5.5146081097351865e-08), ('d__Amer Indian/Alaska Native', 4.1613911307577813e-08), ('d__MARRIED IN ROUND', -3.095100368847204e-08), ('d__Asian', -1.845101762170867e-08), ('d__SEPARATED IN ROUND', 1.8231307298067554e-08), ('d__Native Hawaiian/Pacific Islander', 1.6660190432015383e-08), ('d__Multiple', 1.1147354693465299e-08), ('d__DIVORCED IN ROUND', -9.8643387242391467e-09), ('id', -5.900488616708205e-10)]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length mismatch: Expected axis has 0 elements, new values have 20 elements",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-6e8ff6f44b61>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# TODO: make this work and delete above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0mcoef_importances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mcoef_importances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0mcoef_importances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'importance'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcoef_importances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jan/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   3092\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3094\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3095\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3096\u001b[0m             \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/src/properties.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.AxisProperty.__set__ (pandas/_libs/lib.c:45255)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Users/jan/anaconda/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36m_set_axis\u001b[0;34m(self, axis, labels)\u001b[0m\n\u001b[1;32m    471\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 473\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    474\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_clear_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jan/anaconda/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mset_axis\u001b[0;34m(self, axis, new_labels)\u001b[0m\n\u001b[1;32m   2834\u001b[0m             raise ValueError('Length mismatch: Expected axis has %d elements, '\n\u001b[1;32m   2835\u001b[0m                              \u001b[0;34m'new values have %d elements'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2836\u001b[0;31m                              (old_len, new_len))\n\u001b[0m\u001b[1;32m   2837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2838\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Length mismatch: Expected axis has 0 elements, new values have 20 elements"
     ]
    }
   ],
   "source": [
    "# TODO: change model to sklearn.linear_model.LogisticRegressionCV\n",
    "# We'll use SciKit-Learn's LogisticRegressionCV model. \n",
    "# It uses CV to set its regularization strengths.\n",
    "\n",
    "# logistic = LogisticRegression(random_state=2001, solver='liblinear', class_weight='balanced', n_jobs=-1)\n",
    "logistic = LogisticRegressionCV(random_state=2001, solver='liblinear', class_weight='balanced', n_jobs=-1)\n",
    "\n",
    "\n",
    "# Need to normalize for a logistic regression's coefficients to be meaningful.\n",
    "diabetes_norm = dropped_qual.copy()\n",
    "diabetes_norm = (diabetes_norm - diabetes_norm.mean()) / diabetes_norm.std(ddof=0)\n",
    "# Don't want to normalize our outcome, so set it to the non-normalized version :)\n",
    "diabetes_norm['diabetesDiagnosed'] = dropped_qual['diabetesDiagnosed']\n",
    "\n",
    "# Split train and test again.\n",
    "all_x_norm = diabetes_norm.drop(['diabetesDiagnosed'], axis=1)\n",
    "all_y_norm = diabetes_norm['diabetesDiagnosed']\n",
    "X_train_norm, X_test_norm, Y_train_norm, Y_test_norm = train_test_split(\n",
    "    all_x, all_y, test_size=.2, random_state=2001)\n",
    "\n",
    "for dataset in [X_train, X_test, Y_train, Y_test]:\n",
    "    print(\"\\n Normalized dataset --> \\n\")\n",
    "    print(dataset.head(3))\n",
    "\n",
    "logistic.fit(X_train_norm, Y_train_norm)\n",
    "Y_pred = logistic.predict(X_test_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.593306646259\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.766     0.644     0.700     25951\n",
      "       True      0.240     0.364     0.289      8023\n",
      "\n",
      "avg / total      0.642     0.578     0.603     33974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# First, with more interpretable metrics based on classification accuracy.\n",
    "\n",
    "print(logistic.score(X_test_norm, Y_test_norm))\n",
    "print(classification_report(Y_test, Y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score:\n",
      "(33974,)\n",
      "0.528046267198\n",
      "LogLoss:\n",
      "0.691388348598\n"
     ]
    }
   ],
   "source": [
    "# Then, with more useful metrics based on predicted probabilities. \n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "probs = logistic.predict_proba(X_test_norm)\n",
    "\n",
    "print('AUC Score:')\n",
    "print(roc_auc_score(Y_test_norm, probs[:, 1:]))\n",
    "print('')\n",
    "\n",
    "print('LogLoss:')\n",
    "print(log_loss(Y_test_norm, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AUC is barely over .50, indicating the logistic regression classifier isn't much better than chance. Not shocking - we haven't given it drug info, just demographics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('age', 6.2033913779375457e-05), ('rxQuantity', 2.0160215799022857e-05), ('rxStartYear', 1.080605020961186e-05), ('d__NEVER MARRIED', -6.7139635208516233e-07), ('d__White', -5.0018513020634522e-07), ('d__Black', 4.5915361365064964e-07), ('d__WIDOWED', 3.4427461081279073e-07), ('isFemale', -3.1160106014185239e-07), ('d__DIVORCED', 1.537909523861212e-07), ('d__WIDOWED IN ROUND', 7.7935604065506666e-08), ('d__SEPARATED', 7.2772061093636999e-08), ('d__MARRIED', 5.5146081097351865e-08), ('d__Amer Indian/Alaska Native', 4.1613911307577813e-08), ('d__MARRIED IN ROUND', -3.095100368847204e-08), ('d__Asian', -1.845101762170867e-08), ('d__SEPARATED IN ROUND', 1.8231307298067554e-08), ('d__Native Hawaiian/Pacific Islander', 1.6660190432015383e-08), ('d__Multiple', 1.1147354693465299e-08), ('d__DIVORCED IN ROUND', -9.8643387242391467e-09), ('id', -5.900488616708205e-10)]\n"
     ]
    }
   ],
   "source": [
    "# Now look at importances.\n",
    "\n",
    "# Flatten logistic regression coefficients to a list and show corresponding quantities.\n",
    "# I'm loosely calling them 'importances.'\n",
    "def print_coef_importances(importances, columns):\n",
    "    coefficients = zip(columns, importances.flatten())\n",
    "    sorted_coef = sorted(coefficients, key=(lambda tup: abs(tup[1])), reverse=True)\n",
    "    print(sorted_coef)\n",
    "\n",
    "print_coef_importances(logistic.coef_, X_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's move on to \n",
    "\n",
    "## Tree-Based Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=10,\n",
       "            min_samples_split=20, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=100, n_jobs=-1, oob_score=False,\n",
       "            random_state=2001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest is a great black box classifier \n",
    "#   (and in a slightly altered form, regressor). \n",
    "# We should be able to get good results with little tuning.\n",
    "# Note: we should be using balanced class weights here to compensate for class imbalance,\n",
    "#   but I'm intentionally omitting that to show how it skews results.\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    min_samples_split=20, \n",
    "    min_samples_leaf=10, \n",
    "    max_features='auto', \n",
    "    random_state=2001, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "Y_pred = None  # Make sure we aren't using our old logistic y-hats.\n",
    "# No need to normalize. \n",
    "random_forest.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.816094660623\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.812     0.987     0.891     25951\n",
      "       True      0.864     0.262     0.403      8023\n",
      "\n",
      "avg / total      0.825     0.816     0.776     33974\n",
      "\n",
      "AUC Score:\n",
      "0.863780424102\n",
      "\n",
      "LogLoss:\n",
      "0.401109195697\n"
     ]
    }
   ],
   "source": [
    "# Score it.\n",
    "\n",
    "Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "print(random_forest.score(X_test, Y_test))\n",
    "print(classification_report(Y_test, Y_pred, digits=3))\n",
    "\n",
    "probs = random_forest.predict_proba(X_test)\n",
    "\n",
    "print('AUC Score:')\n",
    "print(roc_auc_score(Y_test, probs[:,1:]))\n",
    "print('')\n",
    "\n",
    "print('LogLoss:')\n",
    "print(log_loss(Y_test, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For simplicity's sake, we'll look at F1-score, since it captures both precision and recall pretty well. We'll also pay attention to accuracy and recall since they can be easily explained to non-data scientists.\n",
    "\n",
    "We'll also look at log-loss and AUC, which describe model quality rather than the performance of a particular cutoff for predicting classes. (In other words, they describe the accuracy of our predicted probabilities of class membership rather than our ultimate class labels.) \n",
    "\n",
    "With our first naive model, we're already getting .86 AUC, which is very respectable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('age', 0.3577093357527954), ('id', 0.29247474708816801), ('rxStartYear', 0.10669557814615584), ('rxQuantity', 0.1065093341713839), ('d__NEVER MARRIED', 0.021151961353537304), ('isFemale', 0.020272319287124554), ('d__Black', 0.016388611164839129), ('d__White', 0.015970265269041023), ('d__WIDOWED', 0.012336259083978635), ('d__MARRIED', 0.0097865329548047619), ('d__DIVORCED', 0.0076916834185343274), ('d__SEPARATED', 0.0052070261919044359), ('d__Asian', 0.0046158120198111705), ('d__Amer Indian/Alaska Native', 0.0044406406277527448), ('d__DIVORCED IN ROUND', 0.0041289514773978561), ('d__WIDOWED IN ROUND', 0.0038531097734076591), ('d__SEPARATED IN ROUND', 0.0032982258117143187), ('d__Multiple', 0.0030978237470242025), ('d__MARRIED IN ROUND', 0.0026873381131272394), ('d__Native Hawaiian/Pacific Islander', 0.0016844445474972995)]\n"
     ]
    }
   ],
   "source": [
    "print_coef_importances(random_forest.feature_importances_, X_test.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I included a logistic regression here so we can inspect it for information. For example, it shows that ethnicity has a pretty significant impact on the probability of having diabetes. However, as a predictive model, it's not terribly impressive. In particular, its recall for the positive class is awful.\n",
    "\n",
    "Our RF accuracy is around what we'd expect, given how little information it has. And it's using age correctly while also giving some weight to rxStartYear and rxQuantitiy. (I suspect some information about type of drug / administration method may be contained in the quantity.) \n",
    "\n",
    "It's not shocking that our recall is much better for False than True. That's just saying it's way easier to predict that someone doesn't have diabetes than that she does. Also, since False is around 3/4 of the dataset, our model's going to benefit more from assuming results will be False. \n",
    "\n",
    "We can tweak our decision threshold using predict_proba in the RF model, but let's hold off for now. First, we'll engineer our variables a bit more, and then we can think about setting thresholds.\n",
    "\n",
    "Also one major concern - one of our most important features is 'id'. That implies leakage some sort of data leakage from the ID, as it should be random. In other words, smaller ids, presumably older ones, may be less likely to have diabetes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.792664979102\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.796     0.980     0.878     25951\n",
      "       True      0.744     0.186     0.298      8023\n",
      "\n",
      "avg / total      0.784     0.793     0.741     33974\n",
      "\n",
      "AUC Score:\n",
      "0.785238158187\n",
      "\n",
      "LogLoss:\n",
      "0.447398101952\n"
     ]
    }
   ],
   "source": [
    "Y_pred = None  # Make sure we aren't using our old logistic y-hats.\n",
    "# No need to normalize. \n",
    "X_train_clean, X_test_clean = X_train.copy().drop('id', axis=1), X_test.copy().drop('id', axis=1)\n",
    "random_forest.fit(X_train_clean, Y_train)\n",
    "\n",
    "# Score it.\n",
    "\n",
    "Y_pred = random_forest.predict(X_test_clean)\n",
    "\n",
    "print(random_forest.score(X_test_clean, Y_test))\n",
    "print(classification_report(Y_test, Y_pred, digits=3))\n",
    "\n",
    "probs = random_forest.predict_proba(X_test_clean)\n",
    "\n",
    "print('AUC Score:')\n",
    "print(roc_auc_score(Y_test, probs[:,1:]))\n",
    "print('')\n",
    "\n",
    "print('LogLoss:')\n",
    "print(log_loss(Y_test, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While our AUC has dropped, it wouldn't be proper to let data leak in from our ID column. This is meant to be a useful model, not an attempt to game a Kaggle competition :)\n",
    "\n",
    "The next order of business is to deal with the rxName column.\n",
    "\n",
    "### Incorporating prescription names into our model\n",
    "\n",
    "First, let's just try label encoding our prescriptions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Dataset --> \n",
      "\n",
      "\n",
      "        age  rxStartYear  rxQuantity  isFemale  d__Amer Indian/Alaska Native  \\\n",
      "18901    51       2011.0        31.0      True                             0   \n",
      "161166   69       2008.0         9.0     False                             0   \n",
      "136061   24       2009.0       120.0      True                             0   \n",
      "36871    66       2011.0        90.0     False                             0   \n",
      "\n",
      "        d__Asian  d__Black  d__Multiple  d__Native Hawaiian/Pacific Islander  \\\n",
      "18901          0         0            0                                    0   \n",
      "161166         0         0            0                                    0   \n",
      "136061         0         0            0                                    0   \n",
      "36871          0         1            0                                    0   \n",
      "\n",
      "        d__White  d__DIVORCED  d__DIVORCED IN ROUND  d__MARRIED  \\\n",
      "18901          1            0                     0           0   \n",
      "161166         1            0                     0           1   \n",
      "136061         1            0                     0           0   \n",
      "36871          0            0                     0           0   \n",
      "\n",
      "        d__MARRIED IN ROUND  d__NEVER MARRIED  d__SEPARATED  \\\n",
      "18901                     0                 1             0   \n",
      "161166                    0                 0             0   \n",
      "136061                    1                 0             0   \n",
      "36871                     0                 0             1   \n",
      "\n",
      "        d__SEPARATED IN ROUND  d__WIDOWED  d__WIDOWED IN ROUND  rxEnc  \n",
      "18901                       0           0                    0   5331  \n",
      "161166                      0           0                    0   5748  \n",
      "136061                      0           0                    0   3682  \n",
      "36871                       0           0                    0   3923  \n",
      "\n",
      "\n",
      "Dataset --> \n",
      "\n",
      "\n",
      "        age  rxStartYear  rxQuantity  isFemale  d__Amer Indian/Alaska Native  \\\n",
      "149602   56       2008.0        60.0      True                             0   \n",
      "57205    61       2009.0        30.0     False                             0   \n",
      "125708   21       2009.0        15.0     False                             0   \n",
      "87514    34       2010.0        10.0     False                             0   \n",
      "\n",
      "        d__Asian  d__Black  d__Multiple  d__Native Hawaiian/Pacific Islander  \\\n",
      "149602         0         0            0                                    0   \n",
      "57205          0         0            0                                    0   \n",
      "125708         0         0            0                                    0   \n",
      "87514          0         0            0                                    0   \n",
      "\n",
      "        d__White  d__DIVORCED  d__DIVORCED IN ROUND  d__MARRIED  \\\n",
      "149602         1            0                     0           1   \n",
      "57205          1            0                     0           0   \n",
      "125708         1            0                     0           0   \n",
      "87514          1            0                     0           0   \n",
      "\n",
      "        d__MARRIED IN ROUND  d__NEVER MARRIED  d__SEPARATED  \\\n",
      "149602                    0                 0             0   \n",
      "57205                     1                 0             0   \n",
      "125708                    0                 1             0   \n",
      "87514                     0                 1             0   \n",
      "\n",
      "        d__SEPARATED IN ROUND  d__WIDOWED  d__WIDOWED IN ROUND  rxEnc  \n",
      "149602                      0           0                    0   5567  \n",
      "57205                       0           0                    0   7323  \n",
      "125708                      0           0                    0   1649  \n",
      "87514                       0           0                    0   6715  \n",
      "\n",
      "\n",
      "Dataset --> \n",
      "\n",
      "\n",
      "18901     False\n",
      "161166    False\n",
      "136061    False\n",
      "36871     False\n",
      "Name: diabetesDiagnosed, dtype: bool\n",
      "\n",
      "\n",
      "Dataset --> \n",
      "\n",
      "\n",
      "149602    False\n",
      "57205      True\n",
      "125708    False\n",
      "87514     False\n",
      "Name: diabetesDiagnosed, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "with_rx = diabetes_df.drop(['rxForm'], axis=1)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "with_rx['rxEnc'] = label_encoder.fit_transform(with_rx['rxName'])\n",
    "\n",
    "all_x = with_rx.drop(['diabetesDiagnosed', 'id', 'rxName'],axis=1)\n",
    "all_y = with_rx['diabetesDiagnosed']\n",
    "\n",
    "X_train_enc, X_test_enc, Y_train_enc, Y_test_enc = train_test_split(all_x, all_y, test_size=.2, random_state=2001)\n",
    "\n",
    "for dataset in [X_train_enc, X_test_enc, Y_train_enc, Y_test_enc]:\n",
    "    print(\"\\n\\nDataset --> \\n\\n\")\n",
    "    print(dataset.head(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forest benefits significantly from inclusion of drug labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.800582798611\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.802     0.981     0.883     25951\n",
      "       True      0.781     0.216     0.339      8023\n",
      "\n",
      "avg / total      0.797     0.801     0.754     33974\n",
      "\n",
      "\n",
      "[('age', 0.36056278570399025), ('rxEnc', 0.262825718365092), ('rxQuantity', 0.12031847313529757), ('rxStartYear', 0.11745041065500818), ('d__NEVER MARRIED', 0.024852817359040564), ('isFemale', 0.020551927606031355), ('d__Black', 0.018332382124160117), ('d__White', 0.017191011270011249), ('d__WIDOWED', 0.011467710559893939), ('d__MARRIED', 0.0092743445731561618), ('d__DIVORCED', 0.0065972091731750383), ('d__SEPARATED', 0.0050327254063759694), ('d__Amer Indian/Alaska Native', 0.0044432517984435201), ('d__Asian', 0.004301073009678559), ('d__DIVORCED IN ROUND', 0.0035001306260339132), ('d__WIDOWED IN ROUND', 0.003468788582554466), ('d__SEPARATED IN ROUND', 0.0029908531775029857), ('d__MARRIED IN ROUND', 0.0026996744238864594), ('d__Multiple', 0.0025743736179944599), ('d__Native Hawaiian/Pacific Islander', 0.0015643388326734323)]\n",
      "\n",
      "AUC Score:\n",
      "0.794428783614\n",
      "\n",
      "LogLoss:\n",
      "0.440975034957\n"
     ]
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    min_samples_split=20, \n",
    "    min_samples_leaf=10, \n",
    "    max_features='auto', \n",
    "    random_state=2001, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_forest.fit(X_train_enc, Y_train_enc)\n",
    "Y_pred_enc = random_forest.predict(X_test_enc)\n",
    "\n",
    "print(random_forest.score(X_test_enc, Y_test_enc))\n",
    "print(classification_report(Y_test_enc, Y_pred_enc, digits=3))\n",
    "print('')\n",
    "\n",
    "print_coef_importances(random_forest.feature_importances_, X_train_enc)\n",
    "\n",
    "probs = random_forest.predict_proba(X_test_enc)\n",
    "\n",
    "print('')\n",
    "print('AUC Score:')\n",
    "print(roc_auc_score(Y_test_enc, probs[:,1:]))\n",
    "print('')\n",
    "\n",
    "print('LogLoss:')\n",
    "print(log_loss(Y_test_enc, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.725643138871\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.883     0.739     0.804     25951\n",
      "       True      0.447     0.683     0.540      8023\n",
      "\n",
      "avg / total      0.780     0.726     0.742     33974\n",
      "\n",
      "\n",
      "[('age', 0.42200980348967621), ('rxEnc', 0.22196416618372841), ('rxQuantity', 0.11296335231539321), ('rxStartYear', 0.10945869683185157), ('d__NEVER MARRIED', 0.031287475585166299), ('isFemale', 0.019323284523234806), ('d__White', 0.016180200186202105), ('d__Black', 0.014517297219627578), ('d__WIDOWED', 0.0097029079282310252), ('d__MARRIED', 0.0092063148798403067), ('d__DIVORCED', 0.0068408432582869683), ('d__SEPARATED', 0.0043443012651767721), ('d__Asian', 0.0040051568069508674), ('d__Amer Indian/Alaska Native', 0.0036746526986122696), ('d__DIVORCED IN ROUND', 0.0036323460229164329), ('d__MARRIED IN ROUND', 0.0028012895201026196), ('d__WIDOWED IN ROUND', 0.0025395978832523703), ('d__SEPARATED IN ROUND', 0.0023741794270886797), ('d__Multiple', 0.0021776235601624902), ('d__Native Hawaiian/Pacific Islander', 0.0009965104144989106)]\n",
      "\n",
      "AUC Score:\n",
      "0.793821847772\n",
      "\n",
      "LogLoss:\n",
      "0.523457754493\n"
     ]
    }
   ],
   "source": [
    "# Let's go ahead and try balanced class weights.\n",
    "\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    min_samples_split=20, \n",
    "    min_samples_leaf=10, \n",
    "    max_features='auto', \n",
    "    class_weight='balanced',\n",
    "    random_state=2001, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "random_forest.fit(X_train_enc, Y_train_enc)\n",
    "Y_pred_enc = random_forest.predict(X_test_enc)\n",
    "\n",
    "print(random_forest.score(X_test_enc, Y_test_enc))\n",
    "print(classification_report(Y_test_enc, Y_pred_enc, digits=3))\n",
    "print('')\n",
    "\n",
    "print_coef_importances(random_forest.feature_importances_, X_train_enc)\n",
    "\n",
    "probs = random_forest.predict_proba(X_test_enc)\n",
    "\n",
    "print('')\n",
    "print('AUC Score:')\n",
    "print(roc_auc_score(Y_test_enc, probs[:,1:]))\n",
    "print('')\n",
    "\n",
    "print('LogLoss:')\n",
    "print(log_loss(Y_test_enc, probs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2.000000\n",
      "mean     0.705857\n",
      "std      0.000883\n",
      "min      0.705232\n",
      "25%      0.705544\n",
      "50%      0.705857\n",
      "75%      0.706169\n",
      "max      0.706481\n",
      "dtype: float64\n",
      "Performance of model vs. dummy: \n",
      "Error of 0.706, 0.500 for model, dummy; -41.171 percent less error.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7058565107121059"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And, finally, just add some more trees.\n",
    "# Since we're now tuning parameters, we should really be using CV.\n",
    "# Repeated k-fold is the gold standard, so we'll use it.\n",
    "# SKL 20.x implements it but wasn't available at the time of writing (2017/06),\n",
    "#   so use a homebrewed version:\n",
    "\n",
    "\n",
    "def get_repeated_k_fold_score(model, xs, ys, folds=None, iters=None,\n",
    "                              agg_inner=None, agg_outer=None, seed=None,\n",
    "                              score_func=None, fit_kwargs=None,\n",
    "                              print_description=None):\n",
    "    \"\"\"\n",
    "    Do k-fold cv a number of times and aggregate results.\n",
    "\n",
    "    :param model: SKLearn model\n",
    "    :params xs: pd.DataFrame with cols for x's, rows for examples\n",
    "    :param yx: pd.Series with col of y's, rows for examples\n",
    "    :param folds: int, number of folds in inner k-fold cv\n",
    "    :param iters: int, number of times to repeat k-fold cv process\n",
    "    :param agg_inner: agg function for the inner loop - each \n",
    "      k-fold cross-validation\n",
    "    :param agg_outer: agg function for the outer loop - combining\n",
    "      the various k-fold cross-validations\n",
    "    :param score_func: SKLearn-style scoring metric \n",
    "      (e.g. sklearn.metrics.mean_squared_error) \n",
    "      that accepts y_true, y_pred as params\n",
    "    :param fit_kwargs: kwargs to add to .fit() method of model when called\n",
    "    :param print_description: Bool, whether or not to print the cv result's \n",
    "      .describe() method's result - e.g. count, mean, std, quantiles, min/max\n",
    "    :return: aggregated final score of the inner and outer loops\n",
    "    \"\"\"\n",
    "    # Set defaults\n",
    "    folds = folds or 10\n",
    "    iters = iters or 10\n",
    "    seed = seed or 1\n",
    "    agg_inner = agg_inner or np.mean\n",
    "    agg_outer = agg_outer or np.mean\n",
    "    fit_kwargs = fit_kwargs or dict()\n",
    "    if print_description is None:\n",
    "        print_description = True\n",
    "    # If supplied a metric, convert to SKLearn scorer object.\n",
    "    # Will use greater_is_better=True so no sign flip happens.\n",
    "    if score_func is not None:\n",
    "        scorer = make_scorer(score_func, greater_is_better=True)\n",
    "    else:\n",
    "        scorer = None\n",
    "    dummy = DummyRegressor(strategy='mean')\n",
    "    all_scores = []\n",
    "    all_dummy_scores = []\n",
    "    # model.fit(xs, ys, **fit_kwargs)\n",
    "    for i in range(seed, seed + iters):\n",
    "        # Set up CV.\n",
    "        kfold = KFold(n_splits=folds, shuffle=True, random_state=i)\n",
    "        # Get CV scores and aggregate over all folds.\n",
    "        scores = cross_val_score(model, xs, ys, scoring=scorer, cv=kfold)\n",
    "        score = agg_inner(scores)\n",
    "        all_scores.append(score)\n",
    "        # Repeat for dummy model.\n",
    "        dummy_scores = cross_val_score(dummy, xs, ys, scoring=scorer, cv=kfold)\n",
    "        dummy_score = agg_inner(dummy_scores)\n",
    "        all_dummy_scores.append(dummy_score)\n",
    "    all_scores = pd.Series(all_scores)\n",
    "    if print_description:\n",
    "        print(all_scores.describe())\n",
    "    score = agg_outer(all_scores)\n",
    "    dummy_score = agg_outer(all_dummy_scores)\n",
    "    print('Performance of model vs. dummy: ')\n",
    "    percent_error = 100 * (dummy_score - score) / float(dummy_score)\n",
    "    to_interpolate = (score, dummy_score, percent_error)\n",
    "    print('Error of %.3f, %.3f for model, dummy; %.3f percent less error.' % to_interpolate)\n",
    "    return score\n",
    "\n",
    "get_repeated_k_fold_score(random_forest, X_train_enc, Y_train_enc, folds=10, iters=2,\n",
    "                              agg_inner=None, agg_outer=None, seed=2001,\n",
    "                              score_func=roc_auc_score, fit_kwargs=None,\n",
    "                              print_description=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have CV set up, we could tune our model a bit. But that's not the point of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting back to our new encoded features, note that logistic regression doesn't benefit too much from encoded drug names without further processing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.614214019751\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.883     0.739     0.804     25951\n",
      "       True      0.447     0.683     0.540      8023\n",
      "\n",
      "avg / total      0.780     0.726     0.742     33974\n",
      "\n",
      "[('d__Amer Indian/Alaska Native', 4.6100036502151118), ('d__Native Hawaiian/Pacific Islander', 4.3882438096225886), ('d__Black', 4.1946082918323464), ('d__Multiple', 4.00312068983503), ('d__Asian', 3.6767788000322703), ('d__White', 3.6540942163760453), ('d__SEPARATED', 3.0683279944537447), ('d__SEPARATED IN ROUND', 2.9380129072322618), ('d__WIDOWED IN ROUND', 2.8784851462807701), ('d__DIVORCED', 2.7712634888388572), ('d__MARRIED IN ROUND', 2.6874017503882723), ('d__MARRIED', 2.6280901673176009), ('d__DIVORCED IN ROUND', 2.6196596715053411), ('d__WIDOWED', 2.5243085519937476), ('d__NEVER MARRIED', 2.4112997799638709), ('isFemale', -0.180838939934476), ('age', 0.036794668758996611), ('rxStartYear', -0.01639758467133311), ('rxQuantity', 1.1047039198874027e-05), ('rxEnc', 6.6698788536737992e-06)]\n",
      "\n",
      "AUC Score:\n",
      "0.683131604706\n",
      "\n",
      "LogLoss:\n",
      "0.640942677814\n"
     ]
    }
   ],
   "source": [
    "logistic.fit(X_train_enc, Y_train_enc)\n",
    "Y_pred = logistic.predict(X_test_enc)\n",
    "\n",
    "print(logistic.score(X_train_enc, Y_train_enc))\n",
    "print(classification_report(Y_test_enc, Y_pred_enc, digits=3))\n",
    "\n",
    "print_coef_importances(logistic.coef_, X_train_enc.columns)\n",
    "\n",
    "probs = logistic.predict_proba(X_test_enc)\n",
    "\n",
    "print('')\n",
    "print('AUC Score:')\n",
    "print(roc_auc_score(Y_test_enc, probs[:, 1:]))\n",
    "print('')\n",
    "\n",
    "print('LogLoss:')\n",
    "print(log_loss(Y_test_enc, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another approach is to one-hot encode. But here it gets a little messy and subjective. There are at least a few way to do this:  \n",
    "\n",
    "1) pick the n most common drugs to use  \n",
    "2) pick the n most common drugs in diabetes patients to use  \n",
    "3) pick the n drugs that have the highest precision or recall when thought of as a \"test\" for diabetes  \n",
    "\n",
    "I don't really think it's an option to encode every drug - we'd have literally thousands of columns.  \n",
    "I'll start with (1) as the simplest solution, but there's certainly value to the others, and, ideally, we'd try them all."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AZITHROMYCIN                   3358\n",
       "LISINOPRIL                     2865\n",
       "AMOXICILLIN                    2687\n",
       "SIMVASTATIN                    2312\n",
       "IBUPROFEN                      2243\n",
       "PREDNISONE                     1712\n",
       "HYDROCO/APAP                   1703\n",
       "LIPITOR                        1630\n",
       "OMEPRAZOLE                     1496\n",
       "METFORMIN                      1422\n",
       "HYDROCHLOROTHIAZIDE            1281\n",
       "NAPROXEN                       1198\n",
       "ATENOLOL                       1102\n",
       "FUROSEMIDE                     1082\n",
       "LEVOTHYROXIN                    954\n",
       "APAP/HYDROCODONE BITARTRATE     951\n",
       "AMLODIPINE                      928\n",
       "HYDROCHLOROT                    852\n",
       "AMLODIPINE BESYLATE             832\n",
       "NEXIUM                          829\n",
       "Name: rxName, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Most common drugs overall:\n",
    "diabetes_df['rxName'].value_counts()[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "METFORMIN                  1158\n",
      "LISINOPRIL                  975\n",
      "SIMVASTATIN                 701\n",
      "LIPITOR                     518\n",
      "ACTOS                       449\n",
      "FUROSEMIDE                  447\n",
      "GLIPIZIDE                   431\n",
      "METFORMIN HCL               426\n",
      "ONETOUCH                    366\n",
      "LANTUS                      350\n",
      "GLYBURIDE                   342\n",
      "AZITHROMYCIN                328\n",
      "OMEPRAZOLE                  315\n",
      "HYDROCHLOROTHIAZIDE         300\n",
      "METFORMIN HYDROCHLORIDE     288\n",
      "GLIMEPIRIDE                 284\n",
      "INSULIN SYRG                268\n",
      "AMOXICILLIN                 250\n",
      "ASPIRIN                     247\n",
      "HYDROCO/APAP                245\n",
      "Name: rxName, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Mote that most of these aren't all that specific for diabetes; \n",
    "#   people with type 2 diabetes are often overweight and have other health issues.\n",
    "\n",
    "have_diabetes = diabetes_df[diabetes_df['diabetesDiagnosed'] == True]\n",
    "print(have_diabetes['rxName'].value_counts()[0:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AZITHROMYCIN    3358\n",
      "LISINOPRIL      2865\n",
      "AMOXICILLIN     2687\n",
      "SIMVASTATIN     2312\n",
      "IBUPROFEN       2243\n",
      "PREDNISONE      1712\n",
      "HYDROCO/APAP    1703\n",
      "LIPITOR         1630\n",
      "OMEPRAZOLE      1496\n",
      "METFORMIN       1422\n",
      "Name: rxName, dtype: int64\n",
      "817     3358\n",
      "3923    2865\n",
      "486     2687\n",
      "6295    2312\n",
      "3443    2243\n",
      "5632    1712\n",
      "3295    1703\n",
      "3906    1630\n",
      "5028    1496\n",
      "4235    1422\n",
      "Name: rxEnc, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# confirming that our label encoder worked correctly \n",
    "\n",
    "print(with_rx['rxName'].value_counts()[:10])\n",
    "print(with_rx['rxEnc'].value_counts()[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtering prescriptions by frequency (so we can feed them into the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0         ATENOLOL\n",
      "1     AZITHROMYCIN\n",
      "2            OTHER\n",
      "3     HYDROCO/APAP\n",
      "4     CARISOPRODOL\n",
      "5            OTHER\n",
      "6            OTHER\n",
      "7            OTHER\n",
      "8          NORVASC\n",
      "9         SEROQUEL\n",
      "10       CLONIDINE\n",
      "11       COMBIVENT\n",
      "12         DIGOXIN\n",
      "13       LORAZEPAM\n",
      "14     SIMVASTATIN\n",
      "15    HYDROCHLOROT\n",
      "16      CARVEDILOL\n",
      "17         LIPITOR\n",
      "18           OTHER\n",
      "19           OTHER\n",
      "Name: rxName, dtype: object\n",
      "(169868, 22)\n",
      "(169868, 22)\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# Re-initalize with_rx df so we can run code nonsequentially. \n",
    "with_rx = diabetes_df.drop(['rxForm'], axis=1)\n",
    "\n",
    "filtered_rx = with_rx\n",
    "\n",
    "filter_by_len = with_rx.groupby('rxName')['rxName'].filter(lambda x: len(x) >= 100)\n",
    "common_drugs = set(filter_by_len)\n",
    "filtered_rx['rxName'] = [rxName if rxName in common_drugs else 'OTHER' for rxName in filtered_rx['rxName']]\n",
    "\n",
    "print(filtered_rx.rxName.head(20))\n",
    "print(filtered_rx.shape)\n",
    "print(with_rx.shape)\n",
    "print('ATENOLOL' in common_drugs)\n",
    "print('this is not there' in common_drugs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, so we have all rx with frequency >=100. Now we have to re-encode to labels and then one-hot encode. If we didn't re-encode, our one-hot encoder would still be based on the entire list of rx's, and we'd have an inordinate number of columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No cols found to drop.\n",
      "0        ATENOLOL\n",
      "1    AZITHROMYCIN\n",
      "2           OTHER\n",
      "3    HYDROCO/APAP\n",
      "4    CARISOPRODOL\n",
      "5           OTHER\n",
      "6           OTHER\n",
      "7           OTHER\n",
      "8         NORVASC\n",
      "9        SEROQUEL\n",
      "Name: rxName, dtype: object\n",
      "0     37\n",
      "1     43\n",
      "2    220\n",
      "3    138\n",
      "4     56\n",
      "5    220\n",
      "6    220\n",
      "7    220\n",
      "8    213\n",
      "9    263\n",
      "Name: rxEnc, dtype: int64\n",
      "\n",
      "\n",
      " We'll have to add columns = \n",
      "329\n"
     ]
    }
   ],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "drop_cols(filtered_rx, ['rxEnc'])\n",
    "filtered_rx['rxEnc'] = label_encoder.fit_transform(filtered_rx['rxName'])\n",
    "\n",
    "print(filtered_rx['rxName'].head(10))\n",
    "print(filtered_rx['rxEnc'].head(10))\n",
    "\n",
    "print(\"\\n\\n We'll have to add columns = \")\n",
    "print(filtered_rx.rxEnc.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, our others are correctly encoded and our maxencoding seems reasonable.\n",
    "\n",
    "Now it's time for\n",
    "\n",
    "### One-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    169868.000000\n",
      "mean          0.001189\n",
      "std           0.034464\n",
      "min           0.000000\n",
      "25%           0.000000\n",
      "50%           0.000000\n",
      "75%           0.000000\n",
      "max           1.000000\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "rx_ohe = filtered_rx\n",
    "\n",
    "# we'll just use the dummies feature in pd\n",
    "onehot_df = pd.get_dummies(filtered_rx.rxEnc)\n",
    "\n",
    "print(onehot_df[0].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above columns are about 99.9% sparse! We might want to encode them as a sparse matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([                          u'id',                          u'age',\n",
       "                  u'diabetesDiagnosed',                  u'rxStartYear',\n",
       "                             u'rxName',                   u'rxQuantity',\n",
       "                           u'isFemale', u'd__Amer Indian/Alaska Native',\n",
       "                           u'd__Asian',                     u'd__Black',\n",
       "       ...\n",
       "                                   320,                             321,\n",
       "                                   322,                             323,\n",
       "                                   324,                             325,\n",
       "                                   326,                             327,\n",
       "                                   328,                             329],\n",
       "      dtype='object', length=353)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get cols back into the data frame\n",
    "rx_ohe = pd.concat([filtered_rx, onehot_df], axis=1)\n",
    "\n",
    "rx_ohe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training and test, again.\n",
    "X_train_ohe, X_test_ohe, Y_train_ohe, Y_test_ohe = train_test_split(rx_ohe.drop(\n",
    "        ['diabetesDiagnosed', 'id', 'rxName'],axis=1), rx_ohe['diabetesDiagnosed'], test_size=.2, random_state=2001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how our models are affected by one-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.675899217048\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.861     0.687     0.764     25951\n",
      "       True      0.387     0.641     0.483      8023\n",
      "\n",
      "avg / total      0.749     0.676     0.698     33974\n",
      "\n",
      "\n",
      "AUC Score:\n",
      "0.742683123944\n",
      "\n",
      "LogLoss:\n",
      "0.582382484001\n"
     ]
    }
   ],
   "source": [
    "logistic.fit(X_train_ohe, Y_train_ohe)\n",
    "Y_pred = logistic.predict(X_test_ohe)\n",
    "\n",
    "print(logistic.score(X_test_ohe, Y_test_ohe))\n",
    "print(classification_report(Y_test_ohe, Y_pred, digits=3))\n",
    "\n",
    "probs = logistic.predict_proba(X_test_ohe)\n",
    "\n",
    "print('')\n",
    "print('AUC Score:')\n",
    "print(roc_auc_score(Y_test_ohe, probs[:, 1:]))\n",
    "print('')\n",
    "\n",
    "print('LogLoss:')\n",
    "print(log_loss(Y_test_ohe, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our logistic couldn't make sense of our encoded prescriptions, but it's gained lots of information from one-hot encoding. At this point, it comes very close to where RF was with a single label-encoded column.\n",
    "\n",
    "Now we can try RF again. It will be painfully slow with 300+ columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.795108023783\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.791     0.994     0.881     25951\n",
      "       True      0.890     0.151     0.258      8023\n",
      "\n",
      "avg / total      0.814     0.795     0.734     33974\n",
      "\n",
      "\n",
      "AUC Score:\n",
      "0.77374064631\n",
      "\n",
      "LogLoss:\n",
      "0.454300897467\n"
     ]
    }
   ],
   "source": [
    "random_forest.fit(X_train_ohe, Y_train_ohe)\n",
    "Y_pred_ohe = random_forest.predict(X_test_ohe)\n",
    "\n",
    "print(random_forest.score(X_test_ohe, Y_test_ohe))\n",
    "print(classification_report(Y_test_ohe, Y_pred_ohe, digits=3))\n",
    "\n",
    "probs = random_forest.predict_proba(X_test_ohe)\n",
    "\n",
    "print('')\n",
    "print('AUC Score:')\n",
    "print(roc_auc_score(Y_test_ohe, probs[:, 1:]))\n",
    "print('')\n",
    "\n",
    "print('LogLoss:')\n",
    "print(log_loss(Y_test_ohe, probs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, RF was able to exploit the encodings effectively, so one-hot encoding was actually harmful (we lost the raw encodings, which actually dropped our AUC by around 2%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Feature Engineering\n",
    "\n",
    "While we aren't dealing with very many columns and probably don't have all that many features to extract, let's try making a few.\n",
    "\n",
    "For instance, we could combine 'd\\__SEPARATED' with 'd\\__SEPARATED IN ROUND' and 'd\\__WIDOWED', 'd\\__WIDOWED IN ROUND'.\n",
    "In these cases, the fact that a separation or widowing happened in a particular year probably isn't all that relevant.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RF Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have RF running well, we can tune it using CV.\n",
    "\n",
    "Interactions between these parameters are pretty minimal, so no need to grid search. \n",
    "We could use random search, but I'll do something even simpler and search over each parameter separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Try increasing trees\n",
    "\n",
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    min_samples_split=13, \n",
    "    min_samples_leaf=3, \n",
    "    max_features=.2, \n",
    "    class_weight='balanced',\n",
    "    random_state=2001, \n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Optimize params using grid search.\n",
    "\n",
    "# First, convert ROC_AUC from SKL metric to scorer API.\n",
    "roc_scorer = make_scorer(roc_auc_score)\n",
    "\n",
    "def test_params(model, param_value_dict, verbose=False):\n",
    "    \"\"\"\n",
    "    Run a grid search for a model using given param values and print results.\n",
    "    CV is stratified K-Fold in this instance.\n",
    "    (SKL is smart enough to know to prefer stratified CV in classification problems.)\n",
    "    \n",
    "    :param model: SciKit-Learn model, i.e. one that has \n",
    "      .fit() and .predict() methods\n",
    "    :param param_value_dict: dict, with keys of param names \n",
    "      and values of [values] to try for given param\n",
    "    :return: None, prints results to stdout\n",
    "    \"\"\"\n",
    "    gsearch = GridSearchCV(\n",
    "        estimator = model, \n",
    "        param_grid = param_value_dict, \n",
    "        scoring=roc_scorer,\n",
    "        n_jobs=1,  # assume model itself is multithreaded - thus only 1 job\n",
    "        iid=False, \n",
    "        cv=10\n",
    "    )\n",
    "    gsearch.fit(X_train_enc, Y_train_enc)\n",
    "    if verbose:\n",
    "        print('Raw grid search scores:')\n",
    "        gsearch1.grid_scores_ \n",
    "    print('Best params for this search:')\n",
    "    print(gsearch.best_params_)\n",
    "    print('Best AUC for these params:')\n",
    "    print(gsearch.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Setup param dict.\n",
    "params = {\n",
    "    'n_estimators': [100, 200, 300, 500, 700, 1000, 2000]\n",
    "}\n",
    "# Use simple 10-fold stratified CV.\n",
    "test_params(random_forest, params, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for this search:\n",
      "{'min_samples_split': 13}\n",
      "Best AUC for these params:\n",
      "0.71458857454\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'min_samples_split': [7, 10, 13, 16, 20]\n",
    "}\n",
    "test_params(random_forest, params, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best params for this search:\n",
      "{'min_samples_leaf': 5}\n",
      "Best AUC for these params:\n",
      "0.712809402922\n",
      "Best params for this search:\n",
      "{'max_features': 0.2}\n",
      "Best AUC for these params:\n",
      "0.710624613055\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    'min_samples_leaf': [1, 2, 5, 10, 15, 20, 30, 50]\n",
    "}\n",
    "test_params(random_forest, params, verbose=False)\n",
    "\n",
    "params = {\n",
    "    'max_features': [.10, .20, .30, .40, .50, .60, .70, .80, .90, 'auto']  # auto means sqrt here\n",
    "}\n",
    "test_params(random_forest, params, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "random_forest = RandomForestClassifier(\n",
    "    n_estimators=100, \n",
    "    min_samples_split=13, \n",
    "    min_samples_leaf=5, \n",
    "    max_features=.2, \n",
    "    class_weight='balanced',\n",
    "    random_state=2001, \n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of model vs. dummy: \n",
      "Error of 0.713, 0.500 for model, dummy; -42.537 percent less error.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7126871479083617"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get final CV score for RF model with different seed\n",
    "\n",
    "get_repeated_k_fold_score(random_forest, X_train_enc, Y_train_enc, folds=10, iters=3,\n",
    "                              agg_inner=None, agg_outer=None, seed=2002,\n",
    "                              score_func=roc_auc_score, fit_kwargs=None,\n",
    "                              print_description=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And test performance:\n",
    "# TODO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO CONCLUSION RF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus \n",
    "\n",
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# First, let's pickle our dataset for easy replication and so we don't have to re-run the above script every time.\n",
    "\n",
    "# X_train_enc.to_pickle('./input/mep_x_train_2017_06_13.pkl.xz', compression='xz')\n",
    "# Y_train_enc.to_pickle('./input/mep_y_train_2017_06_13.pkl.xz', compression='xz')\n",
    "# X_test_enc.to_pickle('./input/mep_x_test_2017_06_13.pkl.xz', compression='xz')\n",
    "# Y_test_enc.to_pickle('./input/mep_y_test_2017_06_13.pkl.xz', compression='xz')\n",
    "\n",
    "# w/o compression for pd < 0.20.0 compatibility\n",
    "X_train_enc.to_pickle('./input/mep_x_train_2017_06_13.pkl')\n",
    "Y_train_enc.to_pickle('./input/mep_y_train_2017_06_13.pkl')\n",
    "X_test_enc.to_pickle('./input/mep_x_test_2017_06_13.pkl')\n",
    "Y_test_enc.to_pickle('./input/mep_y_test_2017_06_13.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# And load from pkl.\n",
    "\n",
    "X_train_enc = pd.read_pickle('./input/mep_x_train_2017_06_13.pkl')\n",
    "Y_train_enc = pd.read_pickle('./input/mep_y_train_2017_06_13.pkl')\n",
    "X_test_enc = pd.read_pickle('./input/mep_x_test_2017_06_13.pkl')\n",
    "Y_test_enc = pd.read_pickle('./input/mep_y_test_2017_06_13.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross-Validation\n",
    "\n",
    "1) We'll use cross-validation to establish num_rounds, \n",
    "2) then tune hyperparameters on that num_rounds, \n",
    "3) and finally fit our resulting model using test set validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build xgboost datamatrix object for further operations.\n",
    "dtrain = xgb.DMatrix(X_train_enc, Y_train_enc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.736994+0.00730653\ttrain-logloss:0.657191+0.00104062\ttest-auc:0.725014+0.00916592\ttest-logloss:0.657793+0.00106194\n",
      "[20]\ttrain-auc:0.814671+0.00134697\ttrain-logloss:0.439679+0.00094271\ttest-auc:0.792183+0.00467564\ttest-logloss:0.449996+0.00181048\n",
      "[40]\ttrain-auc:0.835481+0.00118035\ttrain-logloss:0.405057+0.00121355\ttest-auc:0.806548+0.0043459\ttest-logloss:0.422157+0.0027617\n",
      "[60]\ttrain-auc:0.848699+0.00126471\ttrain-logloss:0.389739+0.00142101\ttest-auc:0.814377+0.00439097\ttest-logloss:0.411935+0.00314276\n",
      "[80]\ttrain-auc:0.858763+0.00122946\ttrain-logloss:0.379272+0.000966371\ttest-auc:0.818938+0.00364885\ttest-logloss:0.406244+0.00262638\n",
      "[100]\ttrain-auc:0.867795+0.00111532\ttrain-logloss:0.370414+0.000832694\ttest-auc:0.822548+0.00332232\ttest-logloss:0.402015+0.0025701\n",
      "[120]\ttrain-auc:0.875949+0.00105389\ttrain-logloss:0.362421+0.000790587\ttest-auc:0.825392+0.0027878\ttest-logloss:0.398723+0.0022755\n",
      "[140]\ttrain-auc:0.882934+0.000993645\ttrain-logloss:0.355472+0.000809815\ttest-auc:0.827775+0.00294327\ttest-logloss:0.396065+0.00236317\n",
      "[160]\ttrain-auc:0.889095+0.00105758\ttrain-logloss:0.349056+0.00109076\ttest-auc:0.829621+0.00263039\ttest-logloss:0.393816+0.00215368\n",
      "[180]\ttrain-auc:0.894988+0.00105705\ttrain-logloss:0.342835+0.00119382\ttest-auc:0.831563+0.00274183\ttest-logloss:0.391745+0.00237056\n",
      "[200]\ttrain-auc:0.899987+0.00119759\ttrain-logloss:0.337376+0.00128627\ttest-auc:0.832837+0.00273348\ttest-logloss:0.390252+0.00233655\n",
      "[220]\ttrain-auc:0.904653+0.00099134\ttrain-logloss:0.332038+0.00103194\ttest-auc:0.834171+0.00288882\ttest-logloss:0.388763+0.00251629\n",
      "[240]\ttrain-auc:0.908966+0.000713698\ttrain-logloss:0.327142+0.000825729\ttest-auc:0.834938+0.00328169\ttest-logloss:0.38776+0.00283505\n",
      "[260]\ttrain-auc:0.913047+0.000777197\ttrain-logloss:0.322338+0.000942822\ttest-auc:0.83581+0.0032644\ttest-logloss:0.386776+0.0028029\n",
      "[280]\ttrain-auc:0.916867+0.000836348\ttrain-logloss:0.317715+0.000957122\ttest-auc:0.836375+0.00343579\ttest-logloss:0.385985+0.00304294\n",
      "[300]\ttrain-auc:0.920103+0.000756778\ttrain-logloss:0.313565+0.000865947\ttest-auc:0.837073+0.00348187\ttest-logloss:0.385215+0.00310886\n",
      "[320]\ttrain-auc:0.923314+0.000864092\ttrain-logloss:0.309422+0.000978745\ttest-auc:0.837599+0.0034479\ttest-logloss:0.384565+0.00309501\n",
      "[340]\ttrain-auc:0.926441+0.000764257\ttrain-logloss:0.305276+0.000947671\ttest-auc:0.838243+0.00357501\ttest-logloss:0.383861+0.00326165\n",
      "[360]\ttrain-auc:0.9293+0.000639208\ttrain-logloss:0.301396+0.000774953\ttest-auc:0.838554+0.00358548\ttest-logloss:0.38337+0.0033492\n",
      "[380]\ttrain-auc:0.931946+0.000685413\ttrain-logloss:0.297697+0.000929908\ttest-auc:0.838731+0.00352917\ttest-logloss:0.383062+0.00328209\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-150-08f92544928a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'logloss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'auc'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2001\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mverbose_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;31m# callbacks=[xgb.callback.print_evaluation(show_stdv=True)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m )\n",
      "\u001b[0;32m/Users/jan/anaconda/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mcv\u001b[0;34m(params, dtrain, num_boost_round, nfold, stratified, folds, metrics, obj, feval, maximize, early_stopping_rounds, fpreproc, as_pandas, verbose_eval, show_stdv, seed, callbacks, shuffle)\u001b[0m\n\u001b[1;32m    405\u001b[0m                            evaluation_result_list=None))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfold\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0mfold\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maggcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcvfolds\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jan/anaconda/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/training.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, iteration, fobj)\u001b[0m\n\u001b[1;32m    216\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m         \u001b[0;34m\"\"\"\"Update the boosters for one iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jan/anaconda/lib/python2.7/site-packages/xgboost-0.6-py2.7.egg/xgboost/core.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m             \u001b[0m_check_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mXGBoosterUpdateOneIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    820\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Cross validate to get n_rounds for our simple starter gradient-boosted tree model.\n",
    "# We'll decrease the learning rate later to improve performance, but use this one\n",
    "#   to set parameters w/ CV.\n",
    "xgb_params = {\n",
    "    'max_depth':9, \n",
    "    'eta':.1, \n",
    "    'silent':0, \n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'auc', \n",
    "    'subsample':0.80, \n",
    "    'colsample_bytree':0.80\n",
    "}\n",
    "\n",
    "# It would be better to use repeated, stratified k-fold validation rather than \n",
    "#   simple stratified k-fold, \n",
    "#   but given our low number of columns and large number of training examples,\n",
    "#   I'm not very worried about overfitting and 1x10-fold CV should be adequate.\n",
    "xgb.cv(\n",
    "    xgb_params, \n",
    "    dtrain, \n",
    "    nfold=10, \n",
    "    stratified=True, \n",
    "    num_boost_round=1000, \n",
    "    early_stopping_rounds=20,\n",
    "    metrics={'logloss', 'auc'},\n",
    "    seed = 2001, \n",
    "    verbose_eval=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier_for_gridsearch = xgb.XGBClassifier(\n",
    "    learning_rate =0.1, \n",
    "    n_estimators=339, \n",
    "    max_depth=9,\n",
    "    min_child_weight=1, \n",
    "    gamma=0, \n",
    "    subsample=0.9, \n",
    "    colsample_bytree=0.7,\n",
    "    objective= 'binary:logistic', \n",
    "    nthread=-1, \n",
    "    scale_pos_weight=1, \n",
    "    seed=2001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([mean: 0.79871, std: 0.00252, params: {'max_depth': 3, 'min_child_weight': 1},\n",
       "  mean: 0.79881, std: 0.00254, params: {'max_depth': 3, 'min_child_weight': 2},\n",
       "  mean: 0.81963, std: 0.00211, params: {'max_depth': 5, 'min_child_weight': 1},\n",
       "  mean: 0.81897, std: 0.00159, params: {'max_depth': 5, 'min_child_weight': 2},\n",
       "  mean: 0.83228, std: 0.00208, params: {'max_depth': 7, 'min_child_weight': 1},\n",
       "  mean: 0.83066, std: 0.00199, params: {'max_depth': 7, 'min_child_weight': 2},\n",
       "  mean: 0.83755, std: 0.00192, params: {'max_depth': 9, 'min_child_weight': 1},\n",
       "  mean: 0.83562, std: 0.00221, params: {'max_depth': 9, 'min_child_weight': 2},\n",
       "  mean: 0.83746, std: 0.00229, params: {'max_depth': 11, 'min_child_weight': 1},\n",
       "  mean: 0.83510, std: 0.00283, params: {'max_depth': 11, 'min_child_weight': 2},\n",
       "  mean: 0.83429, std: 0.00258, params: {'max_depth': 13, 'min_child_weight': 1},\n",
       "  mean: 0.83287, std: 0.00275, params: {'max_depth': 13, 'min_child_weight': 2}],\n",
       " {'max_depth': 9, 'min_child_weight': 1},\n",
       " 0.8375502124420201)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Optimize with grid search.\n",
    "\n",
    "params1 = {\n",
    " 'max_depth':range(3, 14, 2),\n",
    " 'min_child_weight':range(1, 3, 1)\n",
    "}\n",
    "\n",
    "test_params(classifier_for_gridsearch, params1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params2 = {\n",
    " 'max_depth': range(8,11,1),\n",
    " 'gamma': [i/10.0 for i in range(0,2)]\n",
    "}\n",
    "\n",
    "test_params(classifier_for_gridsearch, params2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([mean: 0.83789, std: 0.00229, params: {'subsample': 0.7, 'colsample_bytree': 0.7}, mean: 0.83984, std: 0.00215, params: {'subsample': 0.8, 'colsample_bytree': 0.7}, mean: 0.84272, std: 0.00246, params: {'subsample': 0.9, 'colsample_bytree': 0.7}, mean: 0.84001, std: 0.00202, params: {'subsample': 1.0, 'colsample_bytree': 0.7}, mean: 0.83446, std: 0.00193, params: {'subsample': 0.7, 'colsample_bytree': 0.8}, mean: 0.83755, std: 0.00192, params: {'subsample': 0.8, 'colsample_bytree': 0.8}, mean: 0.84020, std: 0.00204, params: {'subsample': 0.9, 'colsample_bytree': 0.8}, mean: 0.83908, std: 0.00218, params: {'subsample': 1.0, 'colsample_bytree': 0.8}, mean: 0.83090, std: 0.00167, params: {'subsample': 0.7, 'colsample_bytree': 0.9}, mean: 0.83495, std: 0.00179, params: {'subsample': 0.8, 'colsample_bytree': 0.9}, mean: 0.83721, std: 0.00253, params: {'subsample': 0.9, 'colsample_bytree': 0.9}, mean: 0.83773, std: 0.00220, params: {'subsample': 1.0, 'colsample_bytree': 0.9}, mean: 0.82819, std: 0.00174, params: {'subsample': 0.7, 'colsample_bytree': 1.0}, mean: 0.83353, std: 0.00225, params: {'subsample': 0.8, 'colsample_bytree': 1.0}, mean: 0.83679, std: 0.00197, params: {'subsample': 0.9, 'colsample_bytree': 1.0}, mean: 0.83684, std: 0.00271, params: {'subsample': 1.0, 'colsample_bytree': 1.0}], [mean: 0.83789, std: 0.00229, params: {'subsample': 0.7, 'colsample_bytree': 0.7}, mean: 0.83984, std: 0.00215, params: {'subsample': 0.8, 'colsample_bytree': 0.7}, mean: 0.84272, std: 0.00246, params: {'subsample': 0.9, 'colsample_bytree': 0.7}, mean: 0.84001, std: 0.00202, params: {'subsample': 1.0, 'colsample_bytree': 0.7}, mean: 0.83446, std: 0.00193, params: {'subsample': 0.7, 'colsample_bytree': 0.8}, mean: 0.83755, std: 0.00192, params: {'subsample': 0.8, 'colsample_bytree': 0.8}, mean: 0.84020, std: 0.00204, params: {'subsample': 0.9, 'colsample_bytree': 0.8}, mean: 0.83908, std: 0.00218, params: {'subsample': 1.0, 'colsample_bytree': 0.8}, mean: 0.83090, std: 0.00167, params: {'subsample': 0.7, 'colsample_bytree': 0.9}, mean: 0.83495, std: 0.00179, params: {'subsample': 0.8, 'colsample_bytree': 0.9}, mean: 0.83721, std: 0.00253, params: {'subsample': 0.9, 'colsample_bytree': 0.9}, mean: 0.83773, std: 0.00220, params: {'subsample': 1.0, 'colsample_bytree': 0.9}, mean: 0.82819, std: 0.00174, params: {'subsample': 0.7, 'colsample_bytree': 1.0}, mean: 0.83353, std: 0.00225, params: {'subsample': 0.8, 'colsample_bytree': 1.0}, mean: 0.83679, std: 0.00197, params: {'subsample': 0.9, 'colsample_bytree': 1.0}, mean: 0.83684, std: 0.00271, params: {'subsample': 1.0, 'colsample_bytree': 1.0}], [mean: 0.83789, std: 0.00229, params: {'subsample': 0.7, 'colsample_bytree': 0.7}, mean: 0.83984, std: 0.00215, params: {'subsample': 0.8, 'colsample_bytree': 0.7}, mean: 0.84272, std: 0.00246, params: {'subsample': 0.9, 'colsample_bytree': 0.7}, mean: 0.84001, std: 0.00202, params: {'subsample': 1.0, 'colsample_bytree': 0.7}, mean: 0.83446, std: 0.00193, params: {'subsample': 0.7, 'colsample_bytree': 0.8}, mean: 0.83755, std: 0.00192, params: {'subsample': 0.8, 'colsample_bytree': 0.8}, mean: 0.84020, std: 0.00204, params: {'subsample': 0.9, 'colsample_bytree': 0.8}, mean: 0.83908, std: 0.00218, params: {'subsample': 1.0, 'colsample_bytree': 0.8}, mean: 0.83090, std: 0.00167, params: {'subsample': 0.7, 'colsample_bytree': 0.9}, mean: 0.83495, std: 0.00179, params: {'subsample': 0.8, 'colsample_bytree': 0.9}, mean: 0.83721, std: 0.00253, params: {'subsample': 0.9, 'colsample_bytree': 0.9}, mean: 0.83773, std: 0.00220, params: {'subsample': 1.0, 'colsample_bytree': 0.9}, mean: 0.82819, std: 0.00174, params: {'subsample': 0.7, 'colsample_bytree': 1.0}, mean: 0.83353, std: 0.00225, params: {'subsample': 0.8, 'colsample_bytree': 1.0}, mean: 0.83679, std: 0.00197, params: {'subsample': 0.9, 'colsample_bytree': 1.0}, mean: 0.83684, std: 0.00271, params: {'subsample': 1.0, 'colsample_bytree': 1.0}])\n"
     ]
    }
   ],
   "source": [
    "params3 = {\n",
    "    'subsample':[i / 10.0 for i in range(7, 11)],\n",
    "    'colsample_bytree':[i / 10.0 for i in range(7, 11)]\n",
    "}\n",
    "\n",
    "test_params(classifier_for_gridsearch, params3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training Using SKL Wrapper\n",
    "\n",
    "XGBoost provides a convenient SKL wrapper so you can use it as you would the other models in SKL. \n",
    "\n",
    "While XGBoost's native models tend to be a bit faster and let you access more of XGB's inteface,\n",
    "  we'll use the SKL wrapper here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.743262\n",
      "Will train until validation_0-auc hasn't improved in 40 rounds.\n",
      "[40]\tvalidation_0-auc:0.784491\n",
      "[80]\tvalidation_0-auc:0.795197\n",
      "[120]\tvalidation_0-auc:0.80188\n",
      "[160]\tvalidation_0-auc:0.807302\n",
      "[200]\tvalidation_0-auc:0.811926\n",
      "[240]\tvalidation_0-auc:0.815163\n",
      "[280]\tvalidation_0-auc:0.817509\n",
      "[320]\tvalidation_0-auc:0.819837\n",
      "[360]\tvalidation_0-auc:0.821489\n",
      "[400]\tvalidation_0-auc:0.822823\n",
      "[440]\tvalidation_0-auc:0.824378\n",
      "[480]\tvalidation_0-auc:0.825412\n",
      "[520]\tvalidation_0-auc:0.827066\n",
      "[560]\tvalidation_0-auc:0.828169\n",
      "[600]\tvalidation_0-auc:0.829378\n",
      "[640]\tvalidation_0-auc:0.830374\n",
      "[680]\tvalidation_0-auc:0.831341\n",
      "[720]\tvalidation_0-auc:0.832451\n",
      "[760]\tvalidation_0-auc:0.833484\n",
      "[800]\tvalidation_0-auc:0.833997\n",
      "[840]\tvalidation_0-auc:0.834512\n",
      "[880]\tvalidation_0-auc:0.835258\n",
      "[920]\tvalidation_0-auc:0.835846\n",
      "[960]\tvalidation_0-auc:0.836545\n",
      "[1000]\tvalidation_0-auc:0.836908\n",
      "[1040]\tvalidation_0-auc:0.837567\n",
      "[1080]\tvalidation_0-auc:0.837881\n",
      "[1120]\tvalidation_0-auc:0.838382\n",
      "[1160]\tvalidation_0-auc:0.838929\n",
      "[1200]\tvalidation_0-auc:0.839505\n",
      "[1240]\tvalidation_0-auc:0.839874\n",
      "[1280]\tvalidation_0-auc:0.840457\n",
      "[1320]\tvalidation_0-auc:0.840996\n",
      "[1360]\tvalidation_0-auc:0.841456\n",
      "[1400]\tvalidation_0-auc:0.841561\n",
      "[1440]\tvalidation_0-auc:0.841935\n",
      "[1480]\tvalidation_0-auc:0.842136\n",
      "[1520]\tvalidation_0-auc:0.842423\n",
      "[1560]\tvalidation_0-auc:0.842739\n",
      "[1600]\tvalidation_0-auc:0.842872\n",
      "[1640]\tvalidation_0-auc:0.843259\n",
      "[1680]\tvalidation_0-auc:0.843551\n",
      "[1720]\tvalidation_0-auc:0.843683\n",
      "[1760]\tvalidation_0-auc:0.843946\n",
      "[1800]\tvalidation_0-auc:0.844139\n",
      "[1840]\tvalidation_0-auc:0.844333\n",
      "[1880]\tvalidation_0-auc:0.844585\n",
      "[1920]\tvalidation_0-auc:0.845013\n",
      "[1960]\tvalidation_0-auc:0.845237\n",
      "[1999]\tvalidation_0-auc:0.845424\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, colsample_bylevel=1, colsample_bytree=0.7,\n",
       "       gamma=0, learning_rate=0.02, max_delta_step=0, max_depth=9,\n",
       "       min_child_weight=1, missing=None, n_estimators=2000, nthread=-1,\n",
       "       objective='binary:logistic', reg_alpha=0, reg_lambda=1,\n",
       "       scale_pos_weight=1, seed=2016, silent=True, subsample=0.9)"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skl_boost = xgb.XGBClassifier(\n",
    "    missing=np.nan, \n",
    "    n_estimators=2000, \n",
    "    learning_rate=0.02, \n",
    "    silent=True,        \n",
    "    max_depth=9, \n",
    "    min_child_weight=1, \n",
    "    gamma=0, \n",
    "    subsample=0.9, \n",
    "    colsample_bytree=0.7,            \n",
    "    nthread=-1, \n",
    "    seed=2016, \n",
    "    objective='binary:logistic'\n",
    ")\n",
    "\n",
    "# Here I'm using performance on the test set for early stopping.\n",
    "#   Given the large number of training examples and few columns, \n",
    "#   I think this is acceptable. But you might prefer to set the\n",
    "#   number of training rounds purely with CV.\n",
    "skl_boost.fit(X_train_enc, Y_train_enc, early_stopping_rounds=40, verbose=40,\n",
    "            eval_metric=\"auc\", eval_set=[(X_test_enc, Y_test_enc)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "skl_boost = xgb.XGBClassifier(\n",
    "    missing=np.nan, \n",
    "    n_estimators=1686, \n",
    "    learning_rate=0.02, \n",
    "    silent=True,        \n",
    "    max_depth=9, \n",
    "    min_child_weight=1, \n",
    "    gamma=0, \n",
    "    subsample=0.9, \n",
    "    colsample_bytree=0.7,            \n",
    "    nthread=-1, \n",
    "    seed=2016, \n",
    "    objective='binary:logistic'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Scores & Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of model vs. dummy: \n",
      "Error of 0.679, 0.500 for model, dummy; -35.791 percent less error.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6789536671988217"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify above w/ k-fold CV & different seed (so we're not overfitting to those particular cv-splits)\n",
    "\n",
    "get_repeated_k_fold_score(skl_boost, X_train_enc, Y_train_enc, folds=10, iters=1,\n",
    "                              agg_inner=None, agg_outer=None, seed=2002,\n",
    "                              score_func=roc_auc_score, fit_kwargs=None,\n",
    "                              print_description=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-error:0.221061+0.00489284\ttest-error:0.224403+0.00524578\n",
      "[20]\ttrain-error:0.198558+0.00137553\ttest-error:0.202172+0.00189445\n",
      "[40]\ttrain-error:0.194455+0.00110733\ttest-error:0.199185+0.00156989\n",
      "[60]\ttrain-error:0.191194+0.00107074\ttest-error:0.196616+0.00156405\n",
      "[80]\ttrain-error:0.188156+0.000778677\ttest-error:0.193857+0.00147352\n",
      "[100]\ttrain-error:0.185744+0.000766213\ttest-error:0.19173+0.00125641\n",
      "[120]\ttrain-error:0.183226+0.000649301\ttest-error:0.189435+0.00141424\n",
      "[140]\ttrain-error:0.180722+0.000449606\ttest-error:0.187506+0.00126284\n",
      "[160]\ttrain-error:0.178492+0.000570488\ttest-error:0.185395+0.00135194\n",
      "[180]\ttrain-error:0.176483+0.00060382\ttest-error:0.183459+0.00143589\n",
      "[200]\ttrain-error:0.174496+0.000608873\ttest-error:0.181627+0.0015561\n",
      "[220]\ttrain-error:0.172856+0.00057987\ttest-error:0.180427+0.00166718\n",
      "[240]\ttrain-error:0.171551+0.000562294\ttest-error:0.179522+0.00160945\n",
      "[260]\ttrain-error:0.170408+0.000572816\ttest-error:0.178551+0.00161733\n",
      "[280]\ttrain-error:0.169335+0.000461947\ttest-error:0.17766+0.0014494\n",
      "[300]\ttrain-error:0.168436+0.000456619\ttest-error:0.176888+0.00131774\n",
      "[320]\ttrain-error:0.167581+0.000426162\ttest-error:0.176255+0.00108376\n",
      "[340]\ttrain-error:0.166802+0.000447369\ttest-error:0.175563+0.00106874\n",
      "[360]\ttrain-error:0.166034+0.00040892\ttest-error:0.175173+0.00101594\n",
      "[380]\ttrain-error:0.165305+0.000412802\ttest-error:0.174725+0.000956793\n",
      "[400]\ttrain-error:0.164639+0.00040259\ttest-error:0.174305+0.000870114\n",
      "[420]\ttrain-error:0.16399+0.000442411\ttest-error:0.173716+0.000998041\n",
      "[440]\ttrain-error:0.163335+0.000419896\ttest-error:0.17329+0.000943744\n",
      "[460]\ttrain-error:0.162563+0.000321566\ttest-error:0.172848+0.000934658\n",
      "[480]\ttrain-error:0.162019+0.000289289\ttest-error:0.172495+0.000804425\n",
      "[500]\ttrain-error:0.161368+0.000342763\ttest-error:0.172325+0.000732776\n",
      "[520]\ttrain-error:0.160639+0.000299701\ttest-error:0.171921+0.00082517\n",
      "[540]\ttrain-error:0.160086+0.000344351\ttest-error:0.17159+0.000672181\n",
      "[560]\ttrain-error:0.159527+0.000309463\ttest-error:0.171523+0.000815865\n",
      "[580]\ttrain-error:0.158954+0.000359277\ttest-error:0.17117+0.00092372\n",
      "[600]\ttrain-error:0.15833+0.000420418\ttest-error:0.170971+0.000878218\n",
      "[620]\ttrain-error:0.157786+0.000430296\ttest-error:0.170788+0.000895049\n",
      "[640]\ttrain-error:0.157118+0.000457291\ttest-error:0.170515+0.0008054\n",
      "[660]\ttrain-error:0.15653+0.000401612\ttest-error:0.170162+0.000855623\n",
      "[680]\ttrain-error:0.156005+0.0004078\ttest-error:0.169927+0.000939594\n",
      "[700]\ttrain-error:0.155495+0.000433354\ttest-error:0.169765+0.000950004\n",
      "[720]\ttrain-error:0.154956+0.000464642\ttest-error:0.169404+0.000939624\n",
      "[740]\ttrain-error:0.154428+0.00048018\ttest-error:0.16922+0.00109687\n",
      "[760]\ttrain-error:0.153933+0.000468627\ttest-error:0.169029+0.00101068\n",
      "[780]\ttrain-error:0.153456+0.000463019\ttest-error:0.168852+0.000923257\n",
      "[800]\ttrain-error:0.152862+0.000469569\ttest-error:0.168595+0.000928567\n",
      "[820]\ttrain-error:0.152376+0.000504465\ttest-error:0.168469+0.000916096\n",
      "[840]\ttrain-error:0.151831+0.000480865\ttest-error:0.168271+0.00095934\n",
      "[860]\ttrain-error:0.151347+0.000482976\ttest-error:0.168175+0.00104777\n",
      "[880]\ttrain-error:0.150881+0.000454849\ttest-error:0.167962+0.0010594\n",
      "[900]\ttrain-error:0.1504+0.000488052\ttest-error:0.167866+0.000955878\n",
      "[920]\ttrain-error:0.149924+0.000471824\ttest-error:0.167653+0.00106416\n",
      "[940]\ttrain-error:0.149337+0.000535097\ttest-error:0.167601+0.00106566\n",
      "[960]\ttrain-error:0.148865+0.000464816\ttest-error:0.167322+0.00109959\n",
      "[980]\ttrain-error:0.148348+0.000495603\ttest-error:0.167145+0.00102648\n",
      "[1000]\ttrain-error:0.147854+0.000497573\ttest-error:0.16699+0.00110779\n",
      "[1020]\ttrain-error:0.147366+0.000451596\ttest-error:0.166902+0.00123188\n",
      "[1040]\ttrain-error:0.146884+0.000429251\ttest-error:0.166645+0.00130581\n",
      "[1060]\ttrain-error:0.14647+0.00034647\ttest-error:0.16649+0.00129708\n",
      "[1080]\ttrain-error:0.146049+0.00039342\ttest-error:0.166431+0.00123885\n",
      "[1100]\ttrain-error:0.145537+0.00037747\ttest-error:0.166284+0.00130002\n",
      "[1120]\ttrain-error:0.145126+0.000376342\ttest-error:0.166181+0.00125539\n",
      "[1140]\ttrain-error:0.144686+0.000363335\ttest-error:0.16599+0.00125768\n",
      "[1160]\ttrain-error:0.144204+0.00038557\ttest-error:0.165872+0.00124569\n",
      "[1180]\ttrain-error:0.143735+0.000347527\ttest-error:0.165585+0.00120539\n",
      "[1200]\ttrain-error:0.143311+0.000390592\ttest-error:0.165482+0.00119063\n",
      "[1220]\ttrain-error:0.142865+0.000417379\ttest-error:0.165393+0.00125919\n",
      "[1240]\ttrain-error:0.142338+0.000432796\ttest-error:0.165305+0.00130093\n",
      "[1260]\ttrain-error:0.141932+0.000441362\ttest-error:0.165107+0.0012574\n",
      "[1280]\ttrain-error:0.141469+0.000468851\ttest-error:0.164982+0.00121969\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test-error-mean</th>\n",
       "      <th>test-error-std</th>\n",
       "      <th>train-error-mean</th>\n",
       "      <th>train-error-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.224403</td>\n",
       "      <td>0.005246</td>\n",
       "      <td>0.221061</td>\n",
       "      <td>0.004893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.216853</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.213367</td>\n",
       "      <td>0.008318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.214734</td>\n",
       "      <td>0.007105</td>\n",
       "      <td>0.211057</td>\n",
       "      <td>0.007357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.211408</td>\n",
       "      <td>0.006326</td>\n",
       "      <td>0.208266</td>\n",
       "      <td>0.006403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.210627</td>\n",
       "      <td>0.007650</td>\n",
       "      <td>0.207371</td>\n",
       "      <td>0.007425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.208913</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.205374</td>\n",
       "      <td>0.005211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.207154</td>\n",
       "      <td>0.005072</td>\n",
       "      <td>0.203516</td>\n",
       "      <td>0.005004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.206992</td>\n",
       "      <td>0.005207</td>\n",
       "      <td>0.203350</td>\n",
       "      <td>0.005254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.206455</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.202681</td>\n",
       "      <td>0.005355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.206139</td>\n",
       "      <td>0.005536</td>\n",
       "      <td>0.202377</td>\n",
       "      <td>0.005639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.205087</td>\n",
       "      <td>0.005154</td>\n",
       "      <td>0.201184</td>\n",
       "      <td>0.004917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.204387</td>\n",
       "      <td>0.003712</td>\n",
       "      <td>0.200678</td>\n",
       "      <td>0.003372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.204292</td>\n",
       "      <td>0.003450</td>\n",
       "      <td>0.200328</td>\n",
       "      <td>0.003036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.203593</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.199644</td>\n",
       "      <td>0.002334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.203431</td>\n",
       "      <td>0.002784</td>\n",
       "      <td>0.199418</td>\n",
       "      <td>0.002300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.203019</td>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.199287</td>\n",
       "      <td>0.001973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.203203</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>0.199635</td>\n",
       "      <td>0.002185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.202702</td>\n",
       "      <td>0.002283</td>\n",
       "      <td>0.199276</td>\n",
       "      <td>0.001597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.202570</td>\n",
       "      <td>0.002127</td>\n",
       "      <td>0.199218</td>\n",
       "      <td>0.001326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.202415</td>\n",
       "      <td>0.002187</td>\n",
       "      <td>0.198885</td>\n",
       "      <td>0.001554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.202172</td>\n",
       "      <td>0.001894</td>\n",
       "      <td>0.198558</td>\n",
       "      <td>0.001376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.201922</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>0.198316</td>\n",
       "      <td>0.001318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.201768</td>\n",
       "      <td>0.001436</td>\n",
       "      <td>0.197959</td>\n",
       "      <td>0.001290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.201554</td>\n",
       "      <td>0.001431</td>\n",
       "      <td>0.197817</td>\n",
       "      <td>0.001384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.201569</td>\n",
       "      <td>0.001462</td>\n",
       "      <td>0.197651</td>\n",
       "      <td>0.001309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.201429</td>\n",
       "      <td>0.001360</td>\n",
       "      <td>0.197428</td>\n",
       "      <td>0.001421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.201172</td>\n",
       "      <td>0.001483</td>\n",
       "      <td>0.197253</td>\n",
       "      <td>0.001270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.201311</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.197375</td>\n",
       "      <td>0.001487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.201363</td>\n",
       "      <td>0.001402</td>\n",
       "      <td>0.197284</td>\n",
       "      <td>0.001568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.200627</td>\n",
       "      <td>0.001628</td>\n",
       "      <td>0.196761</td>\n",
       "      <td>0.001578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>0.165107</td>\n",
       "      <td>0.001247</td>\n",
       "      <td>0.142096</td>\n",
       "      <td>0.000413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1252</th>\n",
       "      <td>0.165099</td>\n",
       "      <td>0.001264</td>\n",
       "      <td>0.142076</td>\n",
       "      <td>0.000419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1253</th>\n",
       "      <td>0.165099</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.142054</td>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1254</th>\n",
       "      <td>0.165107</td>\n",
       "      <td>0.001285</td>\n",
       "      <td>0.142042</td>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1255</th>\n",
       "      <td>0.165077</td>\n",
       "      <td>0.001261</td>\n",
       "      <td>0.142024</td>\n",
       "      <td>0.000437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1256</th>\n",
       "      <td>0.165019</td>\n",
       "      <td>0.001232</td>\n",
       "      <td>0.142010</td>\n",
       "      <td>0.000436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1257</th>\n",
       "      <td>0.165085</td>\n",
       "      <td>0.001311</td>\n",
       "      <td>0.141986</td>\n",
       "      <td>0.000434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1258</th>\n",
       "      <td>0.165092</td>\n",
       "      <td>0.001309</td>\n",
       "      <td>0.141966</td>\n",
       "      <td>0.000433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1259</th>\n",
       "      <td>0.165063</td>\n",
       "      <td>0.001269</td>\n",
       "      <td>0.141953</td>\n",
       "      <td>0.000442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>0.165107</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>0.141932</td>\n",
       "      <td>0.000441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1261</th>\n",
       "      <td>0.165085</td>\n",
       "      <td>0.001251</td>\n",
       "      <td>0.141915</td>\n",
       "      <td>0.000445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1262</th>\n",
       "      <td>0.165077</td>\n",
       "      <td>0.001307</td>\n",
       "      <td>0.141890</td>\n",
       "      <td>0.000430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1263</th>\n",
       "      <td>0.165063</td>\n",
       "      <td>0.001304</td>\n",
       "      <td>0.141861</td>\n",
       "      <td>0.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1264</th>\n",
       "      <td>0.165077</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.141830</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1265</th>\n",
       "      <td>0.165077</td>\n",
       "      <td>0.001333</td>\n",
       "      <td>0.141803</td>\n",
       "      <td>0.000438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1266</th>\n",
       "      <td>0.165077</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.141770</td>\n",
       "      <td>0.000444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1267</th>\n",
       "      <td>0.165055</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.141761</td>\n",
       "      <td>0.000451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1268</th>\n",
       "      <td>0.165018</td>\n",
       "      <td>0.001323</td>\n",
       "      <td>0.141744</td>\n",
       "      <td>0.000454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269</th>\n",
       "      <td>0.165041</td>\n",
       "      <td>0.001328</td>\n",
       "      <td>0.141725</td>\n",
       "      <td>0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>0.165048</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>0.141704</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1271</th>\n",
       "      <td>0.165048</td>\n",
       "      <td>0.001353</td>\n",
       "      <td>0.141686</td>\n",
       "      <td>0.000475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>0.165004</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.141670</td>\n",
       "      <td>0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1273</th>\n",
       "      <td>0.164989</td>\n",
       "      <td>0.001291</td>\n",
       "      <td>0.141642</td>\n",
       "      <td>0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1274</th>\n",
       "      <td>0.164996</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.141614</td>\n",
       "      <td>0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1275</th>\n",
       "      <td>0.165026</td>\n",
       "      <td>0.001256</td>\n",
       "      <td>0.141595</td>\n",
       "      <td>0.000460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1276</th>\n",
       "      <td>0.165026</td>\n",
       "      <td>0.001280</td>\n",
       "      <td>0.141581</td>\n",
       "      <td>0.000467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1277</th>\n",
       "      <td>0.165011</td>\n",
       "      <td>0.001272</td>\n",
       "      <td>0.141558</td>\n",
       "      <td>0.000465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1278</th>\n",
       "      <td>0.165004</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.141536</td>\n",
       "      <td>0.000470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1279</th>\n",
       "      <td>0.165004</td>\n",
       "      <td>0.001216</td>\n",
       "      <td>0.141503</td>\n",
       "      <td>0.000462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1280</th>\n",
       "      <td>0.164982</td>\n",
       "      <td>0.001220</td>\n",
       "      <td>0.141469</td>\n",
       "      <td>0.000469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1281 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      test-error-mean  test-error-std  train-error-mean  train-error-std\n",
       "0            0.224403        0.005246          0.221061         0.004893\n",
       "1            0.216853        0.008242          0.213367         0.008318\n",
       "2            0.214734        0.007105          0.211057         0.007357\n",
       "3            0.211408        0.006326          0.208266         0.006403\n",
       "4            0.210627        0.007650          0.207371         0.007425\n",
       "5            0.208913        0.005325          0.205374         0.005211\n",
       "6            0.207154        0.005072          0.203516         0.005004\n",
       "7            0.206992        0.005207          0.203350         0.005254\n",
       "8            0.206455        0.005200          0.202681         0.005355\n",
       "9            0.206139        0.005536          0.202377         0.005639\n",
       "10           0.205087        0.005154          0.201184         0.004917\n",
       "11           0.204387        0.003712          0.200678         0.003372\n",
       "12           0.204292        0.003450          0.200328         0.003036\n",
       "13           0.203593        0.002831          0.199644         0.002334\n",
       "14           0.203431        0.002784          0.199418         0.002300\n",
       "15           0.203019        0.002364          0.199287         0.001973\n",
       "16           0.203203        0.002942          0.199635         0.002185\n",
       "17           0.202702        0.002283          0.199276         0.001597\n",
       "18           0.202570        0.002127          0.199218         0.001326\n",
       "19           0.202415        0.002187          0.198885         0.001554\n",
       "20           0.202172        0.001894          0.198558         0.001376\n",
       "21           0.201922        0.001569          0.198316         0.001318\n",
       "22           0.201768        0.001436          0.197959         0.001290\n",
       "23           0.201554        0.001431          0.197817         0.001384\n",
       "24           0.201569        0.001462          0.197651         0.001309\n",
       "25           0.201429        0.001360          0.197428         0.001421\n",
       "26           0.201172        0.001483          0.197253         0.001270\n",
       "27           0.201311        0.001323          0.197375         0.001487\n",
       "28           0.201363        0.001402          0.197284         0.001568\n",
       "29           0.200627        0.001628          0.196761         0.001578\n",
       "...               ...             ...               ...              ...\n",
       "1251         0.165107        0.001247          0.142096         0.000413\n",
       "1252         0.165099        0.001264          0.142076         0.000419\n",
       "1253         0.165099        0.001291          0.142054         0.000430\n",
       "1254         0.165107        0.001285          0.142042         0.000441\n",
       "1255         0.165077        0.001261          0.142024         0.000437\n",
       "1256         0.165019        0.001232          0.142010         0.000436\n",
       "1257         0.165085        0.001311          0.141986         0.000434\n",
       "1258         0.165092        0.001309          0.141966         0.000433\n",
       "1259         0.165063        0.001269          0.141953         0.000442\n",
       "1260         0.165107        0.001257          0.141932         0.000441\n",
       "1261         0.165085        0.001251          0.141915         0.000445\n",
       "1262         0.165077        0.001307          0.141890         0.000430\n",
       "1263         0.165063        0.001304          0.141861         0.000455\n",
       "1264         0.165077        0.001315          0.141830         0.000444\n",
       "1265         0.165077        0.001333          0.141803         0.000438\n",
       "1266         0.165077        0.001387          0.141770         0.000444\n",
       "1267         0.165055        0.001346          0.141761         0.000451\n",
       "1268         0.165018        0.001323          0.141744         0.000454\n",
       "1269         0.165041        0.001328          0.141725         0.000462\n",
       "1270         0.165048        0.001345          0.141704         0.000469\n",
       "1271         0.165048        0.001353          0.141686         0.000475\n",
       "1272         0.165004        0.001314          0.141670         0.000462\n",
       "1273         0.164989        0.001291          0.141642         0.000462\n",
       "1274         0.164996        0.001296          0.141614         0.000462\n",
       "1275         0.165026        0.001256          0.141595         0.000460\n",
       "1276         0.165026        0.001280          0.141581         0.000467\n",
       "1277         0.165011        0.001272          0.141558         0.000465\n",
       "1278         0.165004        0.001237          0.141536         0.000470\n",
       "1279         0.165004        0.001216          0.141503         0.000462\n",
       "1280         0.164982        0.001220          0.141469         0.000469\n",
       "\n",
       "[1281 rows x 4 columns]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# CV perf with a different seed is far worse than test performance, \n",
    "#   suggesting we might be overfitting to the test set. \n",
    "# Let's try checking how many rds we get with CV and lower lrate.\n",
    "\n",
    "xgb_params = {\n",
    "    'max_depth':9, \n",
    "    'eta':.02, \n",
    "    'silent':0, \n",
    "    'objective':'binary:logistic',\n",
    "    'eval_metric':'auc', \n",
    "    'subsample':0.90, \n",
    "    'colsample_bytree':0.70\n",
    "}\n",
    "\n",
    "xgb.cv(\n",
    "    xgb_params, \n",
    "    dtrain, \n",
    "    nfold=10, \n",
    "    stratified=True, \n",
    "    num_boost_round=2500, \n",
    "    early_stopping_rounds=20,\n",
    "    metrics={'error'}, # try metrics={'logloss', 'auc'}\n",
    "    seed = 2003, \n",
    "    verbose_eval=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance of model vs. dummy: \n",
      "Error of 0.673, 0.500 for model, dummy; -34.665 percent less error.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6733272852035482"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now try using cv rounds instead of test-early-stopping rounds (1280 instead of 1686)\n",
    "\n",
    "skl_boost = xgb.XGBClassifier(\n",
    "    missing=np.nan, \n",
    "    n_estimators=1280, \n",
    "    learning_rate=0.02, \n",
    "    silent=True,        \n",
    "    max_depth=9, \n",
    "    min_child_weight=1, \n",
    "    gamma=0, \n",
    "    subsample=0.9, \n",
    "    colsample_bytree=0.7,            \n",
    "    nthread=-1, \n",
    "    seed=2016, \n",
    "    objective='binary:logistic'\n",
    ")\n",
    "\n",
    "get_repeated_k_fold_score(skl_boost, X_train_enc, Y_train_enc, folds=10, iters=1,\n",
    "                              agg_inner=None, agg_outer=None, seed=2002,\n",
    "                              score_func=roc_auc_score, fit_kwargs=None,\n",
    "                              print_description=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC Score:\n",
      "0.77374064631\n",
      "\n",
      "LogLoss:\n",
      "0.454300897467\n",
      "('Accuracy : ', 0.83887678813210098)\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.839     0.976     0.902     25951\n",
      "       True      0.835     0.396     0.537      8023\n",
      "\n",
      "avg / total      0.838     0.839     0.816     33974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predicted_probs = skl_boost.predict_proba(X_test_enc)[:,1]\n",
    "\n",
    "print('AUC Score:')\n",
    "print(roc_auc_score(Y_test_enc, probs[:,1:]))\n",
    "print('')\n",
    "\n",
    "print('LogLoss:')\n",
    "print(log_loss(Y_test_enc, probs))\n",
    "\n",
    "Y_pred_enc = skl_boost.predict(X_test_enc)\n",
    "xgb_accuracy = skl_boost.score(X_test_enc, Y_test_enc)\n",
    "print('Accuracy : ', xgb_accuracy)\n",
    "print('')\n",
    "\n",
    "print(classification_report(Y_test_enc, Y_pred_enc, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGBoost provides a convenient function to show feature importances.\n",
    "# It's even more useful than with RF, since gradient-boosted trees tend to \n",
    "#   \"pick\" between highly correlated features, choosing just one feature to represent the trend.\n",
    "print(\"\\n\\n Feature importances: \")\n",
    "print(xgb.plot_importance(skl_boost))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we got an extra 1%+ accuracy from xgboost vs. rf (.823 vs .836). We lost some recall for the true cases.\n",
    "\n",
    "### Tweaking the decision threshold\n",
    "\n",
    "We wanted to be able to correctly recall instances of diabetes - so here we'll tweak the decision threshold up to trade precision for recall (and, specifically, recall for the positive cases).\n",
    "\n",
    "We'll graph AUC to get a better idea of the trade-offs involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhcAAAGJCAYAAAA5XRHmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1faccdc4320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from @motuai10\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(Y_test_enc, predicted_probs)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate, true_positive_rate, 'b',\n",
    "label='AUC = %0.2f'% roc_auc)\n",
    "plt.legend(loc='lower right')\n",
    "plt.plot([0,1],[0,1],'r--')\n",
    "plt.xlim([-0.1,1.1])\n",
    "plt.ylim([-0.1,1.1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      False      0.881     0.864     0.872     25968\n",
      "       True      0.584     0.621     0.602      8006\n",
      "\n",
      "avg / total      0.811     0.806     0.808     33974\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred_30 = predicted_probs >= .30\n",
    "print(classification_report(Y_test_enc, Y_pred_30, digits=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now recall 62% of true positives - much better than 37%!   \n",
    "\n",
    "Only 58% of our positives actually have diabetes, but that seems like an acceptable trade-off from a medical standpoint; it's OK to spend a little extra time checking on these people if they more likely than not have diabetes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus 2 - LightGBM\n",
    "\n",
    "I originally wrote this notebook in Summer 2016, and since then, LightGBM has risen to prominence as a faster and often more accurate alternative to XGBoost. By using binning, it can typically run 5-15x faster, and XGBoost is already quite fast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/Users/jan/anaconda/lib/python2.7/site-packages/lightgbm-0.1-py2.7.egg/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/gcc/lib/gcc/6/libgomp.1.dylib\n  Referenced from: /Users/jan/anaconda/lib/python2.7/site-packages/lightgbm-0.1-py2.7.egg/lightgbm/lib_lightgbm.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-153-fe89d58d4379>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Start by using CV to get rounds for a quicker-training model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m lgb_params = {\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m'learning_rate'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jan/anaconda/lib/python2.7/site-packages/lightgbm-0.1-py2.7.egg/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m from .callback import (early_stopping, print_evaluation, record_evaluation,\n\u001b[1;32m     11\u001b[0m                        reset_parameter)\n",
      "\u001b[0;32m/Users/jan/anaconda/lib/python2.7/site-packages/lightgbm-0.1-py2.7.egg/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jan/anaconda/lib/python2.7/site-packages/lightgbm-0.1-py2.7.egg/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cannot find LightGBM library\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jan/anaconda/lib/python2.7/ctypes/__init__.pyc\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 440\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jan/anaconda/lib/python2.7/ctypes/__init__.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/Users/jan/anaconda/lib/python2.7/site-packages/lightgbm-0.1-py2.7.egg/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/gcc/lib/gcc/6/libgomp.1.dylib\n  Referenced from: /Users/jan/anaconda/lib/python2.7/site-packages/lightgbm-0.1-py2.7.egg/lightgbm/lib_lightgbm.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "# Start by using CV to get rounds for a quicker-training model.\n",
    "import lightgbm as lgb\n",
    "\n",
    "lgb_params = {\n",
    "    'learning_rate': 0.1,\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': ['rmse', 'auc'],\n",
    "    'num_leaves': 31,\n",
    "    'max_depth':-1,\n",
    "    'n_estimators':2000,\n",
    "    'max_bin':255,\n",
    "    'min_split_gain':0,\n",
    "    'min_child_weight':5,\n",
    "    'min_child_samples':30,\n",
    "    'subsample':.8,\n",
    "    'subsample_freq':1,\n",
    "    'colsample_bytree':.8,\n",
    "    'reg_alpha':0,\n",
    "    'reg_lambda':0,\n",
    "    'seed':0,\n",
    "    'nthread':-1,\n",
    "    'verbose': 20\n",
    "}\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train_enc, Y_train_enc)\n",
    "# lgb_eval = lgb.Dataset(???, reference=lgb_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CV for lgbm\n",
    "# Using log vals to simulate eval metric\n",
    "cv_result = lgb.cv(\n",
    "lgb_params, \n",
    "lgb_train, \n",
    "nfold=10,\n",
    "num_boost_round=2000, \n",
    "early_stopping_rounds=20,\n",
    "verbose_eval=True, \n",
    "show_stdv=False,\n",
    "seed=2001\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Set number of boost rds w/ CV result\n",
    "cv_result[['train-rmse-mean', 'test-rmse-mean']].plot()\n",
    "if cv_result:\n",
    "    rds = len(cv_result)\n",
    "    print('num rds from cv = %i' % rds)\n",
    "else:\n",
    "    rds = 1050\n",
    "    print('rds manually set to %i' % rds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: LightGBM\n",
    "\n",
    "# Tune w/ random search, 10-fold CV, \n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
